{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "GRU_model_code.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYT1K8yxLld3",
        "outputId": "dda4e33e-708a-48c2-e825-2a04ab921076"
      },
      "source": [
        "#to get the files from google drive folder\n",
        "!pip install kora -q\n",
        "from kora import drive\n",
        "drive.link_nbs()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 57 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 2.3 MB/s \n",
            "\u001b[?25hMounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y875WthgG8TC"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "import numpy as np  \n",
        "from datetime import date, timedelta\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "#from github import Github\n",
        "#import github\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# Import tensor dataset & data loader\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "# Import nn.functional\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from typing import Union, Tuple\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statistics import mean\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
        "import math\n",
        "import random\n",
        "import imageio\n",
        "from data_preparation import create_dataset, data_preparation\n",
        "from model_fit_code import fit\n",
        "#from sklearn.metrics import mean_absolute_percentage_error\n",
        "matplotlib.style.use('seaborn')\n",
        "%matplotlib inline\n",
        "#random.seed(42)\n",
        "#torch.manual_seed(42)\n",
        "#np.random.seed(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7xL5tAwG8TF"
      },
      "source": [
        "#generalisd implementation of GRU architecture\n",
        "class GRUNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
        "        super(GRUNet, self).__init__()\n",
        "        self.hidden_dim = hidden_dim # hidden dimention\n",
        "        self.n_layers = n_layers # number of layers\n",
        "        \n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True) # nn gru layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim) # linear layer on top of gru layer\n",
        "        self.relu = nn.ReLU() # relu activation function\n",
        "         \n",
        "    def forward(self, x):\n",
        "        weight = next(self.parameters()).data\n",
        "        h = weight.new(self.n_layers, x.size(0), self.hidden_dim).zero_()\n",
        "        out, h = self.gru(x, h)\n",
        "        out = self.fc(self.relu(out[:,-1]))\n",
        "        return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "94hYt3khG8TH",
        "outputId": "fe019af4-17be-4810-cdc0-7e31ca451366"
      },
      "source": [
        "Shortlisted_States=['Karnataka','Maharashtra','Uttar-Pradesh','Kerala','Tamil-Nadu'] #list of states \n",
        "results_gru=[]\n",
        "for state in Shortlisted_States: ##state iteration\n",
        "  best_models=[]\n",
        "  #getting data from github\n",
        "  df=pd.read_csv(\"https://raw.githubusercontent.com/sureshkuc/Data-Science-in-Life-Science-Project/main/Indian-States-Covid19-Datasets/\"+state+\".csv\", parse_dates=[\"Date\"]).drop(columns =[\"Unnamed: 0\"])\n",
        "  df = df[df[\"Date\"] > \"2020-03-10\"] # selecting data from 10th March 2020 onwards\n",
        "  df = df.set_index(\"Date\")\n",
        "  df = df[['Confirmed', 'Recovered', 'Deceased', 'New_Confirmerd', 'New_Deaths', 'New_Recovered']] # list of selected features\n",
        "  #print(df.describe())\n",
        "\n",
        "  time_step=[5,7,15,30] # list of time step\n",
        "  Number_of_feature=[1,2,3,4,5,6] # list of feature index\n",
        "  multi_feature=True\n",
        "  output_dim=1\n",
        "  for n_f in Number_of_feature: # feature iteration\n",
        "    for t_s in time_step: # time step iteration \n",
        "      #data preprocessing\n",
        "      train_loader, test_loader, scaler = data_preparation(df, scaling_range=(0,1),time_step=t_s,number_feature=n_f, response_variable_index=0,data_split_ratio=0.8, Suffle=False)\n",
        "      for n_layers in range(1,3,1): #layers iteration\n",
        "        for n_hidden_nodes in [1,5,8,16,32]: # hidden nodes list iteration\n",
        "          \n",
        "          max_epochs=25 # max epochs\n",
        "          # setting seed to reproduce the results\n",
        "          random.seed(42)\n",
        "          torch.manual_seed(42)\n",
        "          np.random.seed(42)\n",
        "          #CNN model with L1 loss\n",
        "          #best_model=Call_CNN_model(state,dataset=(train_loader, test_loader), lr=1e-2,criterion=nn.L1Loss(),max_epochs=max_epochs)\n",
        "          GRUNet_model = GRUNet(n_f, n_hidden_nodes, output_dim, n_layers)\n",
        "          #if torch.cuda.is_available():\n",
        "          #stm_model = lstm_model.cuda()\n",
        "          #gru_optim = optim.SGD(GRUNet_model.parameters(), lr=1e-3, momentum=0.9)\n",
        "          gru_optim = optim.Adam(GRUNet_model.parameters(), lr=1e-3)\n",
        "          train_losses,test_losses,best_model = fit(GRUNet_model, gru_optim,nn.L1Loss(),(train_loader, test_loader), max_epochs=max_epochs,cuda=False)\n",
        "          #print(f'\\nTraining took {end-start}s!')\n",
        "          #plot_loss(max_epochs,train_losses,test_losses,model_name='CNN for '+state)\n",
        "          GRUNet_model = GRUNet(n_f, n_hidden_nodes, output_dim, n_layers)\n",
        "          GRUNet_model.load_state_dict(best_model)\n",
        "          GRUNet_model.eval()\n",
        "          test_x,test_y=test_loader\n",
        "          predictions=GRUNet_model(test_x)\n",
        "          test_y=test_y.cpu().detach().numpy()\n",
        "          predictions=predictions.cpu().detach().numpy()\n",
        "          mae=mean_absolute_error(test_y,predictions)\n",
        "          rmse=math.sqrt(mean_squared_error(test_y,predictions))\n",
        "          #mape=mean_absolute_percentage_error(test_y,predictions)\n",
        "          r2s=r2_score(test_y,predictions)\n",
        "          results_gru.append([state,n_f,t_s,n_layers,n_hidden_nodes,mae,rmse,r2s])\n",
        "          print(state,'n_f',n_f,'t_s',t_s,'n_layers',n_layers,n_hidden_nodes,'Error',mae,rmse,r2s)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(384, 5, 1)\n",
            "(384, 5, 1) (384, 1)\n",
            "Epoch: 0/25  Loss: 0.267581 Test loss: 0.250573Karnataka n_f 1 t_s 5 n_layers 1 1 Error 0.5510571 0.6065956212021238 -5.60329328697985\n",
            "Epoch: 0/25  Loss: 0.444396 Test loss: 1.093293Karnataka n_f 1 t_s 5 n_layers 1 5 Error 0.6523116 0.6976152927042509 -7.733614536892693\n",
            "Epoch: 0/25  Loss: 0.147575 Test loss: 0.245210Karnataka n_f 1 t_s 5 n_layers 1 8 Error 0.3266558 0.3932463808481243 -1.7751822152328631\n",
            "Epoch: 0/25  Loss: 0.192040 Test loss: 0.458475Karnataka n_f 1 t_s 5 n_layers 1 16 Error 0.09795287 0.11803494247955973 0.7499751115444157\n",
            "Epoch: 0/25  Loss: 0.134923 Test loss: 0.417773Karnataka n_f 1 t_s 5 n_layers 1 32 Error 0.14954539 0.1721026148877546 0.46845871221696067\n",
            "Epoch: 0/25  Loss: 0.628566 Test loss: 1.419832Karnataka n_f 1 t_s 5 n_layers 2 1 Error 0.67346364 0.7136362435435208 -8.139361765503137\n",
            "Epoch: 0/25  Loss: 0.191334 Test loss: 0.200133Karnataka n_f 1 t_s 5 n_layers 2 5 Error 0.49242127 0.5461023867555833 -4.351926893363695\n",
            "Epoch: 0/25  Loss: 0.164123 Test loss: 0.428252Karnataka n_f 1 t_s 5 n_layers 2 8 Error 0.2120825 0.25413262472802783 -0.15899859205429379\n",
            "Epoch: 0/25  Loss: 0.244736 Test loss: 0.529144Karnataka n_f 1 t_s 5 n_layers 2 16 Error 0.18399455 0.2152057718701239 0.1688682032315304\n",
            "Epoch: 0/25  Loss: 0.177777 Test loss: 0.412157Karnataka n_f 1 t_s 5 n_layers 2 32 Error 0.15552166 0.1895805697099937 0.35501482103919313\n",
            "(384, 7, 1)\n",
            "(384, 7, 1) (384, 1)\n",
            "Epoch: 0/25  Loss: 0.333506 Test loss: 0.215117Karnataka n_f 1 t_s 7 n_layers 1 1 Error 0.5585875 0.6129370774510466 -5.991278959051059\n",
            "Epoch: 0/25  Loss: 0.447097 Test loss: 1.112962Karnataka n_f 1 t_s 7 n_layers 1 5 Error 0.65711236 0.7004157960180181 -8.12928335584743\n",
            "Epoch: 0/25  Loss: 0.147450 Test loss: 0.247700Karnataka n_f 1 t_s 7 n_layers 1 8 Error 0.35294306 0.41814217579208607 -2.253664666309104\n",
            "Epoch: 0/25  Loss: 0.194400 Test loss: 0.467280Karnataka n_f 1 t_s 7 n_layers 1 16 Error 0.13279061 0.15337395185316072 0.5622480942075434\n",
            "Epoch: 0/25  Loss: 0.134435 Test loss: 0.414665"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9b9c3656ac35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0;31m#gru_optim = optim.SGD(GRUNet_model.parameters(), lr=1e-3, momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[0mgru_optim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRUNet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m           \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRUNet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_optim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m           \u001b[0;31m#print(f'\\nTraining took {end-start}s!')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0;31m#plot_loss(max_epochs,train_losses,test_losses,model_name='CNN for '+state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/nbs/model_fit_code.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, optimizer, criterion, data, max_epochs, cuda)\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVk9L_HRM_5c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}