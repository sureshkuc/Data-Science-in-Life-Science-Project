{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import numpy as np  \n",
    "from datetime import date, timedelta\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "#from github import Github\n",
    "#import github\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# Import tensor dataset & data loader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# Import nn.functional\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from typing import Union, Tuple\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "import math\n",
    "import random\n",
    "import imageio\n",
    "#from sklearn.metrics import mean_absolute_percentage_error\n",
    "matplotlib.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "#random.seed(42)\n",
    "#torch.manual_seed(42)\n",
    "#np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1, response_variable_index=0, number_feature = 6):\n",
    "  dataX, dataY = [], []\n",
    "  for i in range(len(dataset)-look_back-1):\n",
    "    a = dataset[i:(i+look_back),:number_feature]\n",
    "    dataX.append(a)\n",
    "    dataY.append(dataset[i + look_back, response_variable_index])\n",
    "  return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(df, scaling_range=(0,1),time_step=5,number_feature=6, response_variable_index=3,data_split_ratio=0.8,Suffle=True):\n",
    "    df = df.astype('float32')\n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=scaling_range)\n",
    "    dataset = scaler.fit_transform(df.copy())\n",
    "    X, Y = create_dataset(dataset, time_step,response_variable_index=response_variable_index, number_feature=number_feature)\n",
    "    # split into train and test sets\n",
    "    train_size = int(len(dataset) * data_split_ratio)\n",
    "    test_size = len(dataset) - train_size\n",
    "    trainX, testX = X[0:train_size,:], X[train_size:len(dataset),:]\n",
    "    trainY, testY = Y[0:train_size], Y[train_size:len(dataset)]\n",
    "    print(trainX.shape)\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    if not multi_feature:\n",
    "      trainX = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "      testX = np.reshape(testX, (testX.shape[0], testX.shape[1],1))\n",
    "    #print(trainX.shape)\n",
    "    X_train=trainX\n",
    "    X_test=testX\n",
    "    y_train=trainY.reshape(-1,1)\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    # summarize the data\n",
    "    inputs = torch.from_numpy(X_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "    # Define dataset\n",
    "    train_ds = TensorDataset(inputs, targets)\n",
    "\n",
    "    batch_size = 16\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=Suffle)\n",
    "\n",
    "    y_test=testY.reshape(-1,1)\n",
    "\n",
    "    inputs = torch.from_numpy(X_test)\n",
    "    targets = torch.from_numpy(y_test)\n",
    "    # Define dataset\n",
    "    #test_ds = TensorDataset(inputs, targets)\n",
    "    test_ds=(inputs, targets)\n",
    "    #test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_ds,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
