{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSiLS-Sw-Project(India-Dataset-short-data).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP6jH3fBr8Os",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abc42d0-ea4e-4465-a93c-72901f32d8f9"
      },
      "source": [
        "!pip install PyGithub\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "import numpy as np  \n",
        "from datetime import date, timedelta\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "from github import Github\n",
        "import github\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# Import tensor dataset & data loader\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "# Import nn.functional\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from typing import Union, Tuple\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statistics import mean\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
        "import math\n",
        "import random\n",
        "import imageio\n",
        "import pickle as pkl\n",
        "#from sklearn.metrics import mean_absolute_percentage_error\n",
        "matplotlib.style.use('seaborn')\n",
        "%matplotlib inline\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyGithub\n",
            "  Downloading PyGithub-1.55-py3-none-any.whl (291 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 40 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 194 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 204 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 215 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 225 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 235 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 245 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 256 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 266 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 276 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 286 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 291 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pyjwt>=2.0\n",
            "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.7/dist-packages (from PyGithub) (2.23.0)\n",
            "Collecting deprecated\n",
            "  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n",
            "Collecting pynacl>=1.4.0\n",
            "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
            "\u001b[K     |████████████████████████████████| 961 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pynacl>=1.4.0->PyGithub) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pynacl>=1.4.0->PyGithub) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (3.0.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->PyGithub) (1.12.1)\n",
            "Installing collected packages: pynacl, pyjwt, deprecated, PyGithub\n",
            "Successfully installed PyGithub-1.55 deprecated-1.2.12 pyjwt-2.1.0 pynacl-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bdQT_iITNZX"
      },
      "source": [
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1, response_variable_index=0, number_feature = 6):\n",
        "  dataX, dataY = [], []\n",
        "  for i in range(len(dataset)-look_back-1):\n",
        "    a = dataset[i:(i+look_back),:number_feature]\n",
        "    dataX.append(a)\n",
        "    dataY.append(dataset[i + look_back, response_variable_index])\n",
        "  return np.array(dataX), np.array(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOmVWeHjTjpv"
      },
      "source": [
        "def data_preparation(df, scaling_range=(0,1),time_step=5,number_feature=6, response_variable_index=3,data_split_ratio=0.8,Suffle=True,Eval=False):\n",
        "    df = df.astype('float32')\n",
        "    # normalize the dataset\n",
        "    scaler = MinMaxScaler(feature_range=scaling_range)\n",
        "    dataset = scaler.fit_transform(df.copy())\n",
        "    X, Y = create_dataset(dataset, time_step,response_variable_index=response_variable_index, number_feature=number_feature)\n",
        "    # split into train and test sets\n",
        "    train_size = int(len(dataset) * data_split_ratio)\n",
        "    test_size = len(dataset) - train_size\n",
        "    trainX, testX = X[0:train_size,:], X[train_size:len(dataset),:]\n",
        "    trainY, testY = Y[0:train_size], Y[train_size:len(dataset)]\n",
        "    \n",
        "    print(trainX.shape)\n",
        "    # reshape input to be [samples, time steps, features]\n",
        "    if not multi_feature:\n",
        "      trainX = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
        "      testX = np.reshape(testX, (testX.shape[0], testX.shape[1],1))\n",
        "    #print(trainX.shape)\n",
        "    X_train=trainX\n",
        "    X_test=testX\n",
        "    y_train=trainY.reshape(-1,1)\n",
        "\n",
        "    print(X_train.shape, y_train.shape)\n",
        "    # summarize the data\n",
        "    inputs = torch.from_numpy(X_train)\n",
        "    targets = torch.from_numpy(y_train)\n",
        "    # Define dataset\n",
        "    train_ds = TensorDataset(inputs, targets)\n",
        "\n",
        "    batch_size = 16\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=Suffle)\n",
        "\n",
        "    y_test=testY.reshape(-1,1)\n",
        "    \n",
        "    inputs = torch.from_numpy(X_test)\n",
        "    targets = torch.from_numpy(y_test)\n",
        "    # Define dataset\n",
        "    #test_ds = TensorDataset(inputs, targets)\n",
        "    test_ds=(inputs, targets)\n",
        "    if Eval:\n",
        "      return (torch.from_numpy(X_train),trainY),test_ds,scaler\n",
        "    #test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, test_ds,scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIBilDqnGJb6"
      },
      "source": [
        "def fit(\n",
        "    model: nn.Module, \n",
        "    optimizer: optim.Optimizer, criterion: nn,\n",
        "    data: Union[DataLoader, Tuple[DataLoader]], \n",
        "    max_epochs: int, \n",
        "    cuda=True):\n",
        "  use_test = False\n",
        "  if isinstance(data, DataLoader):\n",
        "    train_loader = data\n",
        "  elif isinstance(data, tuple):\n",
        "    if len(data) == 2:\n",
        "      train_loader, test_loader = data\n",
        "      if not isinstance(train_loader, DataLoader):\n",
        "        raise TypeError(f'Expected 1st entry of type DataLoader, but got {type(train_loader)}!')\n",
        "      #if not isinstance(test_loader, DataLoader):\n",
        "       # raise TypeError(f'Expected 2nd entry of type DataLoader, but got {type(test_loader)}!')\n",
        "      use_test = True\n",
        "    else:\n",
        "      raise ValueError(f'Expected tuple of length 2, but got {len(data)}!')\n",
        "  \n",
        "  \n",
        "  #criterion = nn.L1Loss()\n",
        "  model.train()\n",
        "  losses = []\n",
        "  test_losses=[]\n",
        "  batch_total = len(train_loader)\n",
        "  best_model=None\n",
        "  min_loss=np.iinfo(0).max\n",
        "  for epoch in range(max_epochs):\n",
        "    #random.seed(42)\n",
        "    #torch.manual_seed(42)\n",
        "    #np.random.seed(42)\n",
        "    running_loss=[]\n",
        "    test_loss=[]\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "      x, y = batch\n",
        "      if cuda:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "      output = model(x)\n",
        "      loss = criterion(output, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      running_loss.append(loss.item())\n",
        "      #rmse += torch.sqrt(criterion(yhat, y))\n",
        "      #losses.append(loss.item())\n",
        "      \n",
        "    if use_test:\n",
        "      model.eval()\n",
        "      test_x, test_y =test_loader\n",
        "      if cuda:\n",
        "        test_x, test_y = test_x.cuda(), test_y.cuda()\n",
        "      test_output = model(test_x)\n",
        "      loss = criterion(test_output, test_y)\n",
        "      test_loss.append(loss.item())\n",
        "      #test_mae = criterion(test_output, test_y)\n",
        "      test_x\n",
        "      #predictions = scaler.inverse_transform(test_output.cpu().detach().numpy())\n",
        "      #test_y = scaler.inverse_transform(test_y.cpu().detach().numpy())\n",
        "      epoch_loss = mean_squared_error(test_y.cpu().detach().numpy(),test_output.cpu().detach().numpy())\n",
        "      if epoch_loss<min_loss:\n",
        "        min_loss = epoch_loss\n",
        "        best_model= model.state_dict()\n",
        "      test_losses.append(loss.item())\n",
        "      model.train()\n",
        "      if epoch%50==0:\n",
        "        sys.stdout.write(f'\\rEpoch: {epoch}/{max_epochs}  Loss: {mean(running_loss):.6f} Test loss: {epoch_loss:.6f}')\n",
        "    else:\n",
        "      sys.stdout.write(f'\\rEpoch: {epoch}/{max_epochs}  Loss: {running_loss:.6f}' )\n",
        "    epoch_loss =mean(running_loss)\n",
        "    losses.append(epoch_loss)\n",
        "  return (losses, test_losses, best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dKvE8Fzxee0"
      },
      "source": [
        "def predict(model: nn.Module, data: DataLoader, cuda=True):\n",
        "  predictions=None\n",
        "  model.eval()\n",
        "  for id,(x, y) in enumerate(data):\n",
        "      if id==0:\n",
        "        predictions=model(x)\n",
        "      else:\n",
        "        output = model(x)\n",
        "        predictions=torch.vstack((predictions,output))\n",
        "  return predictions\n",
        "def plot_predictions(model, data_loader):\n",
        "  \n",
        "  predictions=predict(model, data_loader)\n",
        "\n",
        "  train_y = y_train\n",
        "\n",
        "  test_y=y_test\n",
        "  predictions=predictions.cpu()\n",
        "  plt.plot(range(len(train_y)),train_y, label='train data')\n",
        "  plt.plot(np.arange(len(train_y),len(train_y)+len(test_y),1),test_y,label='Acutal')\n",
        "  plt.plot(np.arange(len(train_y),len(train_y)+len(test_y),1),predictions.detach().numpy(),label='predictions')\n",
        "  plt.legend()\n",
        "  \n",
        "def plot_loss(epochs,train_losses,test_losses,model_name):\n",
        "  plt.rcParams['figure.figsize'] = [10, 5]\n",
        "  plt.rcParams['figure.dpi'] = 100\n",
        "  plt.plot(range(epochs),train_losses, label='train loss')\n",
        "  plt.plot(range(epochs),test_losses,label='test loss')\n",
        "  plt.title(model_name)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz1lccWM4Kzz"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        return x\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "  def __init__(self, time_step,n_layers,vector_length,kernel_size):\n",
        "    super(CNNModel, self).__init__()\n",
        "    self.time_step=time_step\n",
        "    self.n_layers=n_layers\n",
        "    in_channels=1\n",
        "    out_channels=16\n",
        "    layers=[]\n",
        "    dimension=vector_length\n",
        "    for l in range(self.n_layers):\n",
        "        cnn_1d_layer=nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=\"same\")\n",
        "        #dimension=dimension-kernel_size+2*1+1\n",
        "        #if dimension>1:\n",
        "        layers.append(cnn_1d_layer)\n",
        "        if l%2==0:\n",
        "          layers.append(nn.Tanh())\n",
        "        else:\n",
        "          layers.append(nn.ELU(inplace=True))\n",
        "        in_channels=out_channels\n",
        "        out_channels=out_channels*2\n",
        "    layers.append(Flatten())\n",
        "    layers.append(nn.Dropout(p=0.2))\n",
        "    self.body = nn.Sequential(*layers)\n",
        "    #print('dm',dimension,out_channels)\n",
        "    out=int(vector_length*(out_channels/2))\n",
        "    self.head=nn.Linear(out, 1)\n",
        "  def forward(self, x):\n",
        "    b, features, look_back = x.shape\n",
        "    #print(b,n_steps, features)\n",
        "    x = x.reshape([b,1,features*look_back])\n",
        "    y = self.body(x)\n",
        "    #print(y.shape)\n",
        "    #print('re',y.view(len(y),-1).shape)\n",
        "    return self.head(y.view(len(y),-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnRSVoMBWckj",
        "outputId": "a153f736-0e5b-45a2-94e1-ee8b709134cf"
      },
      "source": [
        "Shortlisted_States=['Karnataka','Maharashtra','Uttar-Pradesh','Kerala','Tamil-Nadu']#'Delhi'\n",
        "results_cnn=[]\n",
        "cnn_models=[]\n",
        "for state in Shortlisted_States:\n",
        "  best_models=[]\n",
        "  df=pd.read_csv(\"https://raw.githubusercontent.com/sureshkuc/Data-Science-in-Life-Science-Project/main/Indian-States-Covid19-Datasets/\"+state+\".csv\", parse_dates=[\"Date\"]).drop(columns =[\"Unnamed: 0\"])\n",
        "  df_temp1 = df[df[\"Date\"] <= \"2020-06-18\"]\n",
        "  df_temp2=  df[df[\"Date\"] > \"2020-03-09\"]\n",
        "  df = pd.merge(df_temp1, df_temp2, how='inner')\n",
        "  df = df.set_index(\"Date\")\n",
        "  df = df[['Confirmed', 'Recovered', 'Deceased', 'New_Confirmerd', 'New_Deaths', 'New_Recovered']]\n",
        "  #print(df.describe())\n",
        "\n",
        "  time_step=[5,7]\n",
        "  Number_of_feature=[1,2,3,4,5,6]\n",
        "  multi_feature=True\n",
        "  min_error=np.iinfo(0).max\n",
        "  cnn_best_model={}\n",
        "  temp_result=[]\n",
        "  for n_f in Number_of_feature:\n",
        "    for t_s in time_step:\n",
        "      train_loader, test_loader,scaler = data_preparation(df, scaling_range=(0,1),time_step=t_s,number_feature=n_f, response_variable_index=0,data_split_ratio=0.8)\n",
        "      for n_layers in range(2,5,1):\n",
        "        for kernel_size in range(1,5,1):\n",
        "          \n",
        "          max_epochs=10\n",
        "          #random.seed(42)\n",
        "          #torch.manual_seed(42)\n",
        "          #np.random.seed(42)\n",
        "          #CNN model with L1 loss\n",
        "          #best_model=Call_CNN_model(state,dataset=(train_loader, test_loader), lr=1e-2,criterion=nn.L1Loss(),max_epochs=max_epochs)\n",
        "          CNN_model =  CNNModel(t_s,n_layers,t_s*n_f,kernel_size)\n",
        "          cuda=torch.cuda.is_available()\n",
        "          if cuda:\n",
        "            CNN_model = CNN_model.cuda()\n",
        "          optimizer = optim.SGD(CNN_model.parameters(), lr=1e-2, momentum=0.9)\n",
        "          train_losses,test_losses, best_model = fit(CNN_model, optimizer, nn.L1Loss(),(train_loader, test_loader), max_epochs=max_epochs,cuda=cuda)\n",
        "          end = time.time()\n",
        "          #print(f'\\nTraining took {end-start}s!')\n",
        "          #plot_loss(max_epochs,train_losses,test_losses,model_name='CNN for '+state)\n",
        "          CNN_model =  CNNModel(t_s,n_layers,t_s*n_f,kernel_size)\n",
        "          CNN_model.load_state_dict(best_model)\n",
        "          CNN_model.eval()\n",
        "          test_x,test_y=test_loader\n",
        "          predictions=CNN_model(test_x)\n",
        "          test_y=test_y.cpu().detach().numpy()\n",
        "          predictions=predictions.cpu().detach().numpy()\n",
        "          #predictions = scaler.inverse_transform(predictions)\n",
        "          #target = scaler.inverse_transform(target)\n",
        "          mae=mean_absolute_error(test_y,predictions)\n",
        "          rmse=math.sqrt(mean_squared_error(test_y,predictions))\n",
        "          #rmse=math.sqrt(mean_squared_error(test_y,predictions))\n",
        "          r2s=r2_score(test_y,predictions)\n",
        "          if rmse<min_error:\n",
        "            min_error=rmse\n",
        "            cnn_best_model=best_model\n",
        "            temp_result=[state,n_f,t_s,n_layers,kernel_size,mae,rmse,r2s]\n",
        "            \n",
        "          #mape=mean_absolute_percentage_error(test_y,predictions)\n",
        "          \n",
        "          \n",
        "          print(state,'n_f',n_f,'t_s',t_s,'n_layers',n_layers,'kernel_size',kernel_size,mae,rmse,r2s)\n",
        "          results_cnn.append([state,n_f,t_s,n_layers,kernel_size,mae,rmse,r2s])\n",
        "      #CNN_model =  CNNModel(t_s,n_layers,t_s*n_f,kernel_size)\n",
        "      #CNN_model.load_state_dict(best_model)\n",
        "  \n",
        "  cnn_models.append(cnn_best_model) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.127348 Test loss: 0.863917Karnataka n_f 1 t_s 5 n_layers 2 kernel_size 1 0.17734042 0.17996508469966746 -0.7292414583522189\n",
            "Epoch: 0/10  Loss: 0.117509 Test loss: 0.389513Karnataka n_f 1 t_s 5 n_layers 2 kernel_size 2 0.14837871 0.1497894694669421 -0.19795807393314813\n",
            "Epoch: 0/10  Loss: 0.123983 Test loss: 0.443245Karnataka n_f 1 t_s 5 n_layers 2 kernel_size 3 0.070157796 0.0725351764324143 0.7190840375287999\n",
            "Epoch: 0/10  Loss: 0.095834 Test loss: 0.311133Karnataka n_f 1 t_s 5 n_layers 2 kernel_size 4 0.1280842 0.13198537480998615 0.06989773102133201\n",
            "Epoch: 0/10  Loss: 0.193368 Test loss: 0.313259Karnataka n_f 1 t_s 5 n_layers 3 kernel_size 1 0.23457934 0.23736128112608187 -2.008145431361298\n",
            "Epoch: 0/10  Loss: 0.101198 Test loss: 0.524054Karnataka n_f 1 t_s 5 n_layers 3 kernel_size 2 0.029290915 0.03435863754325443 0.9369694688784052\n",
            "Epoch: 0/10  Loss: 0.070367 Test loss: 0.392736Karnataka n_f 1 t_s 5 n_layers 3 kernel_size 3 0.16256519 0.1642425661574864 -0.4402919191708565\n",
            "Epoch: 0/10  Loss: 0.080086 Test loss: 0.490005Karnataka n_f 1 t_s 5 n_layers 3 kernel_size 4 0.05314471 0.05997299669504919 0.8079604778164249\n",
            "Epoch: 0/10  Loss: 0.108287 Test loss: 0.666595Karnataka n_f 1 t_s 5 n_layers 4 kernel_size 1 0.055743933 0.06146673208099157 0.7982752023921101\n",
            "Epoch: 0/10  Loss: 0.079197 Test loss: 0.389357Karnataka n_f 1 t_s 5 n_layers 4 kernel_size 2 0.11961606 0.12832110708098102 0.12082512204360152\n",
            "Epoch: 0/10  Loss: 0.128488 Test loss: 0.311978Karnataka n_f 1 t_s 5 n_layers 4 kernel_size 3 0.04753299 0.05662794217803858 0.8287854388489209\n",
            "Epoch: 0/10  Loss: 0.075225 Test loss: 0.452564Karnataka n_f 1 t_s 5 n_layers 4 kernel_size 4 0.08731465 0.09367954567147797 0.5314363120320764\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.163250 Test loss: 0.515479Karnataka n_f 1 t_s 7 n_layers 2 kernel_size 1 0.112222895 0.11649855515884648 -0.14024974190082662\n",
            "Epoch: 0/10  Loss: 0.141226 Test loss: 0.572530Karnataka n_f 1 t_s 7 n_layers 2 kernel_size 2 0.11411928 0.11587963643463636 -0.128166297348566\n",
            "Epoch: 0/10  Loss: 0.138214 Test loss: 0.647259Karnataka n_f 1 t_s 7 n_layers 2 kernel_size 3 0.060528096 0.06818744632695234 0.6093680722170987\n",
            "Epoch: 0/10  Loss: 0.141633 Test loss: 0.225728Karnataka n_f 1 t_s 7 n_layers 2 kernel_size 4 0.036780015 0.04689868934385162 0.8152092061214545\n",
            "Epoch: 0/10  Loss: 0.112749 Test loss: 0.585584Karnataka n_f 1 t_s 7 n_layers 3 kernel_size 1 0.18716922 0.18815711230524076 -1.9744055784059817\n",
            "Epoch: 0/10  Loss: 0.094351 Test loss: 0.519002Karnataka n_f 1 t_s 7 n_layers 3 kernel_size 2 0.17192881 0.17339986379904332 -1.526134079371475\n",
            "Epoch: 0/10  Loss: 0.103774 Test loss: 0.478208Karnataka n_f 1 t_s 7 n_layers 3 kernel_size 3 0.026205521 0.030614186912395383 0.9212583771517165\n",
            "Epoch: 0/10  Loss: 0.084081 Test loss: 0.384997Karnataka n_f 1 t_s 7 n_layers 3 kernel_size 4 0.02445082 0.0285947925883703 0.931303788130565\n",
            "Epoch: 0/10  Loss: 0.106104 Test loss: 0.526247Karnataka n_f 1 t_s 7 n_layers 4 kernel_size 1 0.11086629 0.11756162527662413 -0.16115460726936548\n",
            "Epoch: 0/10  Loss: 0.105299 Test loss: 0.546577Karnataka n_f 1 t_s 7 n_layers 4 kernel_size 2 0.12152039 0.12340859575715529 -0.27952775224483384\n",
            "Epoch: 0/10  Loss: 0.103477 Test loss: 0.472564Karnataka n_f 1 t_s 7 n_layers 4 kernel_size 3 0.03744626 0.043508582131655725 0.840959132465753\n",
            "Epoch: 0/10  Loss: 0.118359 Test loss: 0.320572Karnataka n_f 1 t_s 7 n_layers 4 kernel_size 4 0.11883964 0.12019167893043528 -0.2136897893389067\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.173914 Test loss: 0.653706Karnataka n_f 2 t_s 5 n_layers 2 kernel_size 1 0.16868527 0.16959436687591362 -0.5356841853325334\n",
            "Epoch: 0/10  Loss: 0.215383 Test loss: 0.278151Karnataka n_f 2 t_s 5 n_layers 2 kernel_size 2 0.08705261 0.08920788171814378 0.5751011054168872\n",
            "Epoch: 0/10  Loss: 0.111974 Test loss: 0.403251Karnataka n_f 2 t_s 5 n_layers 2 kernel_size 3 0.069095895 0.07088269395186615 0.7317377984196329\n",
            "Epoch: 0/10  Loss: 0.092831 Test loss: 0.522187Karnataka n_f 2 t_s 5 n_layers 2 kernel_size 4 0.09690737 0.10259901746264083 0.43796220234112304\n",
            "Epoch: 0/10  Loss: 0.097058 Test loss: 0.268101Karnataka n_f 2 t_s 5 n_layers 3 kernel_size 1 0.19066778 0.19536610821303665 -1.0378750683271716\n",
            "Epoch: 0/10  Loss: 0.111195 Test loss: 0.402519Karnataka n_f 2 t_s 5 n_layers 3 kernel_size 2 0.039052 0.04435132343670626 0.8949751117177175\n",
            "Epoch: 0/10  Loss: 0.094319 Test loss: 0.555864Karnataka n_f 2 t_s 5 n_layers 3 kernel_size 3 0.3272006 0.33190972965443244 -4.881918844335923\n",
            "Epoch: 0/10  Loss: 0.079376 Test loss: 0.396028Karnataka n_f 2 t_s 5 n_layers 3 kernel_size 4 0.030103413 0.03449335415715056 0.9364742224312269\n",
            "Epoch: 0/10  Loss: 0.089082 Test loss: 0.463863Karnataka n_f 2 t_s 5 n_layers 4 kernel_size 1 0.27566323 0.2774477615890705 -3.1099972670391267\n",
            "Epoch: 0/10  Loss: 0.087628 Test loss: 0.509947Karnataka n_f 2 t_s 5 n_layers 4 kernel_size 2 0.040344432 0.04316287459814528 0.9005282396502622\n",
            "Epoch: 0/10  Loss: 0.105022 Test loss: 0.571282Karnataka n_f 2 t_s 5 n_layers 4 kernel_size 3 0.30742154 0.3084070268513548 -4.078408721544452\n",
            "Epoch: 0/10  Loss: 0.087282 Test loss: 0.558858Karnataka n_f 2 t_s 5 n_layers 4 kernel_size 4 0.12135382 0.12290791203213816 0.19343613767056633\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.195312 Test loss: 0.591608Karnataka n_f 2 t_s 7 n_layers 2 kernel_size 1 0.0678879 0.07593978160699692 0.5154957544757046\n",
            "Epoch: 0/10  Loss: 0.115939 Test loss: 0.555896Karnataka n_f 2 t_s 7 n_layers 2 kernel_size 2 0.0911455 0.09216005939288893 0.2864170976681959\n",
            "Epoch: 0/10  Loss: 0.106207 Test loss: 0.463164Karnataka n_f 2 t_s 7 n_layers 2 kernel_size 3 0.19689688 0.19767154815335625 -2.282821096632919\n",
            "Epoch: 0/10  Loss: 0.158768 Test loss: 0.439673Karnataka n_f 2 t_s 7 n_layers 2 kernel_size 4 0.14914598 0.15038964655173923 -0.9001800340874437\n",
            "Epoch: 0/10  Loss: 0.106780 Test loss: 0.656343Karnataka n_f 2 t_s 7 n_layers 3 kernel_size 1 0.055888478 0.07529322331010706 0.5237108075500195\n",
            "Epoch: 0/10  Loss: 0.094889 Test loss: 0.659531Karnataka n_f 2 t_s 7 n_layers 3 kernel_size 2 0.19759607 0.2050525558517266 -2.5325576882432292\n",
            "Epoch: 0/10  Loss: 0.108532 Test loss: 0.426340Karnataka n_f 2 t_s 7 n_layers 3 kernel_size 3 0.32801083 0.33251642794288283 -8.28934510169059\n",
            "Epoch: 0/10  Loss: 0.094472 Test loss: 0.360720Karnataka n_f 2 t_s 7 n_layers 3 kernel_size 4 0.048603673 0.05416838095127071 0.7534808743579602\n",
            "Epoch: 0/10  Loss: 0.121705 Test loss: 0.452507Karnataka n_f 2 t_s 7 n_layers 4 kernel_size 1 0.43358648 0.43744558609041384 -15.077072694987745\n",
            "Epoch: 0/10  Loss: 0.146447 Test loss: 0.696511Karnataka n_f 2 t_s 7 n_layers 4 kernel_size 2 0.31092352 0.31608697300357613 -7.394060410648169\n",
            "Epoch: 0/10  Loss: 0.134521 Test loss: 0.608415Karnataka n_f 2 t_s 7 n_layers 4 kernel_size 3 0.4431597 0.4481489462685915 -15.873440032503733\n",
            "Epoch: 0/10  Loss: 0.099544 Test loss: 0.530674Karnataka n_f 2 t_s 7 n_layers 4 kernel_size 4 0.37969005 0.3884700270189812 -11.678676079905571\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.202913 Test loss: 0.076759Karnataka n_f 3 t_s 5 n_layers 2 kernel_size 1 0.2225306 0.22528869896039336 -1.7099291262042966\n",
            "Epoch: 0/10  Loss: 0.120174 Test loss: 0.508221Karnataka n_f 3 t_s 5 n_layers 2 kernel_size 2 0.31304702 0.3193191967230397 -4.44413888610938\n",
            "Epoch: 0/10  Loss: 0.139772 Test loss: 0.587573Karnataka n_f 3 t_s 5 n_layers 2 kernel_size 3 0.2774344 0.2828081336132215 -3.2703443721426826\n",
            "Epoch: 0/10  Loss: 0.149985 Test loss: 0.443643Karnataka n_f 3 t_s 5 n_layers 2 kernel_size 4 0.17356881 0.17668728975904902 -0.6668237341329148\n",
            "Epoch: 0/10  Loss: 0.221961 Test loss: 1.216851Karnataka n_f 3 t_s 5 n_layers 3 kernel_size 1 0.4619399 0.4711209891875508 -10.850699981644333\n",
            "Epoch: 0/10  Loss: 0.183336 Test loss: 0.344578Karnataka n_f 3 t_s 5 n_layers 3 kernel_size 2 0.27796564 0.2829760726495198 -3.2754173949155216\n",
            "Epoch: 0/10  Loss: 0.104135 Test loss: 0.477012Karnataka n_f 3 t_s 5 n_layers 3 kernel_size 3 0.32019886 0.33045830360657447 -4.830589132521847\n",
            "Epoch: 0/10  Loss: 0.107285 Test loss: 0.550985Karnataka n_f 3 t_s 5 n_layers 3 kernel_size 4 0.2583793 0.2640877728528926 -2.7237084826638283\n",
            "Epoch: 0/10  Loss: 0.160410 Test loss: 0.263455Karnataka n_f 3 t_s 5 n_layers 4 kernel_size 1 0.28076085 0.28664455285322227 -3.3869880206220015\n",
            "Epoch: 0/10  Loss: 0.123918 Test loss: 0.517963Karnataka n_f 3 t_s 5 n_layers 4 kernel_size 2 0.27321377 0.2819752745940458 -3.245229052706783\n",
            "Epoch: 0/10  Loss: 0.092353 Test loss: 0.483372Karnataka n_f 3 t_s 5 n_layers 4 kernel_size 3 0.4711495 0.48261363739474045 -11.43593143744888\n",
            "Epoch: 0/10  Loss: 0.092165 Test loss: 0.466790Karnataka n_f 3 t_s 5 n_layers 4 kernel_size 4 0.35784036 0.3636151696728962 -6.059323330680037\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.092974 Test loss: 0.360964Karnataka n_f 3 t_s 7 n_layers 2 kernel_size 1 0.18186627 0.1831221000747731 -1.8173474703880368\n",
            "Epoch: 0/10  Loss: 0.218798 Test loss: 0.947613Karnataka n_f 3 t_s 7 n_layers 2 kernel_size 2 0.37742063 0.38195469173017216 -11.2569562314368\n",
            "Epoch: 0/10  Loss: 0.210050 Test loss: 1.085747Karnataka n_f 3 t_s 7 n_layers 2 kernel_size 3 0.29694334 0.3030069539189638 -6.7137240041082675\n",
            "Epoch: 0/10  Loss: 0.179013 Test loss: 0.736048Karnataka n_f 3 t_s 7 n_layers 2 kernel_size 4 0.113513835 0.11456522789515342 -0.10271815122848893\n",
            "Epoch: 0/10  Loss: 0.257427 Test loss: 0.156775Karnataka n_f 3 t_s 7 n_layers 3 kernel_size 1 0.28817832 0.29031456600640776 -6.081031196841064\n",
            "Epoch: 0/10  Loss: 0.121159 Test loss: 0.352308Karnataka n_f 3 t_s 7 n_layers 3 kernel_size 2 1.0627977 1.0777973838270398 -96.59625581154657\n",
            "Epoch: 0/10  Loss: 0.152214 Test loss: 0.299309Karnataka n_f 3 t_s 7 n_layers 3 kernel_size 3 0.27187902 0.27504647848357167 -5.355812532737355\n",
            "Epoch: 0/10  Loss: 0.091578 Test loss: 0.312595Karnataka n_f 3 t_s 7 n_layers 3 kernel_size 4 0.20551363 0.20766567693916363 -2.62316695316125\n",
            "Epoch: 0/10  Loss: 0.157015 Test loss: 0.667910Karnataka n_f 3 t_s 7 n_layers 4 kernel_size 1 0.19458152 0.1949394191422433 -2.1927008175536744\n",
            "Epoch: 0/10  Loss: 0.143336 Test loss: 0.567940Karnataka n_f 3 t_s 7 n_layers 4 kernel_size 2 0.2798308 0.28305549720058104 -5.731348167698876\n",
            "Epoch: 0/10  Loss: 0.135025 Test loss: 0.633746Karnataka n_f 3 t_s 7 n_layers 4 kernel_size 3 0.43982813 0.4489013213787656 -15.930144381313166\n",
            "Epoch: 0/10  Loss: 0.125836 Test loss: 0.516248Karnataka n_f 3 t_s 7 n_layers 4 kernel_size 4 0.3399485 0.34402724486473024 -8.943621154753405\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.134946 Test loss: 0.165117Karnataka n_f 4 t_s 5 n_layers 2 kernel_size 1 0.23266344 0.2611174151632432 -2.64041376154308\n",
            "Epoch: 0/10  Loss: 0.108794 Test loss: 0.675788Karnataka n_f 4 t_s 5 n_layers 2 kernel_size 2 0.31241813 0.32625141430325355 -4.683081504791225\n",
            "Epoch: 0/10  Loss: 0.318033 Test loss: 0.408985Karnataka n_f 4 t_s 5 n_layers 2 kernel_size 3 0.1680806 0.19782763390103125 -1.0895512488289008\n",
            "Epoch: 0/10  Loss: 0.130534 Test loss: 0.503835Karnataka n_f 4 t_s 5 n_layers 2 kernel_size 4 0.30620387 0.35136953992411324 -5.591850135518111\n",
            "Epoch: 0/10  Loss: 0.250657 Test loss: 0.026145Karnataka n_f 4 t_s 5 n_layers 3 kernel_size 1 0.26534298 0.27663737323425924 -3.086023028654056\n",
            "Epoch: 0/10  Loss: 0.171767 Test loss: 0.459222Karnataka n_f 4 t_s 5 n_layers 3 kernel_size 2 0.078221515 0.09625452168792215 0.5053233697818558\n",
            "Epoch: 0/10  Loss: 0.080223 Test loss: 0.426091Karnataka n_f 4 t_s 5 n_layers 3 kernel_size 3 0.3601267 0.3753844912660022 -6.523704220858071\n",
            "Epoch: 0/10  Loss: 0.086057 Test loss: 0.282055Karnataka n_f 4 t_s 5 n_layers 3 kernel_size 4 0.24966653 0.2652639993295459 -2.7569526528818353\n",
            "Epoch: 0/10  Loss: 0.123629 Test loss: 0.267396Karnataka n_f 4 t_s 5 n_layers 4 kernel_size 1 0.26439568 0.2774534545774458 -3.1101660387258647\n",
            "Epoch: 0/10  Loss: 0.085611 Test loss: 0.447774Karnataka n_f 4 t_s 5 n_layers 4 kernel_size 2 0.5579978 0.5755245645899811 -16.685070818555534\n",
            "Epoch: 0/10  Loss: 0.104490 Test loss: 0.496406Karnataka n_f 4 t_s 5 n_layers 4 kernel_size 3 0.21138932 0.22887566723458053 -1.7969090531518361\n",
            "Epoch: 0/10  Loss: 0.098042 Test loss: 0.426059Karnataka n_f 4 t_s 5 n_layers 4 kernel_size 4 0.24473502 0.27046102676956507 -2.905606176749906\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.170683 Test loss: 0.303689Karnataka n_f 4 t_s 7 n_layers 2 kernel_size 1 0.21593419 0.23407013456679637 -3.6031050469193326\n",
            "Epoch: 0/10  Loss: 0.118235 Test loss: 0.435932Karnataka n_f 4 t_s 7 n_layers 2 kernel_size 2 0.23460993 0.2701410637465345 -5.131124126660572\n",
            "Epoch: 0/10  Loss: 0.139299 Test loss: 0.413783Karnataka n_f 4 t_s 7 n_layers 2 kernel_size 3 0.28641546 0.31570961875439035 -7.374030096049017\n",
            "Epoch: 0/10  Loss: 0.085390 Test loss: 0.201394Karnataka n_f 4 t_s 7 n_layers 2 kernel_size 4 0.14053026 0.1813613323586866 -1.763428879743624\n",
            "Epoch: 0/10  Loss: 0.185662 Test loss: 0.241350Karnataka n_f 4 t_s 7 n_layers 3 kernel_size 1 0.40877146 0.4193140821087327 -13.771947979817933\n",
            "Epoch: 0/10  Loss: 0.115254 Test loss: 0.579470Karnataka n_f 4 t_s 7 n_layers 3 kernel_size 2 0.24838573 0.26849267416999373 -5.056528287262642\n",
            "Epoch: 0/10  Loss: 0.146924 Test loss: 0.499440Karnataka n_f 4 t_s 7 n_layers 3 kernel_size 3 0.5537742 0.5749316040078446 -26.770980770791024\n",
            "Epoch: 0/10  Loss: 0.120762 Test loss: 0.480583Karnataka n_f 4 t_s 7 n_layers 3 kernel_size 4 0.2432638 0.283642749914379 -5.759308719170387\n",
            "Epoch: 0/10  Loss: 0.253671 Test loss: 0.853006Karnataka n_f 4 t_s 7 n_layers 4 kernel_size 1 0.45130163 0.4664092749109372 -17.276509161306\n",
            "Epoch: 0/10  Loss: 0.173260 Test loss: 0.287578Karnataka n_f 4 t_s 7 n_layers 4 kernel_size 2 0.3606137 0.3719020473036659 -10.620265371175101\n",
            "Epoch: 0/10  Loss: 0.183150 Test loss: 0.839470Karnataka n_f 4 t_s 7 n_layers 4 kernel_size 3 0.42188114 0.4388283930134715 -15.178874295750106\n",
            "Epoch: 0/10  Loss: 0.128690 Test loss: 0.404274Karnataka n_f 4 t_s 7 n_layers 4 kernel_size 4 0.60691667 0.6209589494015594 -31.395500546907236\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.201835 Test loss: 1.231210Karnataka n_f 5 t_s 5 n_layers 2 kernel_size 1 0.16819613 0.18463126694858772 -0.8200760685011108\n",
            "Epoch: 0/10  Loss: 0.130371 Test loss: 0.132262Karnataka n_f 5 t_s 5 n_layers 2 kernel_size 2 0.18715757 0.21072181518341582 -1.3708171176778232\n",
            "Epoch: 0/10  Loss: 0.144637 Test loss: 0.235531Karnataka n_f 5 t_s 5 n_layers 2 kernel_size 3 0.22922774 0.2533569556493343 -2.427242021422997\n",
            "Epoch: 0/10  Loss: 0.117587 Test loss: 0.245209Karnataka n_f 5 t_s 5 n_layers 2 kernel_size 4 0.124961585 0.15612658156349038 -0.30146590683715724\n",
            "Epoch: 0/10  Loss: 0.362691 Test loss: 0.218368Karnataka n_f 5 t_s 5 n_layers 3 kernel_size 1 0.40760934 0.42966296386023395 -8.856777126764111\n",
            "Epoch: 0/10  Loss: 0.211085 Test loss: 0.182675Karnataka n_f 5 t_s 5 n_layers 3 kernel_size 2 0.2878036 0.31509742125340023 -4.301133999198822\n",
            "Epoch: 0/10  Loss: 0.132115 Test loss: 0.359173Karnataka n_f 5 t_s 5 n_layers 3 kernel_size 3 0.20571703 0.2299678904339391 -1.8236670049951784\n",
            "Epoch: 0/10  Loss: 0.125626 Test loss: 0.477421Karnataka n_f 5 t_s 5 n_layers 3 kernel_size 4 0.28996617 0.3193927329416409 -4.4466460030909305\n",
            "Epoch: 0/10  Loss: 0.333806 Test loss: 0.222398Karnataka n_f 5 t_s 5 n_layers 4 kernel_size 1 0.27617723 0.3062231416991728 -4.006740662314631\n",
            "Epoch: 0/10  Loss: 0.130133 Test loss: 0.261321Karnataka n_f 5 t_s 5 n_layers 4 kernel_size 2 0.19837491 0.22438236042531154 -1.6881685464045368\n",
            "Epoch: 0/10  Loss: 0.143168 Test loss: 0.706158Karnataka n_f 5 t_s 5 n_layers 4 kernel_size 3 0.3706311 0.39715669501995043 -7.421759857353008\n",
            "Epoch: 0/10  Loss: 0.093356 Test loss: 0.359296Karnataka n_f 5 t_s 5 n_layers 4 kernel_size 4 0.26771063 0.3048902106258087 -3.9632490686729813\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.399636 Test loss: 0.171249Karnataka n_f 5 t_s 7 n_layers 2 kernel_size 1 0.18362638 0.2182750825823037 -3.0028303539974432\n",
            "Epoch: 0/10  Loss: 0.156843 Test loss: 0.938043Karnataka n_f 5 t_s 7 n_layers 2 kernel_size 2 0.2503522 0.30603550775994554 -6.868691495346441\n",
            "Epoch: 0/10  Loss: 0.318677 Test loss: 0.194058Karnataka n_f 5 t_s 7 n_layers 2 kernel_size 3 0.12324341 0.16075633022716723 -1.1711759825538333\n",
            "Epoch: 0/10  Loss: 0.129907 Test loss: 0.222505Karnataka n_f 5 t_s 7 n_layers 2 kernel_size 4 0.33751562 0.38723941393371586 -11.59847599223924\n",
            "Epoch: 0/10  Loss: 0.568484 Test loss: 0.398475Karnataka n_f 5 t_s 7 n_layers 3 kernel_size 1 0.07845928 0.09680456227188317 0.21268129507510547\n",
            "Epoch: 0/10  Loss: 0.120473 Test loss: 0.147588Karnataka n_f 5 t_s 7 n_layers 3 kernel_size 2 0.35392332 0.3696704271748426 -10.481227344104735\n",
            "Epoch: 0/10  Loss: 0.236542 Test loss: 0.798850Karnataka n_f 5 t_s 7 n_layers 3 kernel_size 3 0.25417504 0.2902889267186336 -6.079780783575425\n",
            "Epoch: 0/10  Loss: 0.141197 Test loss: 0.478676Karnataka n_f 5 t_s 7 n_layers 3 kernel_size 4 0.26635665 0.3112536610537389 -7.13931440613443\n",
            "Epoch: 0/10  Loss: 0.657624 Test loss: 0.359349Karnataka n_f 5 t_s 7 n_layers 4 kernel_size 1 0.27580974 0.3027418443312106 -6.700231757961748\n",
            "Epoch: 0/10  Loss: 0.208956 Test loss: 0.171585Karnataka n_f 5 t_s 7 n_layers 4 kernel_size 2 0.34169823 0.36090731473926363 -9.943349132935168\n",
            "Epoch: 0/10  Loss: 0.178261 Test loss: 0.669132Karnataka n_f 5 t_s 7 n_layers 4 kernel_size 3 0.20828818 0.2412560223904921 -3.8900713703385073\n",
            "Epoch: 0/10  Loss: 0.140620 Test loss: 0.407963Karnataka n_f 5 t_s 7 n_layers 4 kernel_size 4 0.33082008 0.37686565352786244 -10.932516318281198\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.164715 Test loss: 0.416468Karnataka n_f 6 t_s 5 n_layers 2 kernel_size 1 0.37004384 0.39677540663392546 -7.4055976287627665\n",
            "Epoch: 0/10  Loss: 0.415217 Test loss: 0.211954Karnataka n_f 6 t_s 5 n_layers 2 kernel_size 2 0.15896098 0.2076230318353968 -1.301601540359262\n",
            "Epoch: 0/10  Loss: 0.120757 Test loss: 0.198385Karnataka n_f 6 t_s 5 n_layers 2 kernel_size 3 0.30805948 0.3346778629956454 -4.980438871425698\n",
            "Epoch: 0/10  Loss: 0.141671 Test loss: 0.418673Karnataka n_f 6 t_s 5 n_layers 2 kernel_size 4 0.42992154 0.4748069759990065 -11.036862189932686\n",
            "Epoch: 0/10  Loss: 0.188222 Test loss: 0.535144Karnataka n_f 6 t_s 5 n_layers 3 kernel_size 1 0.19907564 0.21463888978419876 -1.4597781146366535\n",
            "Epoch: 0/10  Loss: 0.122202 Test loss: 0.172561Karnataka n_f 6 t_s 5 n_layers 3 kernel_size 2 0.3443779 0.3671111169462406 -6.195718222483212\n",
            "Epoch: 0/10  Loss: 0.168498 Test loss: 0.660036Karnataka n_f 6 t_s 5 n_layers 3 kernel_size 3 0.4430888 0.4760990860142034 -11.102464335638116\n",
            "Epoch: 0/10  Loss: 0.140433 Test loss: 0.514676Karnataka n_f 6 t_s 5 n_layers 3 kernel_size 4 0.299362 0.33348369435707975 -4.937837050264882\n",
            "Epoch: 0/10  Loss: 0.243961 Test loss: 0.118604Karnataka n_f 6 t_s 5 n_layers 4 kernel_size 1 0.39879 0.42994694246597254 -8.869810719257325\n",
            "Epoch: 0/10  Loss: 0.219585 Test loss: 0.222970Karnataka n_f 6 t_s 5 n_layers 4 kernel_size 2 0.5232021 0.5428380740328322 -14.733296417496065\n",
            "Epoch: 0/10  Loss: 0.082605 Test loss: 0.298744Karnataka n_f 6 t_s 5 n_layers 4 kernel_size 3 0.40988368 0.4363367931901733 -9.16535913160761\n",
            "Epoch: 0/10  Loss: 0.156751 Test loss: 0.822724Karnataka n_f 6 t_s 5 n_layers 4 kernel_size 4 0.30449963 0.3289471498915298 -4.777385024340968\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.378941 Test loss: 0.175718Karnataka n_f 6 t_s 7 n_layers 2 kernel_size 1 0.17751493 0.2035666487829977 -2.4815464414163495\n",
            "Epoch: 0/10  Loss: 0.347418 Test loss: 0.010853Karnataka n_f 6 t_s 7 n_layers 2 kernel_size 2 0.38587886 0.41178085466782643 -13.245944296375457\n",
            "Epoch: 0/10  Loss: 0.365799 Test loss: 0.344016Karnataka n_f 6 t_s 7 n_layers 2 kernel_size 3 0.19666265 0.22876127195727458 -3.3966701384658275\n",
            "Epoch: 0/10  Loss: 0.118386 Test loss: 0.282635Karnataka n_f 6 t_s 7 n_layers 2 kernel_size 4 0.2925713 0.34616496599862023 -9.067581097759799\n",
            "Epoch: 0/10  Loss: 0.183294 Test loss: 1.075713Karnataka n_f 6 t_s 7 n_layers 3 kernel_size 1 0.66037184 0.6760746754335224 -37.40150570044419\n",
            "Epoch: 0/10  Loss: 0.212857 Test loss: 0.403240Karnataka n_f 6 t_s 7 n_layers 3 kernel_size 2 0.4664088 0.5024917621791345 -20.213718567672576\n",
            "Epoch: 0/10  Loss: 0.132941 Test loss: 0.274858Karnataka n_f 6 t_s 7 n_layers 3 kernel_size 3 0.3316771 0.3715455767962062 -10.598000186289692\n",
            "Epoch: 0/10  Loss: 0.132282 Test loss: 0.559626Karnataka n_f 6 t_s 7 n_layers 3 kernel_size 4 0.42095035 0.4688048648515085 -17.464736881397982\n",
            "Epoch: 0/10  Loss: 0.406113 Test loss: 0.542524Karnataka n_f 6 t_s 7 n_layers 4 kernel_size 1 0.3173663 0.33975334718948724 -8.698094131614143\n",
            "Epoch: 0/10  Loss: 0.146636 Test loss: 0.431276Karnataka n_f 6 t_s 7 n_layers 4 kernel_size 2 0.33041108 0.3638496054774729 -10.122508062266904\n",
            "Epoch: 0/10  Loss: 0.144023 Test loss: 0.216283Karnataka n_f 6 t_s 7 n_layers 4 kernel_size 3 0.3436597 0.37347242040444867 -10.718605706725707\n",
            "Epoch: 0/10  Loss: 0.132445 Test loss: 0.415184Karnataka n_f 6 t_s 7 n_layers 4 kernel_size 4 0.3849169 0.41675551977089187 -13.59222800661756\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.152916 Test loss: 0.375633Maharashtra n_f 1 t_s 5 n_layers 2 kernel_size 1 0.0331341 0.03710271279864622 0.8834119383574452\n",
            "Epoch: 0/10  Loss: 0.160854 Test loss: 0.392243Maharashtra n_f 1 t_s 5 n_layers 2 kernel_size 2 0.147226 0.15005679669558453 -0.9070148308912589\n",
            "Epoch: 0/10  Loss: 0.275566 Test loss: 0.063072Maharashtra n_f 1 t_s 5 n_layers 2 kernel_size 3 0.059480403 0.06523806353094666 0.6395501347108583\n",
            "Epoch: 0/10  Loss: 0.115430 Test loss: 0.318969Maharashtra n_f 1 t_s 5 n_layers 2 kernel_size 4 0.02772305 0.031526571032975806 0.915822453568511\n",
            "Epoch: 0/10  Loss: 0.133840 Test loss: 0.252937Maharashtra n_f 1 t_s 5 n_layers 3 kernel_size 1 0.014495778 0.016938212943314344 0.9757015861612993\n",
            "Epoch: 0/10  Loss: 0.134152 Test loss: 0.453984Maharashtra n_f 1 t_s 5 n_layers 3 kernel_size 2 0.10514004 0.11012541968517892 -0.027112170023663396\n",
            "Epoch: 0/10  Loss: 0.142360 Test loss: 0.190544Maharashtra n_f 1 t_s 5 n_layers 3 kernel_size 3 0.028213603 0.03349302808895996 0.9049938903081302\n",
            "Epoch: 0/10  Loss: 0.155555 Test loss: 0.312557Maharashtra n_f 1 t_s 5 n_layers 3 kernel_size 4 0.08211799 0.08267426796025418 0.4211267929241461\n",
            "Epoch: 0/10  Loss: 0.145134 Test loss: 0.332849Maharashtra n_f 1 t_s 5 n_layers 4 kernel_size 1 0.08374698 0.09360773000448162 0.2578936050909103\n",
            "Epoch: 0/10  Loss: 0.153433 Test loss: 0.367309Maharashtra n_f 1 t_s 5 n_layers 4 kernel_size 2 0.020671586 0.024198239768887287 0.9504081547127241\n",
            "Epoch: 0/10  Loss: 0.132420 Test loss: 0.546516Maharashtra n_f 1 t_s 5 n_layers 4 kernel_size 3 0.0398873 0.050890843259626214 0.7806578804105035\n",
            "Epoch: 0/10  Loss: 0.155218 Test loss: 0.356221Maharashtra n_f 1 t_s 5 n_layers 4 kernel_size 4 0.1207457 0.12900792793514096 -0.4095340774162073\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.145874 Test loss: 0.271893Maharashtra n_f 1 t_s 7 n_layers 2 kernel_size 1 0.040501878 0.042926942741477694 0.8010804673973844\n",
            "Epoch: 0/10  Loss: 0.270503 Test loss: 0.143044Maharashtra n_f 1 t_s 7 n_layers 2 kernel_size 2 0.0553186 0.05786105248429841 0.6385982467453876\n",
            "Epoch: 0/10  Loss: 0.152922 Test loss: 0.397185Maharashtra n_f 1 t_s 7 n_layers 2 kernel_size 3 0.13985692 0.143136355645077 -1.2116554528456338\n",
            "Epoch: 0/10  Loss: 0.145305 Test loss: 0.529752Maharashtra n_f 1 t_s 7 n_layers 2 kernel_size 4 0.015750308 0.020717187117291334 0.9536682060394731\n",
            "Epoch: 0/10  Loss: 0.166206 Test loss: 0.556060Maharashtra n_f 1 t_s 7 n_layers 3 kernel_size 1 0.1608968 0.16219431593617145 -1.8398068432051775\n",
            "Epoch: 0/10  Loss: 0.136889 Test loss: 0.358756Maharashtra n_f 1 t_s 7 n_layers 3 kernel_size 2 0.25659493 0.25974477239677546 -6.283014400746225\n",
            "Epoch: 0/10  Loss: 0.142317 Test loss: 0.474142Maharashtra n_f 1 t_s 7 n_layers 3 kernel_size 3 0.020890076 0.023084828274280038 0.9424731162825368\n",
            "Epoch: 0/10  Loss: 0.151308 Test loss: 0.356208Maharashtra n_f 1 t_s 7 n_layers 3 kernel_size 4 0.022865314 0.028237825948240116 0.9139244004072561\n",
            "Epoch: 0/10  Loss: 0.206578 Test loss: 0.471441Maharashtra n_f 1 t_s 7 n_layers 4 kernel_size 1 0.059565082 0.06266464957159731 0.5761006062183618\n",
            "Epoch: 0/10  Loss: 0.176914 Test loss: 0.352774Maharashtra n_f 1 t_s 7 n_layers 4 kernel_size 2 0.18843736 0.19702618296715466 -3.1904958779330492\n",
            "Epoch: 0/10  Loss: 0.152741 Test loss: 0.459850Maharashtra n_f 1 t_s 7 n_layers 4 kernel_size 3 0.024040043 0.026425102657604907 0.9246209095485056\n",
            "Epoch: 0/10  Loss: 0.134975 Test loss: 0.188648Maharashtra n_f 1 t_s 7 n_layers 4 kernel_size 4 0.17372592 0.17863101944147577 -2.4445401623782907\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.357949 Test loss: 0.374538Maharashtra n_f 2 t_s 5 n_layers 2 kernel_size 1 0.09568174 0.09580001500218926 0.222726318557666\n",
            "Epoch: 0/10  Loss: 0.137229 Test loss: 0.231222Maharashtra n_f 2 t_s 5 n_layers 2 kernel_size 2 0.05331631 0.058479537515511375 0.7103652980051407\n",
            "Epoch: 0/10  Loss: 0.134824 Test loss: 0.099621Maharashtra n_f 2 t_s 5 n_layers 2 kernel_size 3 0.043935493 0.04808038622562985 0.8042153533190294\n",
            "Epoch: 0/10  Loss: 0.123025 Test loss: 0.247882Maharashtra n_f 2 t_s 5 n_layers 2 kernel_size 4 0.018384282 0.02218077301371822 0.9583326282357835\n",
            "Epoch: 0/10  Loss: 0.200378 Test loss: 0.919766Maharashtra n_f 2 t_s 5 n_layers 3 kernel_size 1 0.112910315 0.1198940919011659 -0.2174139269086528\n",
            "Epoch: 0/10  Loss: 0.266354 Test loss: 0.361123Maharashtra n_f 2 t_s 5 n_layers 3 kernel_size 2 0.08392131 0.08416826608801567 0.4000162682968331\n",
            "Epoch: 0/10  Loss: 0.173005 Test loss: 0.392044Maharashtra n_f 2 t_s 5 n_layers 3 kernel_size 3 0.18523706 0.18879676460579226 -2.018782450128306\n",
            "Epoch: 0/10  Loss: 0.125279 Test loss: 0.315852Maharashtra n_f 2 t_s 5 n_layers 3 kernel_size 4 0.05936214 0.05974173699549947 0.6977276607662649\n",
            "Epoch: 0/10  Loss: 0.156649 Test loss: 0.616618Maharashtra n_f 2 t_s 5 n_layers 4 kernel_size 1 0.07382696 0.07784044179621076 0.48683935863972205\n",
            "Epoch: 0/10  Loss: 0.129528 Test loss: 0.427113Maharashtra n_f 2 t_s 5 n_layers 4 kernel_size 2 0.026451552 0.03182220367526755 0.9142363447514683\n",
            "Epoch: 0/10  Loss: 0.128133 Test loss: 0.454631Maharashtra n_f 2 t_s 5 n_layers 4 kernel_size 3 0.041948307 0.046963255966710485 0.8132076129140015\n",
            "Epoch: 0/10  Loss: 0.151617 Test loss: 0.310577Maharashtra n_f 2 t_s 5 n_layers 4 kernel_size 4 0.11228843 0.11981952816612655 -0.21590025352538422\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.395218 Test loss: 0.473338Maharashtra n_f 2 t_s 7 n_layers 2 kernel_size 1 0.023801286 0.02641867868358504 0.9246575520714067\n",
            "Epoch: 0/10  Loss: 0.228479 Test loss: 0.343488Maharashtra n_f 2 t_s 7 n_layers 2 kernel_size 2 0.13015793 0.13409953048326592 -0.9412079452405835\n",
            "Epoch: 0/10  Loss: 0.182043 Test loss: 0.163495Maharashtra n_f 2 t_s 7 n_layers 2 kernel_size 3 0.12762977 0.13119813143944914 -0.8581159770517979\n",
            "Epoch: 0/10  Loss: 0.161119 Test loss: 0.122886Maharashtra n_f 2 t_s 7 n_layers 2 kernel_size 4 0.113649055 0.11865680984443361 -0.5198575988051788\n",
            "Epoch: 0/10  Loss: 0.307295 Test loss: 1.187565Maharashtra n_f 2 t_s 7 n_layers 3 kernel_size 1 0.020125302 0.02597179588704974 0.927184893473311\n",
            "Epoch: 0/10  Loss: 0.171200 Test loss: 0.463548Maharashtra n_f 2 t_s 7 n_layers 3 kernel_size 2 0.107103996 0.11185655331239865 -0.350642430914355\n",
            "Epoch: 0/10  Loss: 0.169341 Test loss: 0.326037Maharashtra n_f 2 t_s 7 n_layers 3 kernel_size 3 0.027327014 0.03312647435836596 0.8815410212438028\n",
            "Epoch: 0/10  Loss: 0.133976 Test loss: 0.257351Maharashtra n_f 2 t_s 7 n_layers 3 kernel_size 4 0.032138273 0.041613003451523814 0.8130714414412906\n",
            "Epoch: 0/10  Loss: 0.153204 Test loss: 0.190699Maharashtra n_f 2 t_s 7 n_layers 4 kernel_size 1 0.16186523 0.16193232577113553 -1.8306400074553322\n",
            "Epoch: 0/10  Loss: 0.136413 Test loss: 0.381431Maharashtra n_f 2 t_s 7 n_layers 4 kernel_size 2 0.05299622 0.057697819604942385 0.640634491190121\n",
            "Epoch: 0/10  Loss: 0.151249 Test loss: 0.453968Maharashtra n_f 2 t_s 7 n_layers 4 kernel_size 3 0.20465103 0.20852955676945853 -3.6941052284169977\n",
            "Epoch: 0/10  Loss: 0.175059 Test loss: 0.259152Maharashtra n_f 2 t_s 7 n_layers 4 kernel_size 4 0.1011086 0.10875412004849283 -0.27675904953755515\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.164610 Test loss: 0.395753Maharashtra n_f 3 t_s 5 n_layers 2 kernel_size 1 0.09061996 0.09108758893288074 0.297314206652298\n",
            "Epoch: 0/10  Loss: 0.215787 Test loss: 0.090245Maharashtra n_f 3 t_s 5 n_layers 2 kernel_size 2 0.022965463 0.024824993530761317 0.9478059462945881\n",
            "Epoch: 0/10  Loss: 0.169029 Test loss: 0.347857Maharashtra n_f 3 t_s 5 n_layers 2 kernel_size 3 0.10381306 0.10924937492853032 -0.01083581472985129\n",
            "Epoch: 0/10  Loss: 0.167373 Test loss: 0.237414Maharashtra n_f 3 t_s 5 n_layers 2 kernel_size 4 0.17391516 0.1768972468623124 -1.6502380454657701\n",
            "Epoch: 0/10  Loss: 0.213842 Test loss: 0.393764Maharashtra n_f 3 t_s 5 n_layers 3 kernel_size 1 0.016309746 0.02060369092946442 0.9640471952250651\n",
            "Epoch: 0/10  Loss: 0.151135 Test loss: 0.387526Maharashtra n_f 3 t_s 5 n_layers 3 kernel_size 2 0.24757536 0.2504822877163145 -4.313696762072477\n",
            "Epoch: 0/10  Loss: 0.172978 Test loss: 0.591128Maharashtra n_f 3 t_s 5 n_layers 3 kernel_size 3 0.09087297 0.09132800176463693 0.29360002794905526\n",
            "Epoch: 0/10  Loss: 0.131907 Test loss: 0.422170Maharashtra n_f 3 t_s 5 n_layers 3 kernel_size 4 0.057783958 0.060444892087541564 0.6905703298998495\n",
            "Epoch: 0/10  Loss: 0.217842 Test loss: 1.061051Maharashtra n_f 3 t_s 5 n_layers 4 kernel_size 1 0.032819238 0.03651671156431699 0.8870656597699809\n",
            "Epoch: 0/10  Loss: 0.144779 Test loss: 0.461397Maharashtra n_f 3 t_s 5 n_layers 4 kernel_size 2 0.08766525 0.09075380782146385 0.30245457908702644\n",
            "Epoch: 0/10  Loss: 0.128334 Test loss: 0.465874Maharashtra n_f 3 t_s 5 n_layers 4 kernel_size 3 0.3011568 0.30642769339234327 -6.952409016034408\n",
            "Epoch: 0/10  Loss: 0.120840 Test loss: 0.360599Maharashtra n_f 3 t_s 5 n_layers 4 kernel_size 4 0.14855266 0.15813040533740697 -1.1177444082917352\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.154395 Test loss: 0.382103Maharashtra n_f 3 t_s 7 n_layers 2 kernel_size 1 0.05332715 0.05407589766732907 0.6843360495622718\n",
            "Epoch: 0/10  Loss: 0.243408 Test loss: 0.455593Maharashtra n_f 3 t_s 7 n_layers 2 kernel_size 2 0.013213543 0.014319239445990622 0.9778661253336612\n",
            "Epoch: 0/10  Loss: 0.120594 Test loss: 0.111008Maharashtra n_f 3 t_s 7 n_layers 2 kernel_size 3 0.04504836 0.05033917757873614 0.726454365534804\n",
            "Epoch: 0/10  Loss: 0.163617 Test loss: 0.446730Maharashtra n_f 3 t_s 7 n_layers 2 kernel_size 4 0.1231444 0.1282828094745405 -0.7764559533257367\n",
            "Epoch: 0/10  Loss: 0.149718 Test loss: 0.337203Maharashtra n_f 3 t_s 7 n_layers 3 kernel_size 1 0.07210578 0.07774762263584656 0.3474831294951988\n",
            "Epoch: 0/10  Loss: 0.223235 Test loss: 0.610530Maharashtra n_f 3 t_s 7 n_layers 3 kernel_size 2 0.055472214 0.06459019996814762 0.5496493566784453\n",
            "Epoch: 0/10  Loss: 0.132546 Test loss: 0.150660Maharashtra n_f 3 t_s 7 n_layers 3 kernel_size 3 0.37672928 0.38130678160524584 -14.69519121297944\n",
            "Epoch: 0/10  Loss: 0.199931 Test loss: 0.283493Maharashtra n_f 3 t_s 7 n_layers 3 kernel_size 4 0.00864144 0.009724723575535945 0.9897912617051915\n",
            "Epoch: 0/10  Loss: 0.293604 Test loss: 1.242754Maharashtra n_f 3 t_s 7 n_layers 4 kernel_size 1 0.08910309 0.09098121786757049 0.10644552355761971\n",
            "Epoch: 0/10  Loss: 0.158526 Test loss: 0.272177Maharashtra n_f 3 t_s 7 n_layers 4 kernel_size 2 0.4052231 0.41172720377456945 -17.299391880504054\n",
            "Epoch: 0/10  Loss: 0.141391 Test loss: 0.397578Maharashtra n_f 3 t_s 7 n_layers 4 kernel_size 3 0.25295976 0.2564652527423933 -6.100265460276199\n",
            "Epoch: 0/10  Loss: 0.162271 Test loss: 0.426760Maharashtra n_f 3 t_s 7 n_layers 4 kernel_size 4 0.21220668 0.21532759369929313 -4.00514753637922\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.172678 Test loss: 0.135609Maharashtra n_f 4 t_s 5 n_layers 2 kernel_size 1 0.2952058 0.3000169555521712 -6.623148126915935\n",
            "Epoch: 0/10  Loss: 0.204540 Test loss: 0.528410Maharashtra n_f 4 t_s 5 n_layers 2 kernel_size 2 0.12053798 0.1257300293333688 -0.3388156820369834\n",
            "Epoch: 0/10  Loss: 0.160642 Test loss: 0.426854Maharashtra n_f 4 t_s 5 n_layers 2 kernel_size 3 0.38373426 0.3940817472338982 -12.152715280527172\n",
            "Epoch: 0/10  Loss: 0.111257 Test loss: 0.057574Maharashtra n_f 4 t_s 5 n_layers 2 kernel_size 4 0.13246496 0.13936621150717457 -0.6449689220320829\n",
            "Epoch: 0/10  Loss: 0.147745 Test loss: 0.194628Maharashtra n_f 4 t_s 5 n_layers 3 kernel_size 1 0.15165935 0.15556968762133333 -1.0497111840300506\n",
            "Epoch: 0/10  Loss: 0.161937 Test loss: 0.159633Maharashtra n_f 4 t_s 5 n_layers 3 kernel_size 2 0.13641484 0.14489271096700848 -0.7780167356027607\n",
            "Epoch: 0/10  Loss: 0.129583 Test loss: 0.396570Maharashtra n_f 4 t_s 5 n_layers 3 kernel_size 3 0.41643432 0.42439869740072317 -14.254249063220625\n",
            "Epoch: 0/10  Loss: 0.163656 Test loss: 0.420190Maharashtra n_f 4 t_s 5 n_layers 3 kernel_size 4 0.3613463 0.37462627146049765 -10.886095739401103\n",
            "Epoch: 0/10  Loss: 0.293169 Test loss: 0.785424Maharashtra n_f 4 t_s 5 n_layers 4 kernel_size 1 0.28906354 0.2976956694325148 -6.505641246682239\n",
            "Epoch: 0/10  Loss: 0.134003 Test loss: 0.375118Maharashtra n_f 4 t_s 5 n_layers 4 kernel_size 2 0.28037053 0.2897675267473657 -6.111188677994478\n",
            "Epoch: 0/10  Loss: 0.190748 Test loss: 0.565676Maharashtra n_f 4 t_s 5 n_layers 4 kernel_size 3 0.27484617 0.2805483065010672 -5.665888195264847\n",
            "Epoch: 0/10  Loss: 0.122611 Test loss: 0.355075Maharashtra n_f 4 t_s 5 n_layers 4 kernel_size 4 0.2605721 0.26987093101073717 -5.168150486005648\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.163248 Test loss: 0.090975Maharashtra n_f 4 t_s 7 n_layers 2 kernel_size 1 0.24404195 0.24923763412871067 -5.705710139308755\n",
            "Epoch: 0/10  Loss: 0.194013 Test loss: 0.471060Maharashtra n_f 4 t_s 7 n_layers 2 kernel_size 2 0.19949828 0.20419587689460483 -3.501025294542228\n",
            "Epoch: 0/10  Loss: 0.138061 Test loss: 0.042743Maharashtra n_f 4 t_s 7 n_layers 2 kernel_size 3 0.22686456 0.2322964850953778 -4.82509199601666\n",
            "Epoch: 0/10  Loss: 0.194190 Test loss: 0.240036Maharashtra n_f 4 t_s 7 n_layers 2 kernel_size 4 0.21576701 0.22241493164683784 -4.3400512675337035\n",
            "Epoch: 0/10  Loss: 0.285139 Test loss: 0.355144Maharashtra n_f 4 t_s 7 n_layers 3 kernel_size 1 0.054678794 0.059484934596397254 0.618028004747948\n",
            "Epoch: 0/10  Loss: 0.149897 Test loss: 0.239095Maharashtra n_f 4 t_s 7 n_layers 3 kernel_size 2 0.47786075 0.4863399059906288 -24.532734399776686\n",
            "Epoch: 0/10  Loss: 0.211641 Test loss: 0.425884Maharashtra n_f 4 t_s 7 n_layers 3 kernel_size 3 0.14903173 0.15711334843782435 -1.6646715545059116\n",
            "Epoch: 0/10  Loss: 0.176441 Test loss: 0.256823Maharashtra n_f 4 t_s 7 n_layers 3 kernel_size 4 0.2505774 0.25726543529606605 -6.144641106898584\n",
            "Epoch: 0/10  Loss: 0.259625 Test loss: 0.634994Maharashtra n_f 4 t_s 7 n_layers 4 kernel_size 1 0.14377414 0.14961781042237335 -1.4164853168941414\n",
            "Epoch: 0/10  Loss: 0.155084 Test loss: 0.339797Maharashtra n_f 4 t_s 7 n_layers 4 kernel_size 2 0.17196257 0.17829198664532278 -2.431477746627105\n",
            "Epoch: 0/10  Loss: 0.176632 Test loss: 0.486491Maharashtra n_f 4 t_s 7 n_layers 4 kernel_size 3 0.2304752 0.23936893451715135 -5.185190980313438\n",
            "Epoch: 0/10  Loss: 0.178703 Test loss: 0.395419Maharashtra n_f 4 t_s 7 n_layers 4 kernel_size 4 0.2515104 0.2589333905513838 -6.237584744258351\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.199194 Test loss: 0.032965Maharashtra n_f 5 t_s 5 n_layers 2 kernel_size 1 0.34311765 0.3600808964674587 -9.981025911657888\n",
            "Epoch: 0/10  Loss: 0.182923 Test loss: 0.035029Maharashtra n_f 5 t_s 5 n_layers 2 kernel_size 2 0.15417148 0.1663932376573704 -1.344844521122969\n",
            "Epoch: 0/10  Loss: 0.190228 Test loss: 0.274184Maharashtra n_f 5 t_s 5 n_layers 2 kernel_size 3 0.04786436 0.057240985494727926 0.7225038846771789\n",
            "Epoch: 0/10  Loss: 0.105352 Test loss: 0.210913Maharashtra n_f 5 t_s 5 n_layers 2 kernel_size 4 0.20977633 0.2164332889369742 -2.96726203026552\n",
            "Epoch: 0/10  Loss: 0.200460 Test loss: 0.374386Maharashtra n_f 5 t_s 5 n_layers 3 kernel_size 1 0.19684179 0.20303190372074684 -2.491172469846889\n",
            "Epoch: 0/10  Loss: 0.157966 Test loss: 0.441236Maharashtra n_f 5 t_s 5 n_layers 3 kernel_size 2 0.11046759 0.12170951548082999 -0.25456114387122764\n",
            "Epoch: 0/10  Loss: 0.116652 Test loss: 0.162424Maharashtra n_f 5 t_s 5 n_layers 3 kernel_size 3 0.16700776 0.17293894439455282 -1.5329600360319149\n",
            "Epoch: 0/10  Loss: 0.120011 Test loss: 0.150635Maharashtra n_f 5 t_s 5 n_layers 3 kernel_size 4 0.2140003 0.2206406884788658 -3.1230059777401635\n",
            "Epoch: 0/10  Loss: 0.163305 Test loss: 0.423246Maharashtra n_f 5 t_s 5 n_layers 4 kernel_size 1 0.56766534 0.5738382700834147 -26.888281430562298\n",
            "Epoch: 0/10  Loss: 0.140352 Test loss: 0.384048Maharashtra n_f 5 t_s 5 n_layers 4 kernel_size 2 0.06829444 0.08076014200075955 0.44762138818317865\n",
            "Epoch: 0/10  Loss: 0.150221 Test loss: 0.324515Maharashtra n_f 5 t_s 5 n_layers 4 kernel_size 3 0.23023754 0.2373699443870356 -3.77193133611377\n",
            "Epoch: 0/10  Loss: 0.132814 Test loss: 0.282174Maharashtra n_f 5 t_s 5 n_layers 4 kernel_size 4 0.1308164 0.13752455302495045 -0.6017810770339802\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.324886 Test loss: 0.052989Maharashtra n_f 5 t_s 7 n_layers 2 kernel_size 1 0.3111015 0.3180236333208786 -9.917829521635566\n",
            "Epoch: 0/10  Loss: 0.162986 Test loss: 0.008436Maharashtra n_f 5 t_s 7 n_layers 2 kernel_size 2 0.29203326 0.29573269725159795 -8.440961990999414\n",
            "Epoch: 0/10  Loss: 0.185292 Test loss: 0.168369Maharashtra n_f 5 t_s 7 n_layers 2 kernel_size 3 0.27634782 0.28494408958364453 -7.764696293822007\n",
            "Epoch: 0/10  Loss: 0.145851 Test loss: 0.352185Maharashtra n_f 5 t_s 7 n_layers 2 kernel_size 4 0.17190672 0.17682688506836813 -2.3753134947558685\n",
            "Epoch: 0/10  Loss: 0.145461 Test loss: 0.325718Maharashtra n_f 5 t_s 7 n_layers 3 kernel_size 1 0.24920832 0.2556615603494272 -6.055834906028678\n",
            "Epoch: 0/10  Loss: 0.203572 Test loss: 0.362200Maharashtra n_f 5 t_s 7 n_layers 3 kernel_size 2 0.0718085 0.08059156776319663 0.2988729176458048\n",
            "Epoch: 0/10  Loss: 0.203175 Test loss: 0.483215Maharashtra n_f 5 t_s 7 n_layers 3 kernel_size 3 0.09622418 0.10528010699318896 -0.19649301392831853\n",
            "Epoch: 0/10  Loss: 0.218677 Test loss: 0.612725Maharashtra n_f 5 t_s 7 n_layers 3 kernel_size 4 0.14146069 0.1496157189162125 -1.4164176413127945\n",
            "Epoch: 0/10  Loss: 0.307672 Test loss: 0.087141Maharashtra n_f 5 t_s 7 n_layers 4 kernel_size 1 0.23453778 0.23990506186867486 -5.212928711703963\n",
            "Epoch: 0/10  Loss: 0.205715 Test loss: 0.494789Maharashtra n_f 5 t_s 7 n_layers 4 kernel_size 2 0.15366662 0.16075728033874706 -1.789708460953244\n",
            "Epoch: 0/10  Loss: 0.153502 Test loss: 0.143853Maharashtra n_f 5 t_s 7 n_layers 4 kernel_size 3 0.15044867 0.15496386851949362 -1.5922592296079103\n",
            "Epoch: 0/10  Loss: 0.216009 Test loss: 0.669949Maharashtra n_f 5 t_s 7 n_layers 4 kernel_size 4 0.14726678 0.15097081986494637 -1.4603878105904906\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.167465 Test loss: 0.147933Maharashtra n_f 6 t_s 5 n_layers 2 kernel_size 1 0.105868176 0.11090719386645281 -0.041746760532742844\n",
            "Epoch: 0/10  Loss: 0.134190 Test loss: 0.056861Maharashtra n_f 6 t_s 5 n_layers 2 kernel_size 2 0.17996134 0.183010198604047 -1.8365687756600702\n",
            "Epoch: 0/10  Loss: 0.131606 Test loss: 0.082767Maharashtra n_f 6 t_s 5 n_layers 2 kernel_size 3 0.11362674 0.11841963093462626 -0.18765452461906262\n",
            "Epoch: 0/10  Loss: 0.180281 Test loss: 0.182675Maharashtra n_f 6 t_s 5 n_layers 2 kernel_size 4 0.036278076 0.04161706672467967 0.8533150232911607\n",
            "Epoch: 0/10  Loss: 0.407120 Test loss: 0.204961Maharashtra n_f 6 t_s 5 n_layers 3 kernel_size 1 0.24699147 0.25387967777591314 -4.458817749590848\n",
            "Epoch: 0/10  Loss: 0.266219 Test loss: 0.712549Maharashtra n_f 6 t_s 5 n_layers 3 kernel_size 2 0.1221108 0.13382591658828302 -0.5167818654567484\n",
            "Epoch: 0/10  Loss: 0.165641 Test loss: 0.682216Maharashtra n_f 6 t_s 5 n_layers 3 kernel_size 3 0.24476127 0.2521531545610017 -4.384824411569583\n",
            "Epoch: 0/10  Loss: 0.172769 Test loss: 0.465060Maharashtra n_f 6 t_s 5 n_layers 3 kernel_size 4 0.2706442 0.27668999464910843 -5.483800416826244\n",
            "Epoch: 0/10  Loss: 0.261907 Test loss: 0.352903Maharashtra n_f 6 t_s 5 n_layers 4 kernel_size 1 0.13114928 0.13510822892852714 -0.545988741296513\n",
            "Epoch: 0/10  Loss: 0.186208 Test loss: 0.443774Maharashtra n_f 6 t_s 5 n_layers 4 kernel_size 2 0.2801715 0.28926459542099847 -6.086525413369118\n",
            "Epoch: 0/10  Loss: 0.167305 Test loss: 0.505525Maharashtra n_f 6 t_s 5 n_layers 4 kernel_size 3 0.30218413 0.30915408627901875 -7.094550418612203\n",
            "Epoch: 0/10  Loss: 0.127665 Test loss: 0.062639Maharashtra n_f 6 t_s 5 n_layers 4 kernel_size 4 0.12568003 0.13237821174206843 -0.4841430161031304\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.224738 Test loss: 0.015170Maharashtra n_f 6 t_s 7 n_layers 2 kernel_size 1 0.14693263 0.15515977069897782 -1.5988175200895909\n",
            "Epoch: 0/10  Loss: 0.165879 Test loss: 0.511716Maharashtra n_f 6 t_s 7 n_layers 2 kernel_size 2 0.12982586 0.13325580075566973 -0.9168573337757073\n",
            "Epoch: 0/10  Loss: 0.323227 Test loss: 0.015852Maharashtra n_f 6 t_s 7 n_layers 2 kernel_size 3 0.2512141 0.2559742269375969 -6.073103354133802\n",
            "Epoch: 0/10  Loss: 0.156750 Test loss: 0.188580Maharashtra n_f 6 t_s 7 n_layers 2 kernel_size 4 0.038918667 0.043529359227035394 0.7954581970132268\n",
            "Epoch: 0/10  Loss: 0.354883 Test loss: 0.038238Maharashtra n_f 6 t_s 7 n_layers 3 kernel_size 1 0.26093736 0.2663783721656676 -6.659765220517856\n",
            "Epoch: 0/10  Loss: 0.161587 Test loss: 0.333058Maharashtra n_f 6 t_s 7 n_layers 3 kernel_size 2 0.31247982 0.3190290393713522 -9.986969790949818\n",
            "Epoch: 0/10  Loss: 0.159257 Test loss: 0.202063Maharashtra n_f 6 t_s 7 n_layers 3 kernel_size 3 0.23969425 0.2461734067578058 -5.541837852616731\n",
            "Epoch: 0/10  Loss: 0.181334 Test loss: 0.324886Maharashtra n_f 6 t_s 7 n_layers 3 kernel_size 4 0.118010715 0.12318044557747627 -0.6379515114554395\n",
            "Epoch: 0/10  Loss: 0.428602 Test loss: 0.142892Maharashtra n_f 6 t_s 7 n_layers 4 kernel_size 1 0.2862129 0.29496186345303266 -8.391808623110341\n",
            "Epoch: 0/10  Loss: 0.264212 Test loss: 0.099218Maharashtra n_f 6 t_s 7 n_layers 4 kernel_size 2 0.14241245 0.1493667515169169 -1.408382362782107\n",
            "Epoch: 0/10  Loss: 0.210756 Test loss: 0.728104Maharashtra n_f 6 t_s 7 n_layers 4 kernel_size 3 0.18050033 0.18725275586676063 -2.785070370682032\n",
            "Epoch: 0/10  Loss: 0.148530 Test loss: 0.300816Maharashtra n_f 6 t_s 7 n_layers 4 kernel_size 4 0.1441653 0.1486163442263211 -1.384243648349444\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.198068 Test loss: 0.283166Uttar-Pradesh n_f 1 t_s 5 n_layers 2 kernel_size 1 0.06929645 0.07283281041488364 0.640910942659018\n",
            "Epoch: 0/10  Loss: 0.144298 Test loss: 0.242206Uttar-Pradesh n_f 1 t_s 5 n_layers 2 kernel_size 2 0.06321218 0.07471139122201795 0.622148046152964\n",
            "Epoch: 0/10  Loss: 0.111027 Test loss: 0.196118Uttar-Pradesh n_f 1 t_s 5 n_layers 2 kernel_size 3 0.11787799 0.1260473141377078 -0.07551186775667951\n",
            "Epoch: 0/10  Loss: 0.157632 Test loss: 0.196177Uttar-Pradesh n_f 1 t_s 5 n_layers 2 kernel_size 4 0.09359887 0.10288573200580076 0.28343048182575803\n",
            "Epoch: 0/10  Loss: 0.165177 Test loss: 0.489653Uttar-Pradesh n_f 1 t_s 5 n_layers 3 kernel_size 1 0.04797941 0.05042710517784196 0.8278622776656556\n",
            "Epoch: 0/10  Loss: 0.140021 Test loss: 0.364331Uttar-Pradesh n_f 1 t_s 5 n_layers 3 kernel_size 2 0.089196615 0.09261580678167265 0.41934496236063934\n",
            "Epoch: 0/10  Loss: 0.139488 Test loss: 0.399847Uttar-Pradesh n_f 1 t_s 5 n_layers 3 kernel_size 3 0.13587548 0.14379317397188232 -0.3996665951649425\n",
            "Epoch: 0/10  Loss: 0.155276 Test loss: 0.232235Uttar-Pradesh n_f 1 t_s 5 n_layers 3 kernel_size 4 0.03812038 0.04417689287182015 0.8678891827565834\n",
            "Epoch: 0/10  Loss: 0.131166 Test loss: 0.320019Uttar-Pradesh n_f 1 t_s 5 n_layers 4 kernel_size 1 0.13367479 0.13405507505080622 -0.21650680819974588\n",
            "Epoch: 0/10  Loss: 0.151287 Test loss: 0.219190Uttar-Pradesh n_f 1 t_s 5 n_layers 4 kernel_size 2 0.07266375 0.07739672063095988 0.5944979002952311\n",
            "Epoch: 0/10  Loss: 0.135169 Test loss: 0.390546Uttar-Pradesh n_f 1 t_s 5 n_layers 4 kernel_size 3 0.056001473 0.06593529508845401 0.7057042955933337\n",
            "Epoch: 0/10  Loss: 0.149414 Test loss: 0.278802Uttar-Pradesh n_f 1 t_s 5 n_layers 4 kernel_size 4 0.04651415 0.0588505778741145 0.7655504032548248\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.184973 Test loss: 0.493337Uttar-Pradesh n_f 1 t_s 7 n_layers 2 kernel_size 1 0.14484046 0.14906185374929584 -0.9380521885378419\n",
            "Epoch: 0/10  Loss: 0.203710 Test loss: 0.196424Uttar-Pradesh n_f 1 t_s 7 n_layers 2 kernel_size 2 0.018137079 0.024912565601736707 0.9458660993231588\n",
            "Epoch: 0/10  Loss: 0.199101 Test loss: 0.133130Uttar-Pradesh n_f 1 t_s 7 n_layers 2 kernel_size 3 0.11124424 0.11679039270535446 -0.18972523601356306\n",
            "Epoch: 0/10  Loss: 0.128762 Test loss: 0.130164Uttar-Pradesh n_f 1 t_s 7 n_layers 2 kernel_size 4 0.015539944 0.017996785978173925 0.9717497489846394\n",
            "Epoch: 0/10  Loss: 0.151039 Test loss: 0.553494Uttar-Pradesh n_f 1 t_s 7 n_layers 3 kernel_size 1 0.33841655 0.3415465828135053 -9.174950941882436\n",
            "Epoch: 0/10  Loss: 0.139695 Test loss: 0.402462Uttar-Pradesh n_f 1 t_s 7 n_layers 3 kernel_size 2 0.034783207 0.043282259204611456 0.8365999290870849\n",
            "Epoch: 0/10  Loss: 0.195735 Test loss: 0.186079Uttar-Pradesh n_f 1 t_s 7 n_layers 3 kernel_size 3 0.10664438 0.10962815024684255 -0.04827819003581113\n",
            "Epoch: 0/10  Loss: 0.151338 Test loss: 0.231669Uttar-Pradesh n_f 1 t_s 7 n_layers 3 kernel_size 4 0.15854982 0.16385611541043515 -1.3418428239363958\n",
            "Epoch: 0/10  Loss: 0.211872 Test loss: 0.429786Uttar-Pradesh n_f 1 t_s 7 n_layers 4 kernel_size 1 0.13998173 0.14541922823426892 -0.8444890510821372\n",
            "Epoch: 0/10  Loss: 0.160415 Test loss: 0.312298Uttar-Pradesh n_f 1 t_s 7 n_layers 4 kernel_size 2 0.14325126 0.1466302653836399 -0.8753385217995724\n",
            "Epoch: 0/10  Loss: 0.155813 Test loss: 0.259534Uttar-Pradesh n_f 1 t_s 7 n_layers 4 kernel_size 3 0.017062953 0.01890156973811824 0.9688377956067907\n",
            "Epoch: 0/10  Loss: 0.147349 Test loss: 0.307132Uttar-Pradesh n_f 1 t_s 7 n_layers 4 kernel_size 4 0.022208966 0.029090050966350266 0.9261889524388297\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.164727 Test loss: 0.206920Uttar-Pradesh n_f 2 t_s 5 n_layers 2 kernel_size 1 0.13468105 0.13957070808343908 -0.31867137287032143\n",
            "Epoch: 0/10  Loss: 0.277549 Test loss: 0.202840Uttar-Pradesh n_f 2 t_s 5 n_layers 2 kernel_size 2 0.022043688 0.028095149799502943 0.9465668572205403\n",
            "Epoch: 0/10  Loss: 0.121905 Test loss: 0.203675Uttar-Pradesh n_f 2 t_s 5 n_layers 2 kernel_size 3 0.15829471 0.1641806449562706 -0.8247021271745778\n",
            "Epoch: 0/10  Loss: 0.196528 Test loss: 0.177148Uttar-Pradesh n_f 2 t_s 5 n_layers 2 kernel_size 4 0.026418205 0.03169215591965853 0.9320089795574942\n",
            "Epoch: 0/10  Loss: 0.151654 Test loss: 0.307811Uttar-Pradesh n_f 2 t_s 5 n_layers 3 kernel_size 1 0.22186117 0.224467979375129 -2.4108040606386263\n",
            "Epoch: 0/10  Loss: 0.154073 Test loss: 0.277978Uttar-Pradesh n_f 2 t_s 5 n_layers 3 kernel_size 2 0.027516743 0.033047285827040036 0.9260701824318718\n",
            "Epoch: 0/10  Loss: 0.117210 Test loss: 0.122974Uttar-Pradesh n_f 2 t_s 5 n_layers 3 kernel_size 3 0.01881328 0.02323511906737874 0.9634541709266244\n",
            "Epoch: 0/10  Loss: 0.139795 Test loss: 0.094448Uttar-Pradesh n_f 2 t_s 5 n_layers 3 kernel_size 4 0.19474125 0.20203790084323772 -1.7632087859711443\n",
            "Epoch: 0/10  Loss: 0.166008 Test loss: 0.470041Uttar-Pradesh n_f 2 t_s 5 n_layers 4 kernel_size 1 0.13540268 0.13913922738086038 -0.310530490417271\n",
            "Epoch: 0/10  Loss: 0.132852 Test loss: 0.363340Uttar-Pradesh n_f 2 t_s 5 n_layers 4 kernel_size 2 0.07448163 0.08544133013687577 0.5058213040145719\n",
            "Epoch: 0/10  Loss: 0.128902 Test loss: 0.304436Uttar-Pradesh n_f 2 t_s 5 n_layers 4 kernel_size 3 0.2868165 0.29242682880564513 -4.7887184048205675\n",
            "Epoch: 0/10  Loss: 0.139221 Test loss: 0.222520Uttar-Pradesh n_f 2 t_s 5 n_layers 4 kernel_size 4 0.09534662 0.1093955616697286 0.18988364408609038\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.139509 Test loss: 0.224902Uttar-Pradesh n_f 2 t_s 7 n_layers 2 kernel_size 1 0.08170644 0.08292930761511712 0.4001419219427623\n",
            "Epoch: 0/10  Loss: 0.150060 Test loss: 0.322448Uttar-Pradesh n_f 2 t_s 7 n_layers 2 kernel_size 2 0.0441489 0.04468777809440006 0.8258153226830863\n",
            "Epoch: 0/10  Loss: 0.163153 Test loss: 0.305481Uttar-Pradesh n_f 2 t_s 7 n_layers 2 kernel_size 3 0.021996178 0.025160737997859128 0.9447821945622626\n",
            "Epoch: 0/10  Loss: 0.203467 Test loss: 0.113710Uttar-Pradesh n_f 2 t_s 7 n_layers 2 kernel_size 4 0.025543176 0.034163254806707045 0.898199268882957\n",
            "Epoch: 0/10  Loss: 0.214222 Test loss: 0.585746Uttar-Pradesh n_f 2 t_s 7 n_layers 3 kernel_size 1 0.030572763 0.03253475661884792 0.9076732450109756\n",
            "Epoch: 0/10  Loss: 0.151835 Test loss: 0.325853Uttar-Pradesh n_f 2 t_s 7 n_layers 3 kernel_size 2 0.5097722 0.515067579501962 -22.13986825357194\n",
            "Epoch: 0/10  Loss: 0.159555 Test loss: 0.338953Uttar-Pradesh n_f 2 t_s 7 n_layers 3 kernel_size 3 0.02377932 0.02699375204811709 0.9364436490445545\n",
            "Epoch: 0/10  Loss: 0.149060 Test loss: 0.184444Uttar-Pradesh n_f 2 t_s 7 n_layers 3 kernel_size 4 0.11945959 0.12322270228756468 -0.3243838234503351\n",
            "Epoch: 0/10  Loss: 0.219921 Test loss: 0.673558Uttar-Pradesh n_f 2 t_s 7 n_layers 4 kernel_size 1 0.09409951 0.10192798911198848 0.09380976332337887\n",
            "Epoch: 0/10  Loss: 0.136333 Test loss: 0.128223Uttar-Pradesh n_f 2 t_s 7 n_layers 4 kernel_size 2 0.02785961 0.03607173216118218 0.8865076965042187\n",
            "Epoch: 0/10  Loss: 0.139687 Test loss: 0.302572Uttar-Pradesh n_f 2 t_s 7 n_layers 4 kernel_size 3 0.17519584 0.17833454330166068 -1.773980525223489\n",
            "Epoch: 0/10  Loss: 0.138987 Test loss: 0.319866Uttar-Pradesh n_f 2 t_s 7 n_layers 4 kernel_size 4 0.07666386 0.08475169361793791 0.37348823318979385\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.352953 Test loss: 0.313124Uttar-Pradesh n_f 3 t_s 5 n_layers 2 kernel_size 1 0.04721182 0.05001690939988343 0.8306513611519837\n",
            "Epoch: 0/10  Loss: 0.180124 Test loss: 0.311402Uttar-Pradesh n_f 3 t_s 5 n_layers 2 kernel_size 2 0.028923564 0.03599422852065942 0.9122971498186602\n",
            "Epoch: 0/10  Loss: 0.162033 Test loss: 0.618431Uttar-Pradesh n_f 3 t_s 5 n_layers 2 kernel_size 3 0.04103517 0.047074041871768994 0.8499931924848958\n",
            "Epoch: 0/10  Loss: 0.118302 Test loss: 0.156264Uttar-Pradesh n_f 3 t_s 5 n_layers 2 kernel_size 4 0.016287979 0.019814816221771097 0.9734216450894929\n",
            "Epoch: 0/10  Loss: 0.292863 Test loss: 0.962202Uttar-Pradesh n_f 3 t_s 5 n_layers 3 kernel_size 1 0.017234905 0.021437267520075975 0.9688909400560011\n",
            "Epoch: 0/10  Loss: 0.174606 Test loss: 0.423970Uttar-Pradesh n_f 3 t_s 5 n_layers 3 kernel_size 2 0.14709137 0.14753389764077363 -0.4734374316983603\n",
            "Epoch: 0/10  Loss: 0.144583 Test loss: 0.425928Uttar-Pradesh n_f 3 t_s 5 n_layers 3 kernel_size 3 0.023194853 0.028550988471755818 0.9448189034731291\n",
            "Epoch: 0/10  Loss: 0.191619 Test loss: 0.157150Uttar-Pradesh n_f 3 t_s 5 n_layers 3 kernel_size 4 0.1552796 0.16107940944848154 -0.7564186642746746\n",
            "Epoch: 0/10  Loss: 0.234028 Test loss: 0.635778Uttar-Pradesh n_f 3 t_s 5 n_layers 4 kernel_size 1 0.13751459 0.142015883608035 -0.36528032512841935\n",
            "Epoch: 0/10  Loss: 0.151445 Test loss: 0.398121Uttar-Pradesh n_f 3 t_s 5 n_layers 4 kernel_size 2 0.097181 0.1088524922861187 0.19790696372497996\n",
            "Epoch: 0/10  Loss: 0.180884 Test loss: 0.295781Uttar-Pradesh n_f 3 t_s 5 n_layers 4 kernel_size 3 0.037062246 0.04438196840693936 0.86665979834564\n",
            "Epoch: 0/10  Loss: 0.171868 Test loss: 0.318813Uttar-Pradesh n_f 3 t_s 5 n_layers 4 kernel_size 4 0.06173759 0.07112841926700038 0.6575207032653885\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.247359 Test loss: 0.068975Uttar-Pradesh n_f 3 t_s 7 n_layers 2 kernel_size 1 0.032609668 0.03926101103368633 0.8655516816172364\n",
            "Epoch: 0/10  Loss: 0.155112 Test loss: 0.256171Uttar-Pradesh n_f 3 t_s 7 n_layers 2 kernel_size 2 0.08520766 0.08829715277480117 0.3199735131052738\n",
            "Epoch: 0/10  Loss: 0.166259 Test loss: 0.237260Uttar-Pradesh n_f 3 t_s 7 n_layers 2 kernel_size 3 0.09761364 0.09784887390097881 0.1648892111009792\n",
            "Epoch: 0/10  Loss: 0.175556 Test loss: 0.639439Uttar-Pradesh n_f 3 t_s 7 n_layers 2 kernel_size 4 0.04411724 0.051375268710233055 0.7697812688390994\n",
            "Epoch: 0/10  Loss: 0.224062 Test loss: 0.102349Uttar-Pradesh n_f 3 t_s 7 n_layers 3 kernel_size 1 0.12607834 0.12824336754090104 -0.4345056388252675\n",
            "Epoch: 0/10  Loss: 0.143402 Test loss: 0.510339Uttar-Pradesh n_f 3 t_s 7 n_layers 3 kernel_size 2 0.07025628 0.07043048112922491 0.5673330406399182\n",
            "Epoch: 0/10  Loss: 0.171379 Test loss: 0.393535Uttar-Pradesh n_f 3 t_s 7 n_layers 3 kernel_size 3 0.077391066 0.08158023348218606 0.41949992697430416\n",
            "Epoch: 0/10  Loss: 0.195009 Test loss: 0.222374Uttar-Pradesh n_f 3 t_s 7 n_layers 3 kernel_size 4 0.019666191 0.02734560193874857 0.9347760054297518\n",
            "Epoch: 0/10  Loss: 0.185206 Test loss: 0.357490Uttar-Pradesh n_f 3 t_s 7 n_layers 4 kernel_size 1 0.37060326 0.37921896545881856 -11.543319625053162\n",
            "Epoch: 0/10  Loss: 0.135055 Test loss: 0.238525Uttar-Pradesh n_f 3 t_s 7 n_layers 4 kernel_size 2 0.32784107 0.32976266356699446 -8.484956881567102\n",
            "Epoch: 0/10  Loss: 0.136743 Test loss: 0.223740Uttar-Pradesh n_f 3 t_s 7 n_layers 4 kernel_size 3 0.22541986 0.23068534242566185 -3.641650150721836\n",
            "Epoch: 0/10  Loss: 0.159536 Test loss: 0.332136Uttar-Pradesh n_f 3 t_s 7 n_layers 4 kernel_size 4 0.063081175 0.06373793270396623 0.6456533281390238\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.193794 Test loss: 0.181188Uttar-Pradesh n_f 4 t_s 5 n_layers 2 kernel_size 1 0.012698456 0.0165947372417071 0.9813581576459874\n",
            "Epoch: 0/10  Loss: 0.235998 Test loss: 0.211662Uttar-Pradesh n_f 4 t_s 5 n_layers 2 kernel_size 2 0.11485097 0.12049792201231016 0.017105032765695083\n",
            "Epoch: 0/10  Loss: 0.150597 Test loss: 0.194077Uttar-Pradesh n_f 4 t_s 5 n_layers 2 kernel_size 3 0.041306652 0.04817321021818362 0.8429061521095094\n",
            "Epoch: 0/10  Loss: 0.126557 Test loss: 0.146629Uttar-Pradesh n_f 4 t_s 5 n_layers 2 kernel_size 4 0.08443283 0.08942029508814395 0.4587221513216403\n",
            "Epoch: 0/10  Loss: 0.171203 Test loss: 0.308409Uttar-Pradesh n_f 4 t_s 5 n_layers 3 kernel_size 1 0.23881203 0.23949744232938394 -2.882842613812386\n",
            "Epoch: 0/10  Loss: 0.155010 Test loss: 0.258982Uttar-Pradesh n_f 4 t_s 5 n_layers 3 kernel_size 2 0.024384828 0.028558404396169263 0.944790236594039\n",
            "Epoch: 0/10  Loss: 0.161380 Test loss: 0.378125Uttar-Pradesh n_f 4 t_s 5 n_layers 3 kernel_size 3 0.1254259 0.13149550246345526 -0.1704957040260433\n",
            "Epoch: 0/10  Loss: 0.149643 Test loss: 0.142938Uttar-Pradesh n_f 4 t_s 5 n_layers 3 kernel_size 4 0.030319221 0.03730643490498491 0.9057859841862574\n",
            "Epoch: 0/10  Loss: 0.168250 Test loss: 0.247438Uttar-Pradesh n_f 4 t_s 5 n_layers 4 kernel_size 1 0.04752994 0.0563711443858474 0.7848894422500802\n",
            "Epoch: 0/10  Loss: 0.210667 Test loss: 0.486781Uttar-Pradesh n_f 4 t_s 5 n_layers 4 kernel_size 2 0.23697583 0.2460379234449668 -3.0978129464670108\n",
            "Epoch: 0/10  Loss: 0.124209 Test loss: 0.240279Uttar-Pradesh n_f 4 t_s 5 n_layers 4 kernel_size 3 0.14981495 0.15682816824665863 -0.6649307234958137\n",
            "Epoch: 0/10  Loss: 0.219371 Test loss: 0.359706Uttar-Pradesh n_f 4 t_s 5 n_layers 4 kernel_size 4 0.05211283 0.054591439382472975 0.7982575999726067\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.215280 Test loss: 0.506811Uttar-Pradesh n_f 4 t_s 7 n_layers 2 kernel_size 1 0.014314165 0.016713712005050847 0.9756343368958519\n",
            "Epoch: 0/10  Loss: 0.237382 Test loss: 0.083418Uttar-Pradesh n_f 4 t_s 7 n_layers 2 kernel_size 2 0.15968435 0.16386858515546918 -1.342199155671271\n",
            "Epoch: 0/10  Loss: 0.179627 Test loss: 0.056606Uttar-Pradesh n_f 4 t_s 7 n_layers 2 kernel_size 3 0.024709206 0.02974823124682972 0.9228111283253846\n",
            "Epoch: 0/10  Loss: 0.080892 Test loss: 0.000950Uttar-Pradesh n_f 4 t_s 7 n_layers 2 kernel_size 4 0.111254536 0.11530745338882227 -0.15970396710481416\n",
            "Epoch: 0/10  Loss: 0.233638 Test loss: 0.130749Uttar-Pradesh n_f 4 t_s 7 n_layers 3 kernel_size 1 0.085241325 0.08750196192874968 0.3321667617237254\n",
            "Epoch: 0/10  Loss: 0.292239 Test loss: 0.769343Uttar-Pradesh n_f 4 t_s 7 n_layers 3 kernel_size 2 0.06873689 0.07743181022464779 0.47703666731299277\n",
            "Epoch: 0/10  Loss: 0.156612 Test loss: 0.180135Uttar-Pradesh n_f 4 t_s 7 n_layers 3 kernel_size 3 0.1034267 0.10691170925746439 0.003027949713532596\n",
            "Epoch: 0/10  Loss: 0.137107 Test loss: 0.110612Uttar-Pradesh n_f 4 t_s 7 n_layers 3 kernel_size 4 0.030220807 0.032607541328273065 0.9072596857902321\n",
            "Epoch: 0/10  Loss: 0.322134 Test loss: 0.341971Uttar-Pradesh n_f 4 t_s 7 n_layers 4 kernel_size 1 0.034667883 0.03594318777664316 0.887315124120947\n",
            "Epoch: 0/10  Loss: 0.153274 Test loss: 0.372925Uttar-Pradesh n_f 4 t_s 7 n_layers 4 kernel_size 2 0.3651851 0.37184765178230833 -11.060422607166553\n",
            "Epoch: 0/10  Loss: 0.188846 Test loss: 0.486195Uttar-Pradesh n_f 4 t_s 7 n_layers 4 kernel_size 3 0.123492755 0.12789028230596733 -0.4266174883738749\n",
            "Epoch: 0/10  Loss: 0.144163 Test loss: 0.235895Uttar-Pradesh n_f 4 t_s 7 n_layers 4 kernel_size 4 0.09354736 0.10041030345817657 0.12059483632038104\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.141344 Test loss: 0.428091Uttar-Pradesh n_f 5 t_s 5 n_layers 2 kernel_size 1 0.06983272 0.07852033783637058 0.5826385478597274\n",
            "Epoch: 0/10  Loss: 0.187859 Test loss: 0.525713Uttar-Pradesh n_f 5 t_s 5 n_layers 2 kernel_size 2 0.09267326 0.09847535888832125 0.3435477199048773\n",
            "Epoch: 0/10  Loss: 0.142284 Test loss: 0.179874Uttar-Pradesh n_f 5 t_s 5 n_layers 2 kernel_size 3 0.041419942 0.04689829466088037 0.8511111458964977\n",
            "Epoch: 0/10  Loss: 0.098946 Test loss: 0.003032Uttar-Pradesh n_f 5 t_s 5 n_layers 2 kernel_size 4 0.18123084 0.1850934159422215 -1.3191560032951077\n",
            "Epoch: 0/10  Loss: 0.456147 Test loss: 0.148078Uttar-Pradesh n_f 5 t_s 5 n_layers 3 kernel_size 1 0.10734338 0.11529318068748354 0.10018081685073521\n",
            "Epoch: 0/10  Loss: 0.174953 Test loss: 0.198553Uttar-Pradesh n_f 5 t_s 5 n_layers 3 kernel_size 2 0.36557257 0.37763022848056044 -8.653427952180735\n",
            "Epoch: 0/10  Loss: 0.102003 Test loss: 0.130554Uttar-Pradesh n_f 5 t_s 5 n_layers 3 kernel_size 3 0.059708346 0.07674038691652497 0.6013461356171452\n",
            "Epoch: 0/10  Loss: 0.106302 Test loss: 0.059879Uttar-Pradesh n_f 5 t_s 5 n_layers 3 kernel_size 4 0.028463852 0.03445538129846669 0.9196358914892067\n",
            "Epoch: 0/10  Loss: 0.338724 Test loss: 0.192544Uttar-Pradesh n_f 5 t_s 5 n_layers 4 kernel_size 1 0.4212651 0.4354689318790337 -11.836965656016103\n",
            "Epoch: 0/10  Loss: 0.130108 Test loss: 0.462401Uttar-Pradesh n_f 5 t_s 5 n_layers 4 kernel_size 2 0.19540848 0.20519144469602146 -1.850142060685855\n",
            "Epoch: 0/10  Loss: 0.154116 Test loss: 0.309718Uttar-Pradesh n_f 5 t_s 5 n_layers 4 kernel_size 3 0.020043535 0.025606249661689447 0.9556146177527934\n",
            "Epoch: 0/10  Loss: 0.123358 Test loss: 0.131836Uttar-Pradesh n_f 5 t_s 5 n_layers 4 kernel_size 4 0.112803474 0.11923326345847174 0.03762821385086168\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.820763 Test loss: 0.038010Uttar-Pradesh n_f 5 t_s 7 n_layers 2 kernel_size 1 0.08570893 0.08845349320545794 0.3175632374480757\n",
            "Epoch: 0/10  Loss: 0.135569 Test loss: 0.559332Uttar-Pradesh n_f 5 t_s 7 n_layers 2 kernel_size 2 0.12949435 0.14790381310811124 -0.9080561955934519\n",
            "Epoch: 0/10  Loss: 0.119506 Test loss: 0.127956Uttar-Pradesh n_f 5 t_s 7 n_layers 2 kernel_size 3 0.3961312 0.4127422011855719 -13.859020047067675\n",
            "Epoch: 0/10  Loss: 0.263209 Test loss: 0.498874Uttar-Pradesh n_f 5 t_s 7 n_layers 2 kernel_size 4 0.02808652 0.034531416738871376 0.8959933269124501\n",
            "Epoch: 0/10  Loss: 0.183220 Test loss: 0.055146Uttar-Pradesh n_f 5 t_s 7 n_layers 3 kernel_size 1 0.13466014 0.13872541146376335 -0.6785893279568453\n",
            "Epoch: 0/10  Loss: 0.237088 Test loss: 0.107471Uttar-Pradesh n_f 5 t_s 7 n_layers 3 kernel_size 2 0.0604979 0.0679636605319429 0.5971104913946326\n",
            "Epoch: 0/10  Loss: 0.200368 Test loss: 0.346936Uttar-Pradesh n_f 5 t_s 7 n_layers 3 kernel_size 3 0.10943491 0.12190785087545437 -0.2962709687404401\n",
            "Epoch: 0/10  Loss: 0.149161 Test loss: 0.441065Uttar-Pradesh n_f 5 t_s 7 n_layers 3 kernel_size 4 0.07263735 0.09299031055706354 0.2457629894867256\n",
            "Epoch: 0/10  Loss: 0.257936 Test loss: 0.373573Uttar-Pradesh n_f 5 t_s 7 n_layers 4 kernel_size 1 0.3350365 0.33813254014808025 -8.972553366713877\n",
            "Epoch: 0/10  Loss: 0.211635 Test loss: 0.303711Uttar-Pradesh n_f 5 t_s 7 n_layers 4 kernel_size 2 0.03705379 0.04188101629418069 0.8470086523393767\n",
            "Epoch: 0/10  Loss: 0.158284 Test loss: 0.319126Uttar-Pradesh n_f 5 t_s 7 n_layers 4 kernel_size 3 0.1319173 0.13657320995365754 -0.6269098350321041\n",
            "Epoch: 0/10  Loss: 0.138480 Test loss: 0.463602Uttar-Pradesh n_f 5 t_s 7 n_layers 4 kernel_size 4 0.23376712 0.24003927325494762 -4.025705250661986\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.290386 Test loss: 0.449161Uttar-Pradesh n_f 6 t_s 5 n_layers 2 kernel_size 1 0.13329424 0.1386749441854902 -0.30179916762460723\n",
            "Epoch: 0/10  Loss: 0.117745 Test loss: 0.028506Uttar-Pradesh n_f 6 t_s 5 n_layers 2 kernel_size 2 0.051166046 0.06172850847055629 0.7420594811497698\n",
            "Epoch: 0/10  Loss: 0.122001 Test loss: 0.037650Uttar-Pradesh n_f 6 t_s 5 n_layers 2 kernel_size 3 0.039975714 0.049578398040593094 0.833607786807856\n",
            "Epoch: 0/10  Loss: 0.126933 Test loss: 0.213706Uttar-Pradesh n_f 6 t_s 5 n_layers 2 kernel_size 4 0.14534073 0.15123592345687187 -0.5483101897068379\n",
            "Epoch: 0/10  Loss: 0.363453 Test loss: 0.084203Uttar-Pradesh n_f 6 t_s 5 n_layers 3 kernel_size 1 0.045502637 0.04827785370433385 0.8422229041833514\n",
            "Epoch: 0/10  Loss: 0.255744 Test loss: 0.200999Uttar-Pradesh n_f 6 t_s 5 n_layers 3 kernel_size 2 0.31084314 0.31836631392891523 -5.86123360864933\n",
            "Epoch: 0/10  Loss: 0.174298 Test loss: 0.335117Uttar-Pradesh n_f 6 t_s 5 n_layers 3 kernel_size 3 0.037166964 0.046415575989692384 0.8541604040248204\n",
            "Epoch: 0/10  Loss: 0.124789 Test loss: 0.048885Uttar-Pradesh n_f 6 t_s 5 n_layers 3 kernel_size 4 0.17858191 0.1866123926039632 -1.357376690149736\n",
            "Epoch: 0/10  Loss: 0.414770 Test loss: 0.448674Uttar-Pradesh n_f 6 t_s 5 n_layers 4 kernel_size 1 0.16591391 0.17112691592654922 -0.9823699267736759\n",
            "Epoch: 0/10  Loss: 0.175021 Test loss: 0.203707Uttar-Pradesh n_f 6 t_s 5 n_layers 4 kernel_size 2 0.14815801 0.15215275480440063 -0.5671394559777871\n",
            "Epoch: 0/10  Loss: 0.120604 Test loss: 0.182382Uttar-Pradesh n_f 6 t_s 5 n_layers 4 kernel_size 3 0.016996829 0.02088924669885505 0.9704611509099854\n",
            "Epoch: 0/10  Loss: 0.147804 Test loss: 0.312126Uttar-Pradesh n_f 6 t_s 5 n_layers 4 kernel_size 4 0.13536994 0.14184547332377376 -0.36200590702185\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.522593 Test loss: 0.139486Uttar-Pradesh n_f 6 t_s 7 n_layers 2 kernel_size 1 0.016662965 0.019751801078665334 0.9659712642001254\n",
            "Epoch: 0/10  Loss: 0.131699 Test loss: 0.272052Uttar-Pradesh n_f 6 t_s 7 n_layers 2 kernel_size 2 0.0126818735 0.01843653646700318 0.9703522885953724\n",
            "Epoch: 0/10  Loss: 0.183860 Test loss: 0.005073Uttar-Pradesh n_f 6 t_s 7 n_layers 2 kernel_size 3 0.24044453 0.2477841600494255 -4.355247200244144\n",
            "Epoch: 0/10  Loss: 0.138275 Test loss: 0.021632Uttar-Pradesh n_f 6 t_s 7 n_layers 2 kernel_size 4 0.0583822 0.0671566262946896 0.6066218883346264\n",
            "Epoch: 0/10  Loss: 0.419456 Test loss: 0.207935Uttar-Pradesh n_f 6 t_s 7 n_layers 3 kernel_size 1 0.33006015 0.33784659876128265 -8.955693442415475\n",
            "Epoch: 0/10  Loss: 0.125361 Test loss: 0.262925Uttar-Pradesh n_f 6 t_s 7 n_layers 3 kernel_size 2 0.044434845 0.056883247093266316 0.7177712776444465\n",
            "Epoch: 0/10  Loss: 0.221183 Test loss: 0.695869Uttar-Pradesh n_f 6 t_s 7 n_layers 3 kernel_size 3 0.13769227 0.1430419601541963 -0.7846757184588715\n",
            "Epoch: 0/10  Loss: 0.154700 Test loss: 0.195809Uttar-Pradesh n_f 6 t_s 7 n_layers 3 kernel_size 4 0.0883962 0.11119771731430993 -0.07851002750868985\n",
            "Epoch: 0/10  Loss: 0.433643 Test loss: 0.169759Uttar-Pradesh n_f 6 t_s 7 n_layers 4 kernel_size 1 0.6801655 0.6905119764613876 -40.58865189402261\n",
            "Epoch: 0/10  Loss: 0.245141 Test loss: 0.124545Uttar-Pradesh n_f 6 t_s 7 n_layers 4 kernel_size 2 0.1327325 0.13869383463461385 -0.6778254626942752\n",
            "Epoch: 0/10  Loss: 0.224354 Test loss: 0.420004Uttar-Pradesh n_f 6 t_s 7 n_layers 4 kernel_size 3 0.37145692 0.376323054784158 -11.352478333265996\n",
            "Epoch: 0/10  Loss: 0.148046 Test loss: 0.188091Uttar-Pradesh n_f 6 t_s 7 n_layers 4 kernel_size 4 0.14692712 0.15667080838121977 -1.1409602007151989\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.137322 Test loss: 0.520575Kerala n_f 1 t_s 5 n_layers 2 kernel_size 1 0.07926591 0.08122487470603812 0.6223348210877641\n",
            "Epoch: 0/10  Loss: 0.152834 Test loss: 0.273149Kerala n_f 1 t_s 5 n_layers 2 kernel_size 2 0.079657994 0.08026961656280296 0.6311657859762252\n",
            "Epoch: 0/10  Loss: 0.128100 Test loss: 0.356592Kerala n_f 1 t_s 5 n_layers 2 kernel_size 3 0.09335779 0.09430527159025118 0.49090268728126096\n",
            "Epoch: 0/10  Loss: 0.120664 Test loss: 0.448664Kerala n_f 1 t_s 5 n_layers 2 kernel_size 4 0.03343864 0.03498017571623134 0.9299557058736285\n",
            "Epoch: 0/10  Loss: 0.170994 Test loss: 0.501011Kerala n_f 1 t_s 5 n_layers 3 kernel_size 1 0.2376194 0.24359737991799607 -2.3968317961851344\n",
            "Epoch: 0/10  Loss: 0.179087 Test loss: 0.180567Kerala n_f 1 t_s 5 n_layers 3 kernel_size 2 0.1682274 0.17289476339711127 -0.7111676417173942\n",
            "Epoch: 0/10  Loss: 0.175013 Test loss: 0.133141Kerala n_f 1 t_s 5 n_layers 3 kernel_size 3 0.0075732986 0.009173116383338748 0.9951831546539411\n",
            "Epoch: 0/10  Loss: 0.147741 Test loss: 0.188732Kerala n_f 1 t_s 5 n_layers 3 kernel_size 4 0.13326535 0.13684235162754435 -0.07193852994046357\n",
            "Epoch: 0/10  Loss: 0.144265 Test loss: 0.415917Kerala n_f 1 t_s 5 n_layers 4 kernel_size 1 0.43496615 0.44296240154473776 -10.232141528345384\n",
            "Epoch: 0/10  Loss: 0.143778 Test loss: 0.285270Kerala n_f 1 t_s 5 n_layers 4 kernel_size 2 0.284442 0.2924733869558183 -3.8966786434903744\n",
            "Epoch: 0/10  Loss: 0.132273 Test loss: 0.268343Kerala n_f 1 t_s 5 n_layers 4 kernel_size 3 0.068673745 0.07089677091484015 0.7122722402660886\n",
            "Epoch: 0/10  Loss: 0.125292 Test loss: 0.237581Kerala n_f 1 t_s 5 n_layers 4 kernel_size 4 0.037050553 0.043423496390826405 0.8920609876686816\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.144409 Test loss: 0.236459Kerala n_f 1 t_s 7 n_layers 2 kernel_size 1 0.10503391 0.10545254070619203 0.06809026657228945\n",
            "Epoch: 0/10  Loss: 0.132455 Test loss: 0.340099Kerala n_f 1 t_s 7 n_layers 2 kernel_size 2 0.16082256 0.16151097167689688 -1.1860689749728084\n",
            "Epoch: 0/10  Loss: 0.155453 Test loss: 0.422760Kerala n_f 1 t_s 7 n_layers 2 kernel_size 3 0.054216865 0.05456919731770112 0.750451527470283\n",
            "Epoch: 0/10  Loss: 0.099498 Test loss: 0.279578Kerala n_f 1 t_s 7 n_layers 2 kernel_size 4 0.092923805 0.09383799476391472 0.26206659808538824\n",
            "Epoch: 0/10  Loss: 0.224343 Test loss: 0.405131Kerala n_f 1 t_s 7 n_layers 3 kernel_size 1 0.0850562 0.08670086912581075 0.37004914243828935\n",
            "Epoch: 0/10  Loss: 0.116777 Test loss: 0.296109Kerala n_f 1 t_s 7 n_layers 3 kernel_size 2 0.16587822 0.1661329191643906 -1.3129761734575838\n",
            "Epoch: 0/10  Loss: 0.121668 Test loss: 0.200817Kerala n_f 1 t_s 7 n_layers 3 kernel_size 3 0.08054493 0.08172904558314195 0.4402260972237826\n",
            "Epoch: 0/10  Loss: 0.164447 Test loss: 0.257358Kerala n_f 1 t_s 7 n_layers 3 kernel_size 4 0.036930624 0.03753335985112385 0.8819422161879508\n",
            "Epoch: 0/10  Loss: 0.194302 Test loss: 0.327957Kerala n_f 1 t_s 7 n_layers 4 kernel_size 1 0.31054053 0.31357001459516376 -7.240029403314811\n",
            "Epoch: 0/10  Loss: 0.102466 Test loss: 0.474063Kerala n_f 1 t_s 7 n_layers 4 kernel_size 2 0.06701319 0.0679042447040272 0.6135852705960515\n",
            "Epoch: 0/10  Loss: 0.154603 Test loss: 0.191983Kerala n_f 1 t_s 7 n_layers 4 kernel_size 3 0.06711529 0.06832221928766108 0.6088136626161262\n",
            "Epoch: 0/10  Loss: 0.151471 Test loss: 0.228210Kerala n_f 1 t_s 7 n_layers 4 kernel_size 4 0.020274006 0.021853215043437336 0.9599787699213985\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.148294 Test loss: 0.572105Kerala n_f 2 t_s 5 n_layers 2 kernel_size 1 0.2521649 0.25892257125601575 -2.837679145732496\n",
            "Epoch: 0/10  Loss: 0.091512 Test loss: 0.312544Kerala n_f 2 t_s 5 n_layers 2 kernel_size 2 0.35120443 0.3566727004402413 -6.28229978253878\n",
            "Epoch: 0/10  Loss: 0.095377 Test loss: 0.419280Kerala n_f 2 t_s 5 n_layers 2 kernel_size 3 0.2146437 0.22070363137516233 -1.7883529933142084\n",
            "Epoch: 0/10  Loss: 0.179631 Test loss: 0.402910Kerala n_f 2 t_s 5 n_layers 2 kernel_size 4 0.317821 0.3276573549869589 -5.14566286805677\n",
            "Epoch: 0/10  Loss: 0.119415 Test loss: 0.360448Kerala n_f 2 t_s 5 n_layers 3 kernel_size 1 0.26496816 0.2706694412743024 -3.193795752119393\n",
            "Epoch: 0/10  Loss: 0.166923 Test loss: 0.285122Kerala n_f 2 t_s 5 n_layers 3 kernel_size 2 0.18996592 0.19254255682076254 -1.122180571405202\n",
            "Epoch: 0/10  Loss: 0.129056 Test loss: 0.358193Kerala n_f 2 t_s 5 n_layers 3 kernel_size 3 0.23849194 0.24389290258089644 -2.4050788617920853\n",
            "Epoch: 0/10  Loss: 0.119140 Test loss: 0.249926Kerala n_f 2 t_s 5 n_layers 3 kernel_size 4 0.2938409 0.302689998204447 -4.2447524421939455\n",
            "Epoch: 0/10  Loss: 0.135825 Test loss: 0.281852Kerala n_f 2 t_s 5 n_layers 4 kernel_size 1 0.43275768 0.43516243017660317 -9.840057585970234\n",
            "Epoch: 0/10  Loss: 0.127189 Test loss: 0.421192Kerala n_f 2 t_s 5 n_layers 4 kernel_size 2 0.25989285 0.2641772195942464 -2.9950250628288297\n",
            "Epoch: 0/10  Loss: 0.157042 Test loss: 0.339320Kerala n_f 2 t_s 5 n_layers 4 kernel_size 3 0.3342411 0.3418273585213671 -5.688712210420795\n",
            "Epoch: 0/10  Loss: 0.143649 Test loss: 0.308330Kerala n_f 2 t_s 5 n_layers 4 kernel_size 4 0.32712305 0.3333000511700167 -5.359158062170273\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.400282 Test loss: 0.460944Kerala n_f 2 t_s 7 n_layers 2 kernel_size 1 0.16675292 0.16777891698555608 -1.3590355911343348\n",
            "Epoch: 0/10  Loss: 0.126222 Test loss: 0.355920Kerala n_f 2 t_s 7 n_layers 2 kernel_size 2 0.20961262 0.20986656907081405 -2.6910187680094784\n",
            "Epoch: 0/10  Loss: 0.100765 Test loss: 0.288451Kerala n_f 2 t_s 7 n_layers 2 kernel_size 3 0.17633793 0.17740792907100345 -1.637581093881587\n",
            "Epoch: 0/10  Loss: 0.116142 Test loss: 0.511346Kerala n_f 2 t_s 7 n_layers 2 kernel_size 4 0.06522813 0.0659281758070576 0.6357480410480376\n",
            "Epoch: 0/10  Loss: 0.139927 Test loss: 0.222520Kerala n_f 2 t_s 7 n_layers 3 kernel_size 1 0.50306153 0.5079298324015615 -20.620572860991263\n",
            "Epoch: 0/10  Loss: 0.149475 Test loss: 0.497162Kerala n_f 2 t_s 7 n_layers 3 kernel_size 2 0.19873518 0.19942632781296013 -2.3329188422289\n",
            "Epoch: 0/10  Loss: 0.128743 Test loss: 0.512288Kerala n_f 2 t_s 7 n_layers 3 kernel_size 3 0.30170313 0.30365664373994344 -6.727257004489965\n",
            "Epoch: 0/10  Loss: 0.130280 Test loss: 0.281763Kerala n_f 2 t_s 7 n_layers 3 kernel_size 4 0.10652521 0.10825542088220778 0.01789239579467572\n",
            "Epoch: 0/10  Loss: 0.126773 Test loss: 0.236718Kerala n_f 2 t_s 7 n_layers 4 kernel_size 1 0.2583036 0.260412028589272 -4.683054886953114\n",
            "Epoch: 0/10  Loss: 0.113420 Test loss: 0.440732Kerala n_f 2 t_s 7 n_layers 4 kernel_size 2 0.20162681 0.20426338570469701 -2.4965589432565514\n",
            "Epoch: 0/10  Loss: 0.141251 Test loss: 0.218122Kerala n_f 2 t_s 7 n_layers 4 kernel_size 3 0.2169347 0.2185025262844816 -3.001037901783307\n",
            "Epoch: 0/10  Loss: 0.102196 Test loss: 0.465944Kerala n_f 2 t_s 7 n_layers 4 kernel_size 4 0.282896 0.2859919334671218 -5.85436627136558\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.177522 Test loss: 0.208198Kerala n_f 3 t_s 5 n_layers 2 kernel_size 1 0.14449666 0.15869994507338264 -0.4417249672503485\n",
            "Epoch: 0/10  Loss: 0.168730 Test loss: 0.248459Kerala n_f 3 t_s 5 n_layers 2 kernel_size 2 0.17046717 0.17403798882713678 -0.7338715692260966\n",
            "Epoch: 0/10  Loss: 0.077868 Test loss: 0.252874Kerala n_f 3 t_s 5 n_layers 2 kernel_size 3 0.1668649 0.1716865785537228 -0.6873358671378411\n",
            "Epoch: 0/10  Loss: 0.138659 Test loss: 0.342278Kerala n_f 3 t_s 5 n_layers 2 kernel_size 4 0.019523859 0.021109012594383993 0.9744926896338731\n",
            "Epoch: 0/10  Loss: 0.100673 Test loss: 0.163796Kerala n_f 3 t_s 5 n_layers 3 kernel_size 1 0.14417502 0.14634940605181523 -0.22605734599766203\n",
            "Epoch: 0/10  Loss: 0.119973 Test loss: 0.598320Kerala n_f 3 t_s 5 n_layers 3 kernel_size 2 0.18352371 0.18834903335819445 -1.0307459140130666\n",
            "Epoch: 0/10  Loss: 0.137852 Test loss: 0.593560Kerala n_f 3 t_s 5 n_layers 3 kernel_size 3 0.06943997 0.07671258737029361 0.6631301689095221\n",
            "Epoch: 0/10  Loss: 0.163337 Test loss: 0.240871Kerala n_f 3 t_s 5 n_layers 3 kernel_size 4 0.14343742 0.1506295411921167 -0.2988206087052421\n",
            "Epoch: 0/10  Loss: 0.157353 Test loss: 0.415468Kerala n_f 3 t_s 5 n_layers 4 kernel_size 1 0.174357 0.18004538306681053 -0.8556361754185833\n",
            "Epoch: 0/10  Loss: 0.096868 Test loss: 0.481357Kerala n_f 3 t_s 5 n_layers 4 kernel_size 2 0.25862387 0.2654527358040417 -3.033696429682599\n",
            "Epoch: 0/10  Loss: 0.154298 Test loss: 0.557663Kerala n_f 3 t_s 5 n_layers 4 kernel_size 3 0.2741435 0.2834431913281818 -3.598973526602906\n",
            "Epoch: 0/10  Loss: 0.179632 Test loss: 0.118657Kerala n_f 3 t_s 5 n_layers 4 kernel_size 4 0.11852983 0.1256217840124672 0.09664444072297651\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.275736 Test loss: 0.078102Kerala n_f 3 t_s 7 n_layers 2 kernel_size 1 0.099113375 0.10029936679984176 0.15694454846212835\n",
            "Epoch: 0/10  Loss: 0.147259 Test loss: 0.437923Kerala n_f 3 t_s 7 n_layers 2 kernel_size 2 0.107690886 0.11368449147659736 -0.08308412991000402\n",
            "Epoch: 0/10  Loss: 0.283937 Test loss: 0.233225Kerala n_f 3 t_s 7 n_layers 2 kernel_size 3 0.06323381 0.06656453258249648 0.6286824348883577\n",
            "Epoch: 0/10  Loss: 0.201156 Test loss: 0.332935Kerala n_f 3 t_s 7 n_layers 2 kernel_size 4 0.0077313413 0.008725222140121239 0.9936201165762019\n",
            "Epoch: 0/10  Loss: 0.190039 Test loss: 0.396236Kerala n_f 3 t_s 7 n_layers 3 kernel_size 1 0.20705055 0.20806769283709392 -2.628014411091975\n",
            "Epoch: 0/10  Loss: 0.151021 Test loss: 0.221479Kerala n_f 3 t_s 7 n_layers 3 kernel_size 2 0.26197106 0.26522686516491323 -4.895148367503984\n",
            "Epoch: 0/10  Loss: 0.234620 Test loss: 0.242607Kerala n_f 3 t_s 7 n_layers 3 kernel_size 3 0.079219036 0.08130944386041723 0.4459592561141943\n",
            "Epoch: 0/10  Loss: 0.168455 Test loss: 0.341669Kerala n_f 3 t_s 7 n_layers 3 kernel_size 4 0.28329998 0.28873356584540544 -5.986413712683099\n",
            "Epoch: 0/10  Loss: 0.235343 Test loss: 0.152505Kerala n_f 3 t_s 7 n_layers 4 kernel_size 1 0.25569355 0.25994496858933075 -4.662686897464381\n",
            "Epoch: 0/10  Loss: 0.117058 Test loss: 0.527242Kerala n_f 3 t_s 7 n_layers 4 kernel_size 2 0.21982911 0.22323720831336932 -3.176312231124502\n",
            "Epoch: 0/10  Loss: 0.131457 Test loss: 0.551297Kerala n_f 3 t_s 7 n_layers 4 kernel_size 3 0.2092811 0.2131156694349844 -2.8061905644000547\n",
            "Epoch: 0/10  Loss: 0.097935 Test loss: 0.359265Kerala n_f 3 t_s 7 n_layers 4 kernel_size 4 0.07683734 0.07869325739789143 0.4810389381361445\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.275023 Test loss: 0.709938Kerala n_f 4 t_s 5 n_layers 2 kernel_size 1 0.08729038 0.09630637874001753 0.46906796218215085\n",
            "Epoch: 0/10  Loss: 0.109555 Test loss: 0.187115Kerala n_f 4 t_s 5 n_layers 2 kernel_size 2 0.08098364 0.09382562269515704 0.4960682513717318\n",
            "Epoch: 0/10  Loss: 0.155874 Test loss: 0.031641Kerala n_f 4 t_s 5 n_layers 2 kernel_size 3 0.04034076 0.05713056089173233 0.8131617415154916\n",
            "Epoch: 0/10  Loss: 0.074117 Test loss: 0.077193Kerala n_f 4 t_s 5 n_layers 2 kernel_size 4 0.15202904 0.16529664135710964 -0.5640725837385587\n",
            "Epoch: 0/10  Loss: 0.161477 Test loss: 0.156642Kerala n_f 4 t_s 5 n_layers 3 kernel_size 1 0.25746277 0.2668991803107354 -3.0777758440507395\n",
            "Epoch: 0/10  Loss: 0.131297 Test loss: 0.478424Kerala n_f 4 t_s 5 n_layers 3 kernel_size 2 0.38075244 0.40202476300529755 -8.251974784525153\n",
            "Epoch: 0/10  Loss: 0.116111 Test loss: 0.303733Kerala n_f 4 t_s 5 n_layers 3 kernel_size 3 0.12517251 0.13984175286385375 -0.11944449448468064\n",
            "Epoch: 0/10  Loss: 0.073108 Test loss: 0.140851Kerala n_f 4 t_s 5 n_layers 3 kernel_size 4 0.05168995 0.05641036461447658 0.8178426740563451\n",
            "Epoch: 0/10  Loss: 0.184015 Test loss: 0.603156Kerala n_f 4 t_s 5 n_layers 4 kernel_size 1 0.20893374 0.2189448289414986 -1.7440892812190514\n",
            "Epoch: 0/10  Loss: 0.112858 Test loss: 0.266920Kerala n_f 4 t_s 5 n_layers 4 kernel_size 2 0.2591421 0.27420642912048493 -3.3041178912729077\n",
            "Epoch: 0/10  Loss: 0.112313 Test loss: 0.553827Kerala n_f 4 t_s 5 n_layers 4 kernel_size 3 0.25429055 0.26475539632598244 -3.0125315129457135\n",
            "Epoch: 0/10  Loss: 0.165199 Test loss: 0.328561Kerala n_f 4 t_s 5 n_layers 4 kernel_size 4 0.15225373 0.16879297014024444 -0.6309383493920206\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.221114 Test loss: 0.314334Kerala n_f 4 t_s 7 n_layers 2 kernel_size 1 0.085283354 0.10011109982905893 0.160106594952373\n",
            "Epoch: 0/10  Loss: 0.135552 Test loss: 0.431338Kerala n_f 4 t_s 7 n_layers 2 kernel_size 2 0.2543898 0.2737546171817972 -5.280332656052759\n",
            "Epoch: 0/10  Loss: 0.137901 Test loss: 0.429908Kerala n_f 4 t_s 7 n_layers 2 kernel_size 3 0.14112699 0.1569740566083455 -1.064978284274531\n",
            "Epoch: 0/10  Loss: 0.124577 Test loss: 0.150757Kerala n_f 4 t_s 7 n_layers 2 kernel_size 4 0.06703576 0.08803193864749385 0.35055811952204685\n",
            "Epoch: 0/10  Loss: 0.344690 Test loss: 0.388586Kerala n_f 4 t_s 7 n_layers 3 kernel_size 1 0.37517217 0.3851072663270238 -11.428627692785694\n",
            "Epoch: 0/10  Loss: 0.156718 Test loss: 0.104536Kerala n_f 4 t_s 7 n_layers 3 kernel_size 2 0.14945664 0.16024569014386444 -1.1519515755581473\n",
            "Epoch: 0/10  Loss: 0.200197 Test loss: 0.796913Kerala n_f 4 t_s 7 n_layers 3 kernel_size 3 0.3353147 0.34918050193841 -9.217854604517848\n",
            "Epoch: 0/10  Loss: 0.164110 Test loss: 0.640660Kerala n_f 4 t_s 7 n_layers 3 kernel_size 4 0.29356214 0.30764097091529036 -6.931368022637976\n",
            "Epoch: 0/10  Loss: 0.262951 Test loss: 0.094917Kerala n_f 4 t_s 7 n_layers 4 kernel_size 1 0.08257668 0.09811048723827609 0.19333983371772157\n",
            "Epoch: 0/10  Loss: 0.218687 Test loss: 0.099216Kerala n_f 4 t_s 7 n_layers 4 kernel_size 2 0.24003008 0.24988017339775284 -4.232669932334811\n",
            "Epoch: 0/10  Loss: 0.140881 Test loss: 0.424556Kerala n_f 4 t_s 7 n_layers 4 kernel_size 3 0.05083098 0.056071694133559113 0.7365203385430076\n",
            "Epoch: 0/10  Loss: 0.139151 Test loss: 0.489407Kerala n_f 4 t_s 7 n_layers 4 kernel_size 4 0.18373092 0.19512356202611683 -2.190650195444696\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.283173 Test loss: 0.052361Kerala n_f 5 t_s 5 n_layers 2 kernel_size 1 0.058602594 0.07731008495399726 0.6578621227799959\n",
            "Epoch: 0/10  Loss: 0.265444 Test loss: 0.668682Kerala n_f 5 t_s 5 n_layers 2 kernel_size 2 0.053329643 0.0733950577252642 0.6916368421401523\n",
            "Epoch: 0/10  Loss: 0.110155 Test loss: 0.215974Kerala n_f 5 t_s 5 n_layers 2 kernel_size 3 0.20986499 0.22562800258794247 -1.9141699743514287\n",
            "Epoch: 0/10  Loss: 0.087737 Test loss: 0.008235Kerala n_f 5 t_s 5 n_layers 2 kernel_size 4 0.10890403 0.12084517037301959 0.16403630469954122\n",
            "Epoch: 0/10  Loss: 0.218865 Test loss: 0.240789Kerala n_f 5 t_s 5 n_layers 3 kernel_size 1 0.19797707 0.20487660997746163 -1.4027779836205294\n",
            "Epoch: 0/10  Loss: 0.153929 Test loss: 0.132107Kerala n_f 5 t_s 5 n_layers 3 kernel_size 2 0.24364397 0.2559314364226196 -2.749524070195578\n",
            "Epoch: 0/10  Loss: 0.105844 Test loss: 0.234920Kerala n_f 5 t_s 5 n_layers 3 kernel_size 3 0.11333645 0.12794055601354662 0.06298760656060254\n",
            "Epoch: 0/10  Loss: 0.142106 Test loss: 0.393068Kerala n_f 5 t_s 5 n_layers 3 kernel_size 4 0.24464491 0.25659625397067765 -2.769029084756189\n",
            "Epoch: 0/10  Loss: 0.374417 Test loss: 0.291809Kerala n_f 5 t_s 5 n_layers 4 kernel_size 1 0.056312855 0.07558168502792197 0.6729892812315883\n",
            "Epoch: 0/10  Loss: 0.110506 Test loss: 0.378523Kerala n_f 5 t_s 5 n_layers 4 kernel_size 2 0.44923684 0.45703586347810865 -10.957197148673664\n",
            "Epoch: 0/10  Loss: 0.118573 Test loss: 0.376956Kerala n_f 5 t_s 5 n_layers 4 kernel_size 3 0.068543896 0.0928127757543584 0.506889370512698\n",
            "Epoch: 0/10  Loss: 0.116062 Test loss: 0.513215Kerala n_f 5 t_s 5 n_layers 4 kernel_size 4 0.16708584 0.17843351040670785 -0.8225593413954133\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.160318 Test loss: 0.128866Kerala n_f 5 t_s 7 n_layers 2 kernel_size 1 0.09736478 0.1182974661327482 -0.17276402259061574\n",
            "Epoch: 0/10  Loss: 0.227563 Test loss: 0.304075Kerala n_f 5 t_s 7 n_layers 2 kernel_size 2 0.13285123 0.13722988359193466 -0.5781822116075137\n",
            "Epoch: 0/10  Loss: 0.161963 Test loss: 0.394302Kerala n_f 5 t_s 7 n_layers 2 kernel_size 3 0.04109363 0.05512579620201533 0.7453348595439171\n",
            "Epoch: 0/10  Loss: 0.159056 Test loss: 0.034425Kerala n_f 5 t_s 7 n_layers 2 kernel_size 4 0.14723833 0.15816644549488337 -1.096468965712754\n",
            "Epoch: 0/10  Loss: 0.487266 Test loss: 0.161231Kerala n_f 5 t_s 7 n_layers 3 kernel_size 1 0.2016361 0.2098882416250696 -2.6917811855713762\n",
            "Epoch: 0/10  Loss: 0.320019 Test loss: 0.372596Kerala n_f 5 t_s 7 n_layers 3 kernel_size 2 0.120733246 0.1303033831492382 -0.42288947955890843\n",
            "Epoch: 0/10  Loss: 0.137383 Test loss: 0.094301Kerala n_f 5 t_s 7 n_layers 3 kernel_size 3 0.18135637 0.1898994399439883 -2.022088054827712\n",
            "Epoch: 0/10  Loss: 0.176063 Test loss: 0.521324Kerala n_f 5 t_s 7 n_layers 3 kernel_size 4 0.21541817 0.22596696158993768 -3.279072600613766\n",
            "Epoch: 0/10  Loss: 0.388546 Test loss: 0.211249Kerala n_f 5 t_s 7 n_layers 4 kernel_size 1 0.17189862 0.18330904007659668 -1.8159665469962913\n",
            "Epoch: 0/10  Loss: 0.182987 Test loss: 0.313958Kerala n_f 5 t_s 7 n_layers 4 kernel_size 2 0.034622915 0.04607176266390476 0.8221190543107209\n",
            "Epoch: 0/10  Loss: 0.152092 Test loss: 0.407768Kerala n_f 5 t_s 7 n_layers 4 kernel_size 3 0.12311355 0.1391021339856829 -0.6215386677505366\n",
            "Epoch: 0/10  Loss: 0.140241 Test loss: 0.222044Kerala n_f 5 t_s 7 n_layers 4 kernel_size 4 0.039576452 0.05493258581407961 0.7471169002884084\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.244069 Test loss: 0.108353Kerala n_f 6 t_s 5 n_layers 2 kernel_size 1 0.06102828 0.07046432792085244 0.7157715998594265\n",
            "Epoch: 0/10  Loss: 0.182860 Test loss: 0.108694Kerala n_f 6 t_s 5 n_layers 2 kernel_size 2 0.20924397 0.22164979808812374 -1.8123121101096231\n",
            "Epoch: 0/10  Loss: 0.099699 Test loss: 0.115784Kerala n_f 6 t_s 5 n_layers 2 kernel_size 3 0.087484166 0.10202162385399545 0.40418248595000095\n",
            "Epoch: 0/10  Loss: 0.304188 Test loss: 0.490661Kerala n_f 6 t_s 5 n_layers 2 kernel_size 4 0.028430669 0.03670523038241972 0.9228768516474743\n",
            "Epoch: 0/10  Loss: 0.354359 Test loss: 0.121523Kerala n_f 6 t_s 5 n_layers 3 kernel_size 1 0.13501666 0.1464819717210081 -0.2282795803315072\n",
            "Epoch: 0/10  Loss: 0.188722 Test loss: 0.275325Kerala n_f 6 t_s 5 n_layers 3 kernel_size 2 0.060789485 0.08106054434240789 0.6238614107988987\n",
            "Epoch: 0/10  Loss: 0.140684 Test loss: 0.202259Kerala n_f 6 t_s 5 n_layers 3 kernel_size 3 0.27169606 0.2831116364127314 -3.588221108013344\n",
            "Epoch: 0/10  Loss: 0.149982 Test loss: 0.235065Kerala n_f 6 t_s 5 n_layers 3 kernel_size 4 0.15672275 0.17096646725973694 -0.6732110780796621\n",
            "Epoch: 0/10  Loss: 0.333936 Test loss: 0.150164Kerala n_f 6 t_s 5 n_layers 4 kernel_size 1 0.2675463 0.2844727830136845 -3.6324454754901865\n",
            "Epoch: 0/10  Loss: 0.196980 Test loss: 0.234063Kerala n_f 6 t_s 5 n_layers 4 kernel_size 2 0.26047233 0.2738182414362191 -3.2919393066840197\n",
            "Epoch: 0/10  Loss: 0.155091 Test loss: 0.537855Kerala n_f 6 t_s 5 n_layers 4 kernel_size 3 0.17334786 0.191249053008409 -1.0937626164487058\n",
            "Epoch: 0/10  Loss: 0.116789 Test loss: 0.446022Kerala n_f 6 t_s 5 n_layers 4 kernel_size 4 0.09130872 0.12135702016924658 0.15693973572531483\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.544100 Test loss: 0.789598Kerala n_f 6 t_s 7 n_layers 2 kernel_size 1 0.15020278 0.16186763364644863 -1.1957344180693155\n",
            "Epoch: 0/10  Loss: 0.106823 Test loss: 0.294094Kerala n_f 6 t_s 7 n_layers 2 kernel_size 2 0.12134814 0.12792462054985268 -0.3714121697559276\n",
            "Epoch: 0/10  Loss: 0.170524 Test loss: 0.014024Kerala n_f 6 t_s 7 n_layers 2 kernel_size 3 0.046894133 0.05340915560156397 0.7609486512955488\n",
            "Epoch: 0/10  Loss: 0.122574 Test loss: 0.206022Kerala n_f 6 t_s 7 n_layers 2 kernel_size 4 0.052828167 0.06060291012272134 0.6922155070506348\n",
            "Epoch: 0/10  Loss: 0.308128 Test loss: 0.152677Kerala n_f 6 t_s 7 n_layers 3 kernel_size 1 0.077796765 0.08917756949911852 0.3335447498211579\n",
            "Epoch: 0/10  Loss: 0.216875 Test loss: 0.128215Kerala n_f 6 t_s 7 n_layers 3 kernel_size 2 0.11804269 0.13447094918291563 -0.5153629116930334\n",
            "Epoch: 0/10  Loss: 0.218374 Test loss: 0.126940Kerala n_f 6 t_s 7 n_layers 3 kernel_size 3 0.0926662 0.09929941138863063 0.17367085182028463\n",
            "Epoch: 0/10  Loss: 0.120087 Test loss: 0.130309Kerala n_f 6 t_s 7 n_layers 3 kernel_size 4 0.04740279 0.06510168746360359 0.6448235221309648\n",
            "Epoch: 0/10  Loss: 0.342671 Test loss: 0.013912Kerala n_f 6 t_s 7 n_layers 4 kernel_size 1 0.21110249 0.22862488832465813 -3.3803295260414528\n",
            "Epoch: 0/10  Loss: 0.194862 Test loss: 0.227632Kerala n_f 6 t_s 7 n_layers 4 kernel_size 2 0.28183347 0.29359729734250056 -6.223768915026503\n",
            "Epoch: 0/10  Loss: 0.174497 Test loss: 0.780302Kerala n_f 6 t_s 7 n_layers 4 kernel_size 3 0.12448327 0.13778065681200047 -0.5908757117537495\n",
            "Epoch: 0/10  Loss: 0.121035 Test loss: 0.206198Kerala n_f 6 t_s 7 n_layers 4 kernel_size 4 0.04782802 0.05463176254071964 0.7498789824144425\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.155001 Test loss: 0.396026Tamil-Nadu n_f 1 t_s 5 n_layers 2 kernel_size 1 0.1499381 0.15042783846495136 -0.0643325695211805\n",
            "Epoch: 0/10  Loss: 0.125513 Test loss: 0.400395Tamil-Nadu n_f 1 t_s 5 n_layers 2 kernel_size 2 0.0472316 0.0550595912626475 0.8574107046521557\n",
            "Epoch: 0/10  Loss: 0.127488 Test loss: 0.227291Tamil-Nadu n_f 1 t_s 5 n_layers 2 kernel_size 3 0.04456598 0.05462345349413539 0.8596607246283131\n",
            "Epoch: 0/10  Loss: 0.095146 Test loss: 0.322614Tamil-Nadu n_f 1 t_s 5 n_layers 2 kernel_size 4 0.15045717 0.15452718446858796 -0.12313171617818575\n",
            "Epoch: 0/10  Loss: 0.113001 Test loss: 0.482868Tamil-Nadu n_f 1 t_s 5 n_layers 3 kernel_size 1 0.043282885 0.0535138263017253 0.8653045555617236\n",
            "Epoch: 0/10  Loss: 0.110283 Test loss: 0.407905Tamil-Nadu n_f 1 t_s 5 n_layers 3 kernel_size 2 0.06871952 0.07899281891966695 0.7065080982925225\n",
            "Epoch: 0/10  Loss: 0.094906 Test loss: 0.376077Tamil-Nadu n_f 1 t_s 5 n_layers 3 kernel_size 3 0.106618956 0.11731086833446115 0.3527121373132619\n",
            "Epoch: 0/10  Loss: 0.139323 Test loss: 0.369201Tamil-Nadu n_f 1 t_s 5 n_layers 3 kernel_size 4 0.079078436 0.09107550280420672 0.6098567754901918\n",
            "Epoch: 0/10  Loss: 0.147699 Test loss: 0.302872Tamil-Nadu n_f 1 t_s 5 n_layers 4 kernel_size 1 0.14289509 0.14365719359799356 0.029320881177646307\n",
            "Epoch: 0/10  Loss: 0.096380 Test loss: 0.381130Tamil-Nadu n_f 1 t_s 5 n_layers 4 kernel_size 2 0.068276644 0.08814907486166278 0.6345260493718857\n",
            "Epoch: 0/10  Loss: 0.126904 Test loss: 0.317461Tamil-Nadu n_f 1 t_s 5 n_layers 4 kernel_size 3 0.050611075 0.06388888690386703 0.808013118958269\n",
            "Epoch: 0/10  Loss: 0.099235 Test loss: 0.376246Tamil-Nadu n_f 1 t_s 5 n_layers 4 kernel_size 4 0.11727127 0.12639008156929232 0.24864202116599254\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.247393 Test loss: 0.168492Tamil-Nadu n_f 1 t_s 7 n_layers 2 kernel_size 1 0.010636944 0.011651795317374645 0.9920034627297243\n",
            "Epoch: 0/10  Loss: 0.164238 Test loss: 0.409545Tamil-Nadu n_f 1 t_s 7 n_layers 2 kernel_size 2 0.12607913 0.1295516445775843 0.011441928916938404\n",
            "Epoch: 0/10  Loss: 0.171902 Test loss: 0.449095Tamil-Nadu n_f 1 t_s 7 n_layers 2 kernel_size 3 0.06326247 0.07330055771937695 0.6835312517483293\n",
            "Epoch: 0/10  Loss: 0.090732 Test loss: 0.180926Tamil-Nadu n_f 1 t_s 7 n_layers 2 kernel_size 4 0.08197403 0.08851765442598276 0.5384953296660707\n",
            "Epoch: 0/10  Loss: 0.125923 Test loss: 0.410170Tamil-Nadu n_f 1 t_s 7 n_layers 3 kernel_size 1 0.24827138 0.24998143246364565 -2.680711437411205\n",
            "Epoch: 0/10  Loss: 0.145242 Test loss: 0.349827Tamil-Nadu n_f 1 t_s 7 n_layers 3 kernel_size 2 0.055043425 0.059818261862180956 0.78924210986419\n",
            "Epoch: 0/10  Loss: 0.110207 Test loss: 0.390409Tamil-Nadu n_f 1 t_s 7 n_layers 3 kernel_size 3 0.08723511 0.09642432425180338 0.45236717048510056\n",
            "Epoch: 0/10  Loss: 0.147839 Test loss: 0.287919Tamil-Nadu n_f 1 t_s 7 n_layers 3 kernel_size 4 0.02533953 0.031046346265461926 0.9432275955509003\n",
            "Epoch: 0/10  Loss: 0.141122 Test loss: 0.511845Tamil-Nadu n_f 1 t_s 7 n_layers 4 kernel_size 1 0.23102628 0.23467999323129685 -2.2439072860720963\n",
            "Epoch: 0/10  Loss: 0.125482 Test loss: 0.434240Tamil-Nadu n_f 1 t_s 7 n_layers 4 kernel_size 2 0.03143545 0.033457834425648106 0.9340656127885234\n",
            "Epoch: 0/10  Loss: 0.100995 Test loss: 0.401344Tamil-Nadu n_f 1 t_s 7 n_layers 4 kernel_size 3 0.5920501 0.6006998837934635 -20.25354626654569\n",
            "Epoch: 0/10  Loss: 0.131011 Test loss: 0.241414Tamil-Nadu n_f 1 t_s 7 n_layers 4 kernel_size 4 0.1965302 0.2043689819348154 -1.4600629852609242\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.157617 Test loss: 0.113563Tamil-Nadu n_f 2 t_s 5 n_layers 2 kernel_size 1 0.06715458 0.07409029749324438 0.7418075025297024\n",
            "Epoch: 0/10  Loss: 0.121707 Test loss: 0.399716Tamil-Nadu n_f 2 t_s 5 n_layers 2 kernel_size 2 0.026270969 0.029968348151430003 0.9577577982963161\n",
            "Epoch: 0/10  Loss: 0.122281 Test loss: 0.240132Tamil-Nadu n_f 2 t_s 5 n_layers 2 kernel_size 3 0.07479003 0.08736075312152235 0.6410337142513391\n",
            "Epoch: 0/10  Loss: 0.117795 Test loss: 0.419099Tamil-Nadu n_f 2 t_s 5 n_layers 2 kernel_size 4 0.04134428 0.04242956328711874 0.9153244436356671\n",
            "Epoch: 0/10  Loss: 0.128067 Test loss: 0.406473Tamil-Nadu n_f 2 t_s 5 n_layers 3 kernel_size 1 0.20118703 0.20569925251701154 -0.9901523154526672\n",
            "Epoch: 0/10  Loss: 0.262798 Test loss: 0.136401Tamil-Nadu n_f 2 t_s 5 n_layers 3 kernel_size 2 0.057185102 0.07171832467349888 0.7580747340053691\n",
            "Epoch: 0/10  Loss: 0.105122 Test loss: 0.433467Tamil-Nadu n_f 2 t_s 5 n_layers 3 kernel_size 3 0.04094065 0.04521223229597157 0.9038536346481912\n",
            "Epoch: 0/10  Loss: 0.105732 Test loss: 0.397202Tamil-Nadu n_f 2 t_s 5 n_layers 3 kernel_size 4 0.028896578 0.03591410066894269 0.9393332189861014\n",
            "Epoch: 0/10  Loss: 0.097038 Test loss: 0.376277Tamil-Nadu n_f 2 t_s 5 n_layers 4 kernel_size 1 0.33839187 0.34940474931172716 -4.74220255179885\n",
            "Epoch: 0/10  Loss: 0.111125 Test loss: 0.443437Tamil-Nadu n_f 2 t_s 5 n_layers 4 kernel_size 2 0.20744395 0.21721492875433818 -1.2192196003367277\n",
            "Epoch: 0/10  Loss: 0.110763 Test loss: 0.307966Tamil-Nadu n_f 2 t_s 5 n_layers 4 kernel_size 3 0.20467749 0.21931047673948623 -1.2622451930901\n",
            "Epoch: 0/10  Loss: 0.107148 Test loss: 0.460831Tamil-Nadu n_f 2 t_s 5 n_layers 4 kernel_size 4 0.5310699 0.5405659373219639 -12.744162164325601\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.286162 Test loss: 0.032605Tamil-Nadu n_f 2 t_s 7 n_layers 2 kernel_size 1 0.08658013 0.08774836205807479 0.546482229610787\n",
            "Epoch: 0/10  Loss: 0.217148 Test loss: 0.185482Tamil-Nadu n_f 2 t_s 7 n_layers 2 kernel_size 2 0.15866144 0.16207452767187241 -0.5471977183595746\n",
            "Epoch: 0/10  Loss: 0.157289 Test loss: 0.099735Tamil-Nadu n_f 2 t_s 7 n_layers 2 kernel_size 3 0.03895923 0.048138113251775284 0.8635120262159449\n",
            "Epoch: 0/10  Loss: 0.144088 Test loss: 0.338640Tamil-Nadu n_f 2 t_s 7 n_layers 2 kernel_size 4 0.11036266 0.11609616341912526 0.20612524600074478\n",
            "Epoch: 0/10  Loss: 0.223197 Test loss: 0.497810Tamil-Nadu n_f 2 t_s 7 n_layers 3 kernel_size 1 0.15589204 0.15957409026624544 -0.4998266074143396\n",
            "Epoch: 0/10  Loss: 0.154461 Test loss: 0.539454Tamil-Nadu n_f 2 t_s 7 n_layers 3 kernel_size 2 0.26606467 0.2698814356276406 -3.2900498216525014\n",
            "Epoch: 0/10  Loss: 0.182279 Test loss: 0.298437Tamil-Nadu n_f 2 t_s 7 n_layers 3 kernel_size 3 0.13923712 0.14432472861699092 -0.22686788735251873\n",
            "Epoch: 0/10  Loss: 0.132417 Test loss: 0.355503Tamil-Nadu n_f 2 t_s 7 n_layers 3 kernel_size 4 0.071694545 0.07773258180802398 0.6441045288293983\n",
            "Epoch: 0/10  Loss: 0.138213 Test loss: 0.465210Tamil-Nadu n_f 2 t_s 7 n_layers 4 kernel_size 1 0.19240941 0.19999979287375216 -1.3560002829354234\n",
            "Epoch: 0/10  Loss: 0.131176 Test loss: 0.542086Tamil-Nadu n_f 2 t_s 7 n_layers 4 kernel_size 2 0.7335746 0.7436458514726042 -31.572315528538674\n",
            "Epoch: 0/10  Loss: 0.129326 Test loss: 0.514211Tamil-Nadu n_f 2 t_s 7 n_layers 4 kernel_size 3 0.51413417 0.524261878750847 -15.188732878524512\n",
            "Epoch: 0/10  Loss: 0.119265 Test loss: 0.337978Tamil-Nadu n_f 2 t_s 7 n_layers 4 kernel_size 4 0.055849507 0.06929122799654976 0.7172042829811254\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.121146 Test loss: 0.232368Tamil-Nadu n_f 3 t_s 5 n_layers 2 kernel_size 1 0.08248409 0.08300066243960832 0.6759708666008561\n",
            "Epoch: 0/10  Loss: 0.119832 Test loss: 0.398773Tamil-Nadu n_f 3 t_s 5 n_layers 2 kernel_size 2 0.40029153 0.41592773440366104 -7.136856950911504\n",
            "Epoch: 0/10  Loss: 0.104872 Test loss: 0.242807Tamil-Nadu n_f 3 t_s 5 n_layers 2 kernel_size 3 0.04707774 0.059937199357644154 0.8310283700741286\n",
            "Epoch: 0/10  Loss: 0.149763 Test loss: 0.191159Tamil-Nadu n_f 3 t_s 5 n_layers 2 kernel_size 4 0.033884183 0.041731981900812606 0.9180858431952534\n",
            "Epoch: 0/10  Loss: 0.210709 Test loss: 0.699816Tamil-Nadu n_f 3 t_s 5 n_layers 3 kernel_size 1 0.06514963 0.06839339227330977 0.779986552443442\n",
            "Epoch: 0/10  Loss: 0.165208 Test loss: 0.692054Tamil-Nadu n_f 3 t_s 5 n_layers 3 kernel_size 2 0.17849617 0.18628528630338242 -0.6322176097429821\n",
            "Epoch: 0/10  Loss: 0.107029 Test loss: 0.325720Tamil-Nadu n_f 3 t_s 5 n_layers 3 kernel_size 3 0.06592271 0.07804459368032138 0.7135119020247471\n",
            "Epoch: 0/10  Loss: 0.137584 Test loss: 0.303090Tamil-Nadu n_f 3 t_s 5 n_layers 3 kernel_size 4 0.0823164 0.09321826401774694 0.5912827419277118\n",
            "Epoch: 0/10  Loss: 0.175599 Test loss: 0.312364Tamil-Nadu n_f 3 t_s 5 n_layers 4 kernel_size 1 0.42429882 0.42957502106703865 -7.679584101930677\n",
            "Epoch: 0/10  Loss: 0.143501 Test loss: 0.425769Tamil-Nadu n_f 3 t_s 5 n_layers 4 kernel_size 2 0.25975537 0.275818026416631 -2.5782133992924545\n",
            "Epoch: 0/10  Loss: 0.144377 Test loss: 0.481669Tamil-Nadu n_f 3 t_s 5 n_layers 4 kernel_size 3 0.12575445 0.13580097325208706 0.13258553993361222\n",
            "Epoch: 0/10  Loss: 0.115983 Test loss: 0.441431Tamil-Nadu n_f 3 t_s 5 n_layers 4 kernel_size 4 0.12910493 0.13903725534246256 0.09075003059504139\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.165224 Test loss: 0.242202Tamil-Nadu n_f 3 t_s 7 n_layers 2 kernel_size 1 0.14634417 0.14654990320018654 -0.26499070496459853\n",
            "Epoch: 0/10  Loss: 0.143648 Test loss: 0.096655Tamil-Nadu n_f 3 t_s 7 n_layers 2 kernel_size 2 0.021353649 0.02257048801104319 0.9699946879253443\n",
            "Epoch: 0/10  Loss: 0.200436 Test loss: 0.454155Tamil-Nadu n_f 3 t_s 7 n_layers 2 kernel_size 3 0.06719149 0.06767466132708465 0.7302456752010444\n",
            "Epoch: 0/10  Loss: 0.126639 Test loss: 0.221761Tamil-Nadu n_f 3 t_s 7 n_layers 2 kernel_size 4 0.023990618 0.02778847846278635 0.9545173459934131\n",
            "Epoch: 0/10  Loss: 0.229951 Test loss: 0.203618Tamil-Nadu n_f 3 t_s 7 n_layers 3 kernel_size 1 0.23194462 0.23769248076784089 -2.3277228260067977\n",
            "Epoch: 0/10  Loss: 0.103006 Test loss: 0.298323Tamil-Nadu n_f 3 t_s 7 n_layers 3 kernel_size 2 0.23389712 0.24461257331825992 -2.5243076450295083\n",
            "Epoch: 0/10  Loss: 0.134610 Test loss: 0.381814Tamil-Nadu n_f 3 t_s 7 n_layers 3 kernel_size 3 0.11223901 0.1206010246230265 0.14332067719640873\n",
            "Epoch: 0/10  Loss: 0.192999 Test loss: 0.738963Tamil-Nadu n_f 3 t_s 7 n_layers 3 kernel_size 4 0.16796009 0.1739065175684184 -0.7813448442485471\n",
            "Epoch: 0/10  Loss: 0.216303 Test loss: 0.244558Tamil-Nadu n_f 3 t_s 7 n_layers 4 kernel_size 1 0.08809845 0.09192543969382481 0.5022770426231669\n",
            "Epoch: 0/10  Loss: 0.179901 Test loss: 0.616423Tamil-Nadu n_f 3 t_s 7 n_layers 4 kernel_size 2 0.5675345 0.582598467432423 -18.991941610311088\n",
            "Epoch: 0/10  Loss: 0.127526 Test loss: 0.306584Tamil-Nadu n_f 3 t_s 7 n_layers 4 kernel_size 3 0.46289313 0.47456623399366493 -12.2650818902997\n",
            "Epoch: 0/10  Loss: 0.129956 Test loss: 0.400333Tamil-Nadu n_f 3 t_s 7 n_layers 4 kernel_size 4 0.12937038 0.13731482537557374 -0.11058327151728564\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.134052 Test loss: 0.465706Tamil-Nadu n_f 4 t_s 5 n_layers 2 kernel_size 1 0.08617345 0.10522789739795373 0.479185907162083\n",
            "Epoch: 0/10  Loss: 0.231014 Test loss: 0.161421Tamil-Nadu n_f 4 t_s 5 n_layers 2 kernel_size 2 0.10737378 0.11577972180082566 0.36949879035720024\n",
            "Epoch: 0/10  Loss: 0.117969 Test loss: 0.430884Tamil-Nadu n_f 4 t_s 5 n_layers 2 kernel_size 3 0.12828754 0.1367285111893688 0.12069586066160132\n",
            "Epoch: 0/10  Loss: 0.119378 Test loss: 0.208365Tamil-Nadu n_f 4 t_s 5 n_layers 2 kernel_size 4 0.02812679 0.032596877193341145 0.9500226889253366\n",
            "Epoch: 0/10  Loss: 0.156600 Test loss: 0.650517Tamil-Nadu n_f 4 t_s 5 n_layers 3 kernel_size 1 0.009126018 0.017256600120364004 0.9859934434121523\n",
            "Epoch: 0/10  Loss: 0.152914 Test loss: 0.478935Tamil-Nadu n_f 4 t_s 5 n_layers 3 kernel_size 2 0.030057656 0.039313620782751524 0.9273045856933716\n",
            "Epoch: 0/10  Loss: 0.112572 Test loss: 0.370153Tamil-Nadu n_f 4 t_s 5 n_layers 3 kernel_size 3 0.1366629 0.14844385560132212 -0.03644301333682698\n",
            "Epoch: 0/10  Loss: 0.110732 Test loss: 0.502242Tamil-Nadu n_f 4 t_s 5 n_layers 3 kernel_size 4 0.05330654 0.05612124328144635 0.851858905257444\n",
            "Epoch: 0/10  Loss: 0.131369 Test loss: 0.389083Tamil-Nadu n_f 4 t_s 5 n_layers 4 kernel_size 1 0.1755704 0.18056064429407348 -0.5334411542950916\n",
            "Epoch: 0/10  Loss: 0.110639 Test loss: 0.425992Tamil-Nadu n_f 4 t_s 5 n_layers 4 kernel_size 2 0.043818176 0.06088703110479487 0.825630492620652\n",
            "Epoch: 0/10  Loss: 0.108530 Test loss: 0.311422Tamil-Nadu n_f 4 t_s 5 n_layers 4 kernel_size 3 0.2674668 0.27746083917606656 -2.620964797761557\n",
            "Epoch: 0/10  Loss: 0.090282 Test loss: 0.211212Tamil-Nadu n_f 4 t_s 5 n_layers 4 kernel_size 4 0.08149966 0.09967254991447885 0.5327255066509884\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.196497 Test loss: 0.728746Tamil-Nadu n_f 4 t_s 7 n_layers 2 kernel_size 1 0.025648434 0.030511336642016534 0.9451674105079\n",
            "Epoch: 0/10  Loss: 0.199864 Test loss: 0.387672Tamil-Nadu n_f 4 t_s 7 n_layers 2 kernel_size 2 0.025848934 0.030822943696296973 0.9440417029005618\n",
            "Epoch: 0/10  Loss: 0.108212 Test loss: 0.041382Tamil-Nadu n_f 4 t_s 7 n_layers 2 kernel_size 3 0.08805825 0.09453482739323688 0.47361929221308685\n",
            "Epoch: 0/10  Loss: 0.166950 Test loss: 0.233250Tamil-Nadu n_f 4 t_s 7 n_layers 2 kernel_size 4 0.19894621 0.20521885720649988 -1.480566122292149\n",
            "Epoch: 0/10  Loss: 0.347815 Test loss: 0.186118Tamil-Nadu n_f 4 t_s 7 n_layers 3 kernel_size 1 0.013352215 0.01660101903699056 0.9837674867693484\n",
            "Epoch: 0/10  Loss: 0.123730 Test loss: 0.191817Tamil-Nadu n_f 4 t_s 7 n_layers 3 kernel_size 2 0.14410247 0.1593638098285073 -0.49587629247918286\n",
            "Epoch: 0/10  Loss: 0.146500 Test loss: 0.561897Tamil-Nadu n_f 4 t_s 7 n_layers 3 kernel_size 3 0.15909417 0.16902827833176073 -0.6828096632790999\n",
            "Epoch: 0/10  Loss: 0.124589 Test loss: 0.105720Tamil-Nadu n_f 4 t_s 7 n_layers 3 kernel_size 4 0.17903702 0.1883223698457557 -1.088911588450944\n",
            "Epoch: 0/10  Loss: 0.185178 Test loss: 0.432915Tamil-Nadu n_f 4 t_s 7 n_layers 4 kernel_size 1 0.46731043 0.4784846704552689 -12.48504371794345\n",
            "Epoch: 0/10  Loss: 0.113966 Test loss: 0.370883Tamil-Nadu n_f 4 t_s 7 n_layers 4 kernel_size 2 0.07540415 0.09736522224963225 0.4416274801254432\n",
            "Epoch: 0/10  Loss: 0.160121 Test loss: 0.543594Tamil-Nadu n_f 4 t_s 7 n_layers 4 kernel_size 3 0.18908373 0.1985330280390661 -1.3215701810654386\n",
            "Epoch: 0/10  Loss: 0.152681 Test loss: 0.519705Tamil-Nadu n_f 4 t_s 7 n_layers 4 kernel_size 4 0.22299877 0.22973887394498865 -2.1087459667361217\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.119757 Test loss: 0.340280Tamil-Nadu n_f 5 t_s 5 n_layers 2 kernel_size 1 0.20296198 0.21211875311701645 -1.1163090028497784\n",
            "Epoch: 0/10  Loss: 0.111588 Test loss: 0.221488Tamil-Nadu n_f 5 t_s 5 n_layers 2 kernel_size 2 0.057700407 0.06814478161569854 0.7815831416172485\n",
            "Epoch: 0/10  Loss: 0.101311 Test loss: 0.219864Tamil-Nadu n_f 5 t_s 5 n_layers 2 kernel_size 3 0.15490058 0.18590576197524403 -0.6255735395652939\n",
            "Epoch: 0/10  Loss: 0.182917 Test loss: 0.577639Tamil-Nadu n_f 5 t_s 5 n_layers 2 kernel_size 4 0.17371942 0.18882913176489527 -0.6770997056105232\n",
            "Epoch: 0/10  Loss: 0.239034 Test loss: 0.725166Tamil-Nadu n_f 5 t_s 5 n_layers 3 kernel_size 1 0.029792674 0.037230077311913815 0.9348058185189152\n",
            "Epoch: 0/10  Loss: 0.149832 Test loss: 0.261637Tamil-Nadu n_f 5 t_s 5 n_layers 3 kernel_size 2 0.1978181 0.21526354611092038 -1.1795252993429766\n",
            "Epoch: 0/10  Loss: 0.126339 Test loss: 0.532098Tamil-Nadu n_f 5 t_s 5 n_layers 3 kernel_size 3 0.047215533 0.05433599508722628 0.8611339181596699\n",
            "Epoch: 0/10  Loss: 0.132574 Test loss: 0.407381Tamil-Nadu n_f 5 t_s 5 n_layers 3 kernel_size 4 0.23852012 0.2590830590450233 -2.157177308593125\n",
            "Epoch: 0/10  Loss: 0.147441 Test loss: 0.232800Tamil-Nadu n_f 5 t_s 5 n_layers 4 kernel_size 1 0.16041371 0.17551710627604966 -0.44897141466495016\n",
            "Epoch: 0/10  Loss: 0.193770 Test loss: 0.339432Tamil-Nadu n_f 5 t_s 5 n_layers 4 kernel_size 2 0.325376 0.3431369994450401 -4.5380392259039795\n",
            "Epoch: 0/10  Loss: 0.206998 Test loss: 0.663865Tamil-Nadu n_f 5 t_s 5 n_layers 4 kernel_size 3 0.08250944 0.09391214336366643 0.5851754243205463\n",
            "Epoch: 0/10  Loss: 0.097792 Test loss: 0.173225Tamil-Nadu n_f 5 t_s 5 n_layers 4 kernel_size 4 0.093541175 0.10390032055794332 0.4922443781463366\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.143009 Test loss: 0.034780Tamil-Nadu n_f 5 t_s 7 n_layers 2 kernel_size 1 0.29998523 0.3109318967534795 -4.694385191359933\n",
            "Epoch: 0/10  Loss: 0.165569 Test loss: 0.248668Tamil-Nadu n_f 5 t_s 7 n_layers 2 kernel_size 2 0.04072911 0.04439854811819575 0.8838942264849856\n",
            "Epoch: 0/10  Loss: 0.138247 Test loss: 0.302273Tamil-Nadu n_f 5 t_s 7 n_layers 2 kernel_size 3 0.067814186 0.07819533460286889 0.6398545245466969\n",
            "Epoch: 0/10  Loss: 0.142188 Test loss: 0.072821Tamil-Nadu n_f 5 t_s 7 n_layers 2 kernel_size 4 0.13919641 0.15508997773389344 -0.4167191255813696\n",
            "Epoch: 0/10  Loss: 0.305562 Test loss: 0.419852Tamil-Nadu n_f 5 t_s 7 n_layers 3 kernel_size 1 0.021323796 0.0234263102820916 0.9676760784379217\n",
            "Epoch: 0/10  Loss: 0.143929 Test loss: 0.612555Tamil-Nadu n_f 5 t_s 7 n_layers 3 kernel_size 2 0.10202286 0.13307905795737882 -0.04312351017958771\n",
            "Epoch: 0/10  Loss: 0.166429 Test loss: 0.347709Tamil-Nadu n_f 5 t_s 7 n_layers 3 kernel_size 3 0.16572332 0.17496383071827237 -0.8030709613826972\n",
            "Epoch: 0/10  Loss: 0.119403 Test loss: 0.137506Tamil-Nadu n_f 5 t_s 7 n_layers 3 kernel_size 4 0.09240982 0.10592723462632336 0.3391064568403407\n",
            "Epoch: 0/10  Loss: 0.391678 Test loss: 0.094327Tamil-Nadu n_f 5 t_s 7 n_layers 4 kernel_size 1 0.5664648 0.5855843051706724 -19.19738383631443\n",
            "Epoch: 0/10  Loss: 0.262909 Test loss: 1.050342Tamil-Nadu n_f 5 t_s 7 n_layers 4 kernel_size 2 0.08777855 0.09221756190384908 0.49910861854233923\n",
            "Epoch: 0/10  Loss: 0.127077 Test loss: 0.222950Tamil-Nadu n_f 5 t_s 7 n_layers 4 kernel_size 3 0.10390377 0.1412196369050436 -0.17464444753091612\n",
            "Epoch: 0/10  Loss: 0.160263 Test loss: 0.603036Tamil-Nadu n_f 5 t_s 7 n_layers 4 kernel_size 4 0.10843627 0.12174630844136937 0.1269725503148459\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.248653 Test loss: 0.761525Tamil-Nadu n_f 6 t_s 5 n_layers 2 kernel_size 1 0.20621148 0.2127202340790609 -1.1283278922212232\n",
            "Epoch: 0/10  Loss: 0.099391 Test loss: 0.132922Tamil-Nadu n_f 6 t_s 5 n_layers 2 kernel_size 2 0.23965843 0.24912353448632932 -1.919109928951892\n",
            "Epoch: 0/10  Loss: 0.121800 Test loss: 0.148831Tamil-Nadu n_f 6 t_s 5 n_layers 2 kernel_size 3 0.29878625 0.3125533535234454 -3.5948280127496117\n",
            "Epoch: 0/10  Loss: 0.225680 Test loss: 0.510830Tamil-Nadu n_f 6 t_s 5 n_layers 2 kernel_size 4 0.03354975 0.054668978977852285 0.859426688443882\n",
            "Epoch: 0/10  Loss: 0.448689 Test loss: 0.049750Tamil-Nadu n_f 6 t_s 5 n_layers 3 kernel_size 1 0.040330965 0.049278983940469555 0.8857794039265838\n",
            "Epoch: 0/10  Loss: 0.158189 Test loss: 0.536813Tamil-Nadu n_f 6 t_s 5 n_layers 3 kernel_size 2 0.21064657 0.22661912966719316 -1.415538981550554\n",
            "Epoch: 0/10  Loss: 0.116831 Test loss: 0.343080Tamil-Nadu n_f 6 t_s 5 n_layers 3 kernel_size 3 0.19566779 0.20892514075646174 -1.0530631381598412\n",
            "Epoch: 0/10  Loss: 0.124003 Test loss: 0.323428Tamil-Nadu n_f 6 t_s 5 n_layers 3 kernel_size 4 0.16820969 0.18128486371988212 -0.5457668987619\n",
            "Epoch: 0/10  Loss: 0.193298 Test loss: 0.052136Tamil-Nadu n_f 6 t_s 5 n_layers 4 kernel_size 1 0.43521026 0.4517944466217073 -8.600695907587424\n",
            "Epoch: 0/10  Loss: 0.159304 Test loss: 0.279454Tamil-Nadu n_f 6 t_s 5 n_layers 4 kernel_size 2 0.22545664 0.23939062830701707 -1.6954742239782221\n",
            "Epoch: 0/10  Loss: 0.112453 Test loss: 0.328616Tamil-Nadu n_f 6 t_s 5 n_layers 4 kernel_size 3 0.17728561 0.1963242551465455 -0.8128790844762923\n",
            "Epoch: 0/10  Loss: 0.119749 Test loss: 0.352529Tamil-Nadu n_f 6 t_s 5 n_layers 4 kernel_size 4 0.24477486 0.25908579099294593 -2.1572437866603416\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.191456 Test loss: 0.466770Tamil-Nadu n_f 6 t_s 7 n_layers 2 kernel_size 1 0.2013673 0.20696650698329203 -1.5229949432547296\n",
            "Epoch: 0/10  Loss: 0.296210 Test loss: 0.172683Tamil-Nadu n_f 6 t_s 7 n_layers 2 kernel_size 2 0.16957419 0.18863316685810563 -1.095812262922661\n",
            "Epoch: 0/10  Loss: 0.257925 Test loss: 0.958479Tamil-Nadu n_f 6 t_s 7 n_layers 2 kernel_size 3 0.22060855 0.23433381354527855 -2.2343440468378253\n",
            "Epoch: 0/10  Loss: 0.126151 Test loss: 0.017738Tamil-Nadu n_f 6 t_s 7 n_layers 2 kernel_size 4 0.11055689 0.12044988473355822 0.1454665466636249\n",
            "Epoch: 0/10  Loss: 0.318508 Test loss: 0.439962Tamil-Nadu n_f 6 t_s 7 n_layers 3 kernel_size 1 0.07892116 0.08328891168710774 0.5914072508606677\n",
            "Epoch: 0/10  Loss: 0.205255 Test loss: 0.111303Tamil-Nadu n_f 6 t_s 7 n_layers 3 kernel_size 2 0.15715331 0.1736747032498089 -0.7765989531854587\n",
            "Epoch: 0/10  Loss: 0.153804 Test loss: 0.733503Tamil-Nadu n_f 6 t_s 7 n_layers 3 kernel_size 3 0.22027925 0.2308514537194583 -2.13892913778711\n",
            "Epoch: 0/10  Loss: 0.160704 Test loss: 0.470554Tamil-Nadu n_f 6 t_s 7 n_layers 3 kernel_size 4 0.14612405 0.1497272811203612 -0.32043844601508686\n",
            "Epoch: 0/10  Loss: 0.404424 Test loss: 1.491423Tamil-Nadu n_f 6 t_s 7 n_layers 4 kernel_size 1 0.06346863 0.07009400420136432 0.7106136507208087\n",
            "Epoch: 0/10  Loss: 0.260931 Test loss: 0.171127Tamil-Nadu n_f 6 t_s 7 n_layers 4 kernel_size 2 0.093793884 0.0959696610111558 0.4575194940255165\n",
            "Epoch: 0/10  Loss: 0.191987 Test loss: 0.402941Tamil-Nadu n_f 6 t_s 7 n_layers 4 kernel_size 3 0.2609615 0.26939654093775234 -3.27464788960868\n",
            "Epoch: 0/10  Loss: 0.171900 Test loss: 0.532352Tamil-Nadu n_f 6 t_s 7 n_layers 4 kernel_size 4 0.17446786 0.1841219142945307 -0.9967664143810986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "YdksVMTRdM9y",
        "outputId": "4dc31c35-1148-456b-ec9d-750e1d7d0804"
      },
      "source": [
        "df_cnn = pd.DataFrame (results_cnn,columns=['State','Number_feature','Time_Step','number_layers','kernel_size','MAE','RMSE','R2_Score'])\n",
        "df_cnn.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Number_feature</th>\n",
              "      <th>Time_Step</th>\n",
              "      <th>number_layers</th>\n",
              "      <th>kernel_size</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.177340</td>\n",
              "      <td>0.179965</td>\n",
              "      <td>-0.729241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.148379</td>\n",
              "      <td>0.149789</td>\n",
              "      <td>-0.197958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.070158</td>\n",
              "      <td>0.072535</td>\n",
              "      <td>0.719084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.128084</td>\n",
              "      <td>0.131985</td>\n",
              "      <td>0.069898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.234579</td>\n",
              "      <td>0.237361</td>\n",
              "      <td>-2.008145</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       State  Number_feature  Time_Step  ...       MAE      RMSE  R2_Score\n",
              "0  Karnataka               1          5  ...  0.177340  0.179965 -0.729241\n",
              "1  Karnataka               1          5  ...  0.148379  0.149789 -0.197958\n",
              "2  Karnataka               1          5  ...  0.070158  0.072535  0.719084\n",
              "3  Karnataka               1          5  ...  0.128084  0.131985  0.069898\n",
              "4  Karnataka               1          5  ...  0.234579  0.237361 -2.008145\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXs43OKciU6q",
        "outputId": "0ce0dbfc-1dc5-40c9-b9a5-79024de68f1e"
      },
      "source": [
        "#github_upload(folder_name='Indian-States-Model-Results',file_name='CNN_on_short_data.csv', file_data=df_cnn.to_csv())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indian-States-Model-Results/CNN_on_short_data.csv CREATED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11NEO9rA86DF"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dim, layers,output_dim):\n",
        "    super(MLP, self).__init__()\n",
        "    self.input_dim=input_dim\n",
        "    self.n_layers=layers\n",
        "    self.output_dim=output_dim\n",
        "    in_features=input_dim\n",
        "    out_features=16\n",
        "    layers=[]\n",
        "    for l in range(self.n_layers):\n",
        "        if l==(self.n_layers-1):\n",
        "          layers.append(nn.Linear(in_features=in_features, out_features=self.output_dim))\n",
        "        else:\n",
        "          layers.append(nn.Linear(in_features=in_features, out_features=out_features))\n",
        "        if l%2==0:\n",
        "          layers.append(nn.Tanh())\n",
        "        else:\n",
        "          layers.append(nn.ELU(inplace=True))\n",
        "        in_features=out_features\n",
        "        out_features=int(out_features/2)\n",
        "    self.body = nn.Sequential(*layers)\n",
        "  def forward(self, x):\n",
        "    b, n_steps, features = x.shape\n",
        "    #print(b,n_steps, features)\n",
        "    x = x.reshape([b,n_steps*features])\n",
        "    return self.body(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSGsPFRmsZIL",
        "outputId": "e6fa9497-a1ea-41bd-8c2f-d218158b9368"
      },
      "source": [
        "Shortlisted_States=['Karnataka','Maharashtra','Uttar-Pradesh','Kerala','Tamil-Nadu']\n",
        "results_mlp=[]\n",
        "for state in Shortlisted_States:\n",
        "  best_models=[]\n",
        "  df=pd.read_csv(\"https://raw.githubusercontent.com/sureshkuc/Data-Science-in-Life-Science-Project/main/Indian-States-Covid19-Datasets/\"+state+\".csv\", parse_dates=[\"Date\"]).drop(columns =[\"Unnamed: 0\"])\n",
        "  df_temp1 = df[df[\"Date\"] <= \"2020-06-18\"]\n",
        "  df_temp2=  df[df[\"Date\"] > \"2020-03-09\"]\n",
        "  df = pd.merge(df_temp1, df_temp2, how='inner')\n",
        "  df = df.set_index(\"Date\")\n",
        "  df = df[['Confirmed', 'Recovered', 'Deceased', 'New_Confirmerd', 'New_Deaths', 'New_Recovered']]\n",
        "  #print(df.describe())\n",
        "\n",
        "  time_step=[5,7]\n",
        "  Number_of_feature=[1,2,3,4,5,6]\n",
        "  multi_feature=True\n",
        "  for n_f in Number_of_feature:\n",
        "    for t_s in time_step:\n",
        "      train_loader, test_loader,scalar = data_preparation(df, scaling_range=(0,1),time_step=t_s,number_feature=n_f, response_variable_index=0,data_split_ratio=0.8)\n",
        "      for n_layers in range(1,3,1):\n",
        "          print(state,'n_f',n_f,'t_s',t_s,'n_layers',n_layers,'Error',mae,rmse,r2s)\n",
        "          max_epochs=10\n",
        "          random.seed(42)\n",
        "          torch.manual_seed(42)\n",
        "          np.random.seed(42)\n",
        "          #CNN model with L1 loss\n",
        "          #best_model=Call_CNN_model(state,dataset=(train_loader, test_loader), lr=1e-2,criterion=nn.L1Loss(),max_epochs=max_epochs)\n",
        "          fc_model = MLP(input_dim=n_f*t_s, layers=n_layers,output_dim=1)\n",
        "          cuda=torch.cuda.is_available()\n",
        "          if cuda:\n",
        "            fc_model = fc_model.cuda()\n",
        "          fc_optim = optim.SGD(fc_model.parameters(), lr=0.02, momentum=0.9)\n",
        "          #fc_optim = optim.Adam(fc_model.parameters(), lr=1e-3)\n",
        "          train_losses,test_losses,best_model = fit(fc_model, fc_optim,nn.L1Loss(),(train_loader, test_loader), max_epochs=max_epochs,cuda=cuda)\n",
        "          #print(f'\\nTraining took {end-start}s!')\n",
        "          #plot_loss(max_epochs,train_losses,test_losses,model_name='CNN for '+state)\n",
        "          fc_model = MLP(input_dim=n_f*t_s, layers=n_layers,output_dim=1)\n",
        "          fc_model.load_state_dict(best_model)\n",
        "          fc_model.eval()\n",
        "          test_x,test_y=test_loader\n",
        "          predictions=fc_model(test_x)\n",
        "          test_y=test_y.cpu().detach().numpy()\n",
        "          predictions=predictions.cpu().detach().numpy()\n",
        "          mae=mean_absolute_error(test_y,predictions)\n",
        "          rmse=math.sqrt(mean_squared_error(test_y,predictions))\n",
        "          #mape=mean_absolute_percentage_error(test_y,predictions)\n",
        "          r2s=r2_score(test_y,predictions)\n",
        "          results_mlp.append([state,n_f,t_s,n_layers,mae,rmse,r2s])\n",
        "          #print(state,n_f,t_s,n_layers,mae,rmse,r2s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Karnataka n_f 1 t_s 5 n_layers 1 Error 0.26164466 0.2695217407318226 -3.2786214440857675\n",
            "\rEpoch: 0/10  Loss: 0.047180 Test loss: 0.069669Karnataka n_f 1 t_s 5 n_layers 2 Error 0.07939138 0.08696174117479391 0.5962286175592951\n",
            "\rEpoch: 0/10  Loss: 0.145948 Test loss: 0.253267(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Karnataka n_f 1 t_s 7 n_layers 1 Error 0.029453028 0.037209590375804284 0.9260754248222786\n",
            "Epoch: 0/10  Loss: 0.122863 Test loss: 0.185007Karnataka n_f 1 t_s 7 n_layers 2 Error 0.11850298 0.12068727938643234 -0.22371952737497947\n",
            "Epoch: 0/10  Loss: 0.094363 Test loss: 0.329318(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Karnataka n_f 2 t_s 5 n_layers 1 Error 0.038968544 0.051950321623808915 0.7732562502834583\n",
            "Epoch: 0/10  Loss: 0.167944 Test loss: 0.160467Karnataka n_f 2 t_s 5 n_layers 2 Error 0.083640896 0.08538240545435664 0.6107614148283276\n",
            "Epoch: 0/10  Loss: 0.107721 Test loss: 0.942938(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Karnataka n_f 2 t_s 7 n_layers 1 Error 0.033020604 0.03633380897980801 0.9295143141088643\n",
            "Epoch: 0/10  Loss: 0.062989 Test loss: 0.072059Karnataka n_f 2 t_s 7 n_layers 2 Error 0.09309743 0.09444348816975771 0.25061847342240606\n",
            "Epoch: 0/10  Loss: 0.138895 Test loss: 0.618189(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Karnataka n_f 3 t_s 5 n_layers 1 Error 0.032491643 0.03753095754680988 0.8816581908649016\n",
            "Epoch: 0/10  Loss: 0.032617 Test loss: 0.035277Karnataka n_f 3 t_s 5 n_layers 2 Error 0.048733752 0.053890584573346216 0.8449381743898327\n",
            "Epoch: 0/10  Loss: 0.125647 Test loss: 0.435528(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Karnataka n_f 3 t_s 7 n_layers 1 Error 0.12547486 0.12862013361931024 0.11672279421338272\n",
            "Epoch: 0/10  Loss: 0.044001 Test loss: 0.076922Karnataka n_f 3 t_s 7 n_layers 2 Error 0.07738847 0.07931818264754652 0.47142772195301985\n",
            "Epoch: 0/10  Loss: 0.219109 Test loss: 0.111572(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Karnataka n_f 4 t_s 5 n_layers 1 Error 0.2053162 0.205807107736038 -2.5586036084463766\n",
            "Epoch: 0/10  Loss: 0.059116 Test loss: 0.007472Karnataka n_f 4 t_s 5 n_layers 2 Error 0.1057404 0.1233959280400694 0.18701834925993255\n",
            "Epoch: 0/10  Loss: 0.171023 Test loss: 0.624743(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Karnataka n_f 4 t_s 7 n_layers 1 Error 0.22289783 0.23836381451108607 -2.033609737667414\n",
            "Epoch: 0/10  Loss: 0.057407 Test loss: 0.070843Karnataka n_f 4 t_s 7 n_layers 2 Error 0.08843044 0.11645835695909092 -0.13946295729747726\n",
            "Epoch: 0/10  Loss: 0.088549 Test loss: 0.460855(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Karnataka n_f 5 t_s 5 n_layers 1 Error 0.066122696 0.08957091659428695 0.3259486979136561\n",
            "Epoch: 0/10  Loss: 0.064769 Test loss: 0.021931Karnataka n_f 5 t_s 5 n_layers 2 Error 0.13381304 0.15892255527822186 -0.3484975988323822\n",
            "Epoch: 0/10  Loss: 0.105224 Test loss: 0.228011(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Karnataka n_f 5 t_s 7 n_layers 1 Error 0.19350497 0.21045805166874282 -1.3648858832036201\n",
            "Epoch: 0/10  Loss: 0.058723 Test loss: 0.180061Karnataka n_f 5 t_s 7 n_layers 2 Error 0.19956215 0.2184560111528913 -3.0094692627634956\n",
            "Epoch: 0/10  Loss: 0.157084 Test loss: 0.149980(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Karnataka n_f 6 t_s 5 n_layers 1 Error 0.18635887 0.2000434578679174 -2.362076755839239\n",
            "Epoch: 0/10  Loss: 0.104983 Test loss: 0.449138Karnataka n_f 6 t_s 5 n_layers 2 Error 0.09144818 0.10929186249828259 0.3622437374903418\n",
            "Epoch: 0/10  Loss: 0.066222 Test loss: 0.286860(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Karnataka n_f 6 t_s 7 n_layers 1 Error 0.06699273 0.09011731791393829 0.566393662429618\n",
            "Epoch: 0/10  Loss: 0.060244 Test loss: 0.195187Karnataka n_f 6 t_s 7 n_layers 2 Error 0.0525641 0.06971893175294645 0.5916238764614188\n",
            "Epoch: 0/10  Loss: 0.107055 Test loss: 0.662232(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Maharashtra n_f 1 t_s 5 n_layers 1 Error 0.04420108 0.054581855162110796 0.7497030799562541\n",
            "Epoch: 0/10  Loss: 0.049653 Test loss: 0.049137Maharashtra n_f 1 t_s 5 n_layers 2 Error 0.07711208 0.08952549355826778 0.32120881983757676\n",
            "Epoch: 0/10  Loss: 0.184314 Test loss: 0.217396(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Maharashtra n_f 1 t_s 7 n_layers 1 Error 0.042788256 0.045927834734765464 0.8213534373277398\n",
            "Epoch: 0/10  Loss: 0.126685 Test loss: 0.109266Maharashtra n_f 1 t_s 7 n_layers 2 Error 0.0701126 0.0826190540202075 0.26315194623297744\n",
            "Epoch: 0/10  Loss: 0.130366 Test loss: 0.209056(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Maharashtra n_f 2 t_s 5 n_layers 1 Error 0.06844731 0.06913251654175442 0.4840801008894775\n",
            "Epoch: 0/10  Loss: 0.161381 Test loss: 0.071636Maharashtra n_f 2 t_s 5 n_layers 2 Error 0.05067977 0.05719096122817642 0.7229886742827878\n",
            "Epoch: 0/10  Loss: 0.170964 Test loss: 0.927613(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Maharashtra n_f 2 t_s 7 n_layers 1 Error 0.030013883 0.03329366198143282 0.9061215581377607\n",
            "Epoch: 0/10  Loss: 0.058356 Test loss: 0.013999Maharashtra n_f 2 t_s 7 n_layers 2 Error 0.04189588 0.054184780689362895 0.6830635677740169\n",
            "Epoch: 0/10  Loss: 0.177108 Test loss: 0.393431(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Maharashtra n_f 3 t_s 5 n_layers 1 Error 0.1539685 0.15425839729034016 -1.5687103893387717\n",
            "Epoch: 0/10  Loss: 0.043548 Test loss: 0.002782Maharashtra n_f 3 t_s 5 n_layers 2 Error 0.035898454 0.04350265909662654 0.8397218361514758\n",
            "Epoch: 0/10  Loss: 0.135332 Test loss: 0.273464(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Maharashtra n_f 3 t_s 7 n_layers 1 Error 0.026327915 0.030241327214957547 0.9225458971533744\n",
            "Epoch: 0/10  Loss: 0.076763 Test loss: 0.002558Maharashtra n_f 3 t_s 7 n_layers 2 Error 0.03578412 0.04363132201050708 0.7944988378067329\n",
            "Epoch: 0/10  Loss: 0.273187 Test loss: 0.123433(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Maharashtra n_f 4 t_s 5 n_layers 1 Error 0.078365676 0.08166206822030823 0.2801230786106508\n",
            "Epoch: 0/10  Loss: 0.047093 Test loss: 0.005403Maharashtra n_f 4 t_s 5 n_layers 2 Error 0.090943985 0.10325414092613379 0.09706253461545555\n",
            "Epoch: 0/10  Loss: 0.188520 Test loss: 0.523130(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Maharashtra n_f 4 t_s 7 n_layers 1 Error 0.07567522 0.08253158673138662 0.42312313457953277\n",
            "Epoch: 0/10  Loss: 0.040953 Test loss: 0.029563Maharashtra n_f 4 t_s 7 n_layers 2 Error 0.09866456 0.10731806941373948 -0.24326366494129315\n",
            "Epoch: 0/10  Loss: 0.129381 Test loss: 0.216109(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Maharashtra n_f 5 t_s 5 n_layers 1 Error 0.14110607 0.14647630033490436 -1.3160729626269343\n",
            "Epoch: 0/10  Loss: 0.060293 Test loss: 0.006745Maharashtra n_f 5 t_s 5 n_layers 2 Error 0.04607568 0.0565660680684766 0.7290090728439758\n",
            "Epoch: 0/10  Loss: 0.135843 Test loss: 0.137741(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Maharashtra n_f 5 t_s 7 n_layers 1 Error 0.18045011 0.18575678546392335 -1.922349009827704\n",
            "Epoch: 0/10  Loss: 0.066240 Test loss: 0.094052Maharashtra n_f 5 t_s 7 n_layers 2 Error 0.062321715 0.07553799991785487 0.3840456691496503\n",
            "Epoch: 0/10  Loss: 0.196720 Test loss: 0.101305(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Maharashtra n_f 6 t_s 5 n_layers 1 Error 0.08821701 0.09249006964727569 0.07656191130854495\n",
            "Epoch: 0/10  Loss: 0.139406 Test loss: 0.135802Maharashtra n_f 6 t_s 5 n_layers 2 Error 0.06965019 0.08101569237333787 0.4441200574186537\n",
            "Epoch: 0/10  Loss: 0.088945 Test loss: 0.143114(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Maharashtra n_f 6 t_s 7 n_layers 1 Error 0.045173883 0.048390941874575474 0.8016780212683554\n",
            "Epoch: 0/10  Loss: 0.092744 Test loss: 0.025424Maharashtra n_f 6 t_s 7 n_layers 2 Error 0.09366839 0.10173691390362367 -0.11731239331611287\n",
            "Epoch: 0/10  Loss: 0.189104 Test loss: 0.657789(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Uttar-Pradesh n_f 1 t_s 5 n_layers 1 Error 0.11013194 0.11310104720481866 -0.3808634949873304\n",
            "Epoch: 0/10  Loss: 0.045110 Test loss: 0.049136Uttar-Pradesh n_f 1 t_s 5 n_layers 2 Error 0.10096755 0.11257429931117803 0.1421200809950416\n",
            "Epoch: 0/10  Loss: 0.188206 Test loss: 0.169571(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Uttar-Pradesh n_f 1 t_s 7 n_layers 1 Error 0.037053533 0.04016124296318184 0.8908151678413609\n",
            "Epoch: 0/10  Loss: 0.112028 Test loss: 0.128621Uttar-Pradesh n_f 1 t_s 7 n_layers 2 Error 0.10858337 0.11800735107351866 -0.2146482460563648\n",
            "Epoch: 0/10  Loss: 0.130224 Test loss: 0.130687(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Uttar-Pradesh n_f 2 t_s 5 n_layers 1 Error 0.05398826 0.05648451082587894 0.7217141201689377\n",
            "Epoch: 0/10  Loss: 0.142998 Test loss: 0.091900Uttar-Pradesh n_f 2 t_s 5 n_layers 2 Error 0.076512225 0.09215744708665567 0.42507803130768707\n",
            "Epoch: 0/10  Loss: 0.181682 Test loss: 0.635886(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Uttar-Pradesh n_f 2 t_s 7 n_layers 1 Error 0.08009386 0.08809433746886274 0.47465571098129566\n",
            "Epoch: 0/10  Loss: 0.056232 Test loss: 0.047997Uttar-Pradesh n_f 2 t_s 7 n_layers 2 Error 0.07310686 0.08754427004946526 0.3315208654441457\n",
            "Epoch: 0/10  Loss: 0.149248 Test loss: 0.306527(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Uttar-Pradesh n_f 3 t_s 5 n_layers 1 Error 0.09458101 0.10169432411261549 0.09795986109120058\n",
            "Epoch: 0/10  Loss: 0.038516 Test loss: 0.004062Uttar-Pradesh n_f 3 t_s 5 n_layers 2 Error 0.05810855 0.07197110952115422 0.6493576153226359\n",
            "Epoch: 0/10  Loss: 0.120494 Test loss: 0.240195(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Uttar-Pradesh n_f 3 t_s 7 n_layers 1 Error 0.07754707 0.08765463937207861 0.47988689495255965\n",
            "Epoch: 0/10  Loss: 0.058166 Test loss: 0.002714Uttar-Pradesh n_f 3 t_s 7 n_layers 2 Error 0.04507362 0.05864652998327257 0.70000287722303\n",
            "Epoch: 0/10  Loss: 0.278635 Test loss: 0.072162(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Uttar-Pradesh n_f 4 t_s 5 n_layers 1 Error 0.06250996 0.0688063551749504 0.5870575801555762\n",
            "Epoch: 0/10  Loss: 0.052773 Test loss: 0.003239Uttar-Pradesh n_f 4 t_s 5 n_layers 2 Error 0.107222125 0.11882352842661309 0.04423105515031944\n",
            "Epoch: 0/10  Loss: 0.172561 Test loss: 0.390684(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Uttar-Pradesh n_f 4 t_s 7 n_layers 1 Error 0.07054448 0.07918093078608254 0.5755864488392028\n",
            "Epoch: 0/10  Loss: 0.059990 Test loss: 0.017081Uttar-Pradesh n_f 4 t_s 7 n_layers 2 Error 0.047158834 0.06317154888924685 0.6519228777466941\n",
            "Epoch: 0/10  Loss: 0.127134 Test loss: 0.177912(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Uttar-Pradesh n_f 5 t_s 5 n_layers 1 Error 0.07187835 0.07954662705983935 0.4480802304169643\n",
            "Epoch: 0/10  Loss: 0.073229 Test loss: 0.003845Uttar-Pradesh n_f 5 t_s 5 n_layers 2 Error 0.08095007 0.09644742482105925 0.370306406936186\n",
            "Epoch: 0/10  Loss: 0.129698 Test loss: 0.090923(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Uttar-Pradesh n_f 5 t_s 7 n_layers 1 Error 0.1360169 0.14342529927517228 -0.39251393738810614\n",
            "Epoch: 0/10  Loss: 0.072764 Test loss: 0.041031Uttar-Pradesh n_f 5 t_s 7 n_layers 2 Error 0.09949476 0.11260091027539597 -0.1059009018495034\n",
            "Epoch: 0/10  Loss: 0.199365 Test loss: 0.046124(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Uttar-Pradesh n_f 6 t_s 5 n_layers 1 Error 0.06342077 0.06764835404645216 0.600840111533733\n",
            "Epoch: 0/10  Loss: 0.098251 Test loss: 0.057746Uttar-Pradesh n_f 6 t_s 5 n_layers 2 Error 0.11079655 0.11664129359851491 0.07901477748835828\n",
            "Epoch: 0/10  Loss: 0.090488 Test loss: 0.122423(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Uttar-Pradesh n_f 6 t_s 7 n_layers 1 Error 0.053088527 0.06421894097821873 0.7208264443189445\n",
            "Epoch: 0/10  Loss: 0.057517 Test loss: 0.007399Uttar-Pradesh n_f 6 t_s 7 n_layers 2 Error 0.12633048 0.13116211531673666 -0.5005457911878941\n",
            "Epoch: 0/10  Loss: 0.163765 Test loss: 0.284285(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Kerala n_f 1 t_s 5 n_layers 1 Error 0.06207323 0.06552792760642896 0.6254711587357479\n",
            "Epoch: 0/10  Loss: 0.045325 Test loss: 0.065652Kerala n_f 1 t_s 5 n_layers 2 Error 0.13601285 0.1413999964453543 -0.14453130019055616\n",
            "Epoch: 0/10  Loss: 0.178358 Test loss: 0.153178(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Kerala n_f 1 t_s 7 n_layers 1 Error 0.083917394 0.08444093097447664 0.5918358268197839\n",
            "Epoch: 0/10  Loss: 0.102234 Test loss: 0.184637Kerala n_f 1 t_s 7 n_layers 2 Error 0.12994224 0.13188981262289456 -0.4577474094203411\n",
            "Epoch: 0/10  Loss: 0.117947 Test loss: 0.155086(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Kerala n_f 2 t_s 5 n_layers 1 Error 0.089703254 0.09038642585878724 0.31535379632683525\n",
            "Epoch: 0/10  Loss: 0.163038 Test loss: 0.189459Kerala n_f 2 t_s 5 n_layers 2 Error 0.20072831 0.20735458999676684 -1.4612523356551104\n",
            "Epoch: 0/10  Loss: 0.139107 Test loss: 0.423523(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Kerala n_f 2 t_s 7 n_layers 1 Error 0.27144083 0.2773254818339827 -3.4025914430481254\n",
            "Epoch: 0/10  Loss: 0.075168 Test loss: 0.114795Kerala n_f 2 t_s 7 n_layers 2 Error 0.15666945 0.16107023353313837 -1.1741543814573387\n",
            "Epoch: 0/10  Loss: 0.106259 Test loss: 0.537490(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Kerala n_f 3 t_s 5 n_layers 1 Error 0.17576799 0.1784801973877375 -1.6695608999984142\n",
            "Epoch: 0/10  Loss: 0.048070 Test loss: 0.033333Kerala n_f 3 t_s 5 n_layers 2 Error 0.09297533 0.10344166182590188 0.3874806676534214\n",
            "Epoch: 0/10  Loss: 0.101957 Test loss: 0.301788(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Kerala n_f 3 t_s 7 n_layers 1 Error 0.14036965 0.14560743416291863 -0.21365694590479967\n",
            "Epoch: 0/10  Loss: 0.061426 Test loss: 0.078929Kerala n_f 3 t_s 7 n_layers 2 Error 0.12072177 0.12475767712845816 -0.30435058633769074\n",
            "Epoch: 0/10  Loss: 0.271616 Test loss: 0.027935(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Kerala n_f 4 t_s 5 n_layers 1 Error 0.14049798 0.1435039326738657 -0.7257876492443469\n",
            "Epoch: 0/10  Loss: 0.063581 Test loss: 0.005207Kerala n_f 4 t_s 5 n_layers 2 Error 0.105827935 0.12107235196467168 0.16089012802321767\n",
            "Epoch: 0/10  Loss: 0.130974 Test loss: 0.515286(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Kerala n_f 4 t_s 7 n_layers 1 Error 0.17022163 0.18644366131140686 -0.9898670137448291\n",
            "Epoch: 0/10  Loss: 0.061949 Test loss: 0.011318Kerala n_f 4 t_s 7 n_layers 2 Error 0.13593729 0.14509701826114757 -0.7643174010134375\n",
            "Epoch: 0/10  Loss: 0.102227 Test loss: 0.158438(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Kerala n_f 5 t_s 5 n_layers 1 Error 0.12035815 0.12913174846210101 -0.3974163889463298\n",
            "Epoch: 0/10  Loss: 0.067268 Test loss: 0.005412Kerala n_f 5 t_s 5 n_layers 2 Error 0.080474235 0.10018413343770204 0.4254514658789528\n",
            "Epoch: 0/10  Loss: 0.115465 Test loss: 0.146151(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Kerala n_f 5 t_s 7 n_layers 1 Error 0.19048317 0.20774427025257952 -1.4705117734775341\n",
            "Epoch: 0/10  Loss: 0.048404 Test loss: 0.049102Kerala n_f 5 t_s 7 n_layers 2 Error 0.11541462 0.12466165079862061 -0.30234342718803475\n",
            "Epoch: 0/10  Loss: 0.209934 Test loss: 0.036881(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Kerala n_f 6 t_s 5 n_layers 1 Error 0.1630515 0.17685097404847522 -1.6210462200427607\n",
            "Epoch: 0/10  Loss: 0.076683 Test loss: 0.326584Kerala n_f 6 t_s 5 n_layers 2 Error 0.16209729 0.17560851829205115 -0.7653058969387863\n",
            "Epoch: 0/10  Loss: 0.051518 Test loss: 0.162181(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Kerala n_f 6 t_s 7 n_layers 1 Error 0.060063932 0.07695094313650822 0.6610335228244698\n",
            "Epoch: 0/10  Loss: 0.060858 Test loss: 0.065069Kerala n_f 6 t_s 7 n_layers 2 Error 0.10785188 0.12528790904508025 -0.3154612578220153\n",
            "Epoch: 0/10  Loss: 0.150647 Test loss: 0.252143(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Tamil-Nadu n_f 1 t_s 5 n_layers 1 Error 0.083972655 0.09844975433064676 0.18775135764503104\n",
            "Epoch: 0/10  Loss: 0.046616 Test loss: 0.058020Tamil-Nadu n_f 1 t_s 5 n_layers 2 Error 0.09883035 0.1113252430258372 0.4170809524699818\n",
            "Epoch: 0/10  Loss: 0.156399 Test loss: 0.203632(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Tamil-Nadu n_f 1 t_s 7 n_layers 1 Error 0.06328348 0.06768405995781084 0.7845265473684215\n",
            "Epoch: 0/10  Loss: 0.118801 Test loss: 0.146822Tamil-Nadu n_f 1 t_s 7 n_layers 2 Error 0.10109801 0.11153827875798084 0.2672358167634046\n",
            "Epoch: 0/10  Loss: 0.100511 Test loss: 0.284757(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Tamil-Nadu n_f 2 t_s 5 n_layers 1 Error 0.047045525 0.04953020322608142 0.855503780478267\n",
            "Epoch: 0/10  Loss: 0.158914 Test loss: 0.083448Tamil-Nadu n_f 2 t_s 5 n_layers 2 Error 0.05917659 0.07492512924597179 0.7359562131525356\n",
            "Epoch: 0/10  Loss: 0.141013 Test loss: 0.854515(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Tamil-Nadu n_f 2 t_s 7 n_layers 1 Error 0.08068239 0.09170961798383123 0.6044050735093216\n",
            "Epoch: 0/10  Loss: 0.057141 Test loss: 0.039730Tamil-Nadu n_f 2 t_s 7 n_layers 2 Error 0.059311364 0.07682941969594648 0.6523266560490133\n",
            "Epoch: 0/10  Loss: 0.152043 Test loss: 0.382390(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Tamil-Nadu n_f 3 t_s 5 n_layers 1 Error 0.030382734 0.034880380284053256 0.9283396843253607\n",
            "Epoch: 0/10  Loss: 0.033710 Test loss: 0.004859Tamil-Nadu n_f 3 t_s 5 n_layers 2 Error 0.046612192 0.06127025719949182 0.8234286139023881\n",
            "Epoch: 0/10  Loss: 0.125303 Test loss: 0.319181(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Tamil-Nadu n_f 3 t_s 7 n_layers 1 Error 0.03692569 0.04806393576314154 0.8913425350004528\n",
            "Epoch: 0/10  Loss: 0.055796 Test loss: 0.006663Tamil-Nadu n_f 3 t_s 7 n_layers 2 Error 0.056235127 0.07192399814168669 0.6953059856667525\n",
            "Epoch: 0/10  Loss: 0.252848 Test loss: 0.139013(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Tamil-Nadu n_f 4 t_s 5 n_layers 1 Error 0.04017893 0.04973686967723799 0.8542954414252144\n",
            "Epoch: 0/10  Loss: 0.050737 Test loss: 0.003989Tamil-Nadu n_f 4 t_s 5 n_layers 2 Error 0.048746005 0.05482294773236165 0.858633765943346\n",
            "Epoch: 0/10  Loss: 0.180989 Test loss: 0.429353(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Tamil-Nadu n_f 4 t_s 7 n_layers 1 Error 0.026353355 0.03427333095080507 0.944749837621804\n",
            "Epoch: 0/10  Loss: 0.045586 Test loss: 0.035723Tamil-Nadu n_f 4 t_s 7 n_layers 2 Error 0.046440665 0.054097410758841 0.8276269985158367\n",
            "Epoch: 0/10  Loss: 0.111414 Test loss: 0.257248(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Tamil-Nadu n_f 5 t_s 5 n_layers 1 Error 0.099228054 0.10422353880773698 0.360194584726782\n",
            "Epoch: 0/10  Loss: 0.064216 Test loss: 0.005895Tamil-Nadu n_f 5 t_s 5 n_layers 2 Error 0.09956043 0.11478433986163841 0.3802932494767167\n",
            "Epoch: 0/10  Loss: 0.100400 Test loss: 0.146613(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Tamil-Nadu n_f 5 t_s 7 n_layers 1 Error 0.039567232 0.04895587659862283 0.8872723139371224\n",
            "Epoch: 0/10  Loss: 0.069183 Test loss: 0.127717Tamil-Nadu n_f 5 t_s 7 n_layers 2 Error 0.09576081 0.11439348789264885 0.229240593387819\n",
            "Epoch: 0/10  Loss: 0.175478 Test loss: 0.088354(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Tamil-Nadu n_f 6 t_s 5 n_layers 1 Error 0.0959628 0.1009828689125861 0.3993635583265821\n",
            "Epoch: 0/10  Loss: 0.109325 Test loss: 0.141214Tamil-Nadu n_f 6 t_s 5 n_layers 2 Error 0.07685529 0.08740920300979743 0.6406354365731552\n",
            "Epoch: 0/10  Loss: 0.080773 Test loss: 0.172809(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Tamil-Nadu n_f 6 t_s 7 n_layers 1 Error 0.06593195 0.0773631470131811 0.7184930002048966\n",
            "Epoch: 0/10  Loss: 0.064729 Test loss: 0.028691Tamil-Nadu n_f 6 t_s 7 n_layers 2 Error 0.051418748 0.06403187886390534 0.7585046605079737\n",
            "Epoch: 0/10  Loss: 0.134983 Test loss: 0.664693"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6hN9QpGqW8xV",
        "outputId": "5ee62c64-2725-4a1b-e91d-c9e028892fb5"
      },
      "source": [
        "df_mlp = pd.DataFrame (results_mlp,columns=['State','Number_feature','Time_Step','number_layers','MAE','RMSE','R2_Score'])\n",
        "df_mlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Number_feature</th>\n",
              "      <th>Time_Step</th>\n",
              "      <th>number_layers</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.079391</td>\n",
              "      <td>0.086962</td>\n",
              "      <td>0.596229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.029453</td>\n",
              "      <td>0.037210</td>\n",
              "      <td>0.926075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.118503</td>\n",
              "      <td>0.120687</td>\n",
              "      <td>-0.223720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0.038969</td>\n",
              "      <td>0.051950</td>\n",
              "      <td>0.773256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.083641</td>\n",
              "      <td>0.085382</td>\n",
              "      <td>0.610761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>Tamil-Nadu</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0.095963</td>\n",
              "      <td>0.100983</td>\n",
              "      <td>0.399364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>Tamil-Nadu</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.076855</td>\n",
              "      <td>0.087409</td>\n",
              "      <td>0.640635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>Tamil-Nadu</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.065932</td>\n",
              "      <td>0.077363</td>\n",
              "      <td>0.718493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>Tamil-Nadu</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.051419</td>\n",
              "      <td>0.064032</td>\n",
              "      <td>0.758505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>Tamil-Nadu</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0.124040</td>\n",
              "      <td>0.126637</td>\n",
              "      <td>0.055425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          State  Number_feature  Time_Step  ...       MAE      RMSE  R2_Score\n",
              "0     Karnataka               1          5  ...  0.079391  0.086962  0.596229\n",
              "1     Karnataka               1          5  ...  0.029453  0.037210  0.926075\n",
              "2     Karnataka               1          7  ...  0.118503  0.120687 -0.223720\n",
              "3     Karnataka               1          7  ...  0.038969  0.051950  0.773256\n",
              "4     Karnataka               2          5  ...  0.083641  0.085382  0.610761\n",
              "..          ...             ...        ...  ...       ...       ...       ...\n",
              "115  Tamil-Nadu               5          7  ...  0.095963  0.100983  0.399364\n",
              "116  Tamil-Nadu               6          5  ...  0.076855  0.087409  0.640635\n",
              "117  Tamil-Nadu               6          5  ...  0.065932  0.077363  0.718493\n",
              "118  Tamil-Nadu               6          7  ...  0.051419  0.064032  0.758505\n",
              "119  Tamil-Nadu               6          7  ...  0.124040  0.126637  0.055425\n",
              "\n",
              "[120 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTgheDsDpH_f",
        "outputId": "41433b91-0b98-474a-9cdb-050935946d53"
      },
      "source": [
        "#github_upload(folder_name='Indian-States-Model-Results',file_name='MLP_on_short_data.csv', file_data=df_mlp.to_csv())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indian-States-Model-Results/MLP_on_short_data.csv UPDATED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdabRPjudcQ0"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim,  output_dim,num_layers, seq_length):\n",
        "        super(LSTM, self).__init__()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_length=seq_length\n",
        "        # Number of hidden layers\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.relu = nn.ELU()\n",
        "        # Readout layer\n",
        "        print(output_dim)\n",
        "        self.fc = nn.Linear(hidden_dim*self.seq_length, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # Initialize cell state\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        x = out.contiguous().view(batch_size,-1)\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 32, 100\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
        "        out = self.fc(self.relu(x)) \n",
        "        # out.size() --> 100, 10\n",
        "        return out\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1718BHMicgT8",
        "outputId": "4d21e9ee-f206-45ca-8683-b9d33406fd2a"
      },
      "source": [
        "Shortlisted_States=['Karnataka','Maharashtra','Uttar-Pradesh','Kerala','Tamil-Nadu']\n",
        "results_lstm=[]\n",
        "lstm_models=[]\n",
        "for state in Shortlisted_States:\n",
        "  best_models=[]\n",
        "  df=pd.read_csv(\"https://raw.githubusercontent.com/sureshkuc/Data-Science-in-Life-Science-Project/main/Indian-States-Covid19-Datasets/\"+state+\".csv\", parse_dates=[\"Date\"]).drop(columns =[\"Unnamed: 0\"])\n",
        "  df_temp1 = df[df[\"Date\"] <= \"2020-06-18\"]\n",
        "  df_temp2=  df[df[\"Date\"] > \"2020-03-09\"]\n",
        "  df = pd.merge(df_temp1, df_temp2, how='inner')\n",
        "  df = df.set_index(\"Date\")\n",
        "  df = df[['Confirmed', 'Recovered', 'Deceased', 'New_Confirmerd', 'New_Deaths', 'New_Recovered']]\n",
        "  #print(df.describe())\n",
        "\n",
        "  time_step=[5,7]\n",
        "  Number_of_feature=[1,2,3,4,5,6]\n",
        "  multi_feature=True\n",
        "  output_dim=1\n",
        "  min_error=np.iinfo(0).max\n",
        "  lstm_best_model={}\n",
        "  for n_f in Number_of_feature:\n",
        "    for t_s in time_step:\n",
        "      train_loader, test_loader,scaler = data_preparation(df, scaling_range=(0,1),time_step=t_s,number_feature=n_f, response_variable_index=0,data_split_ratio=0.8, Suffle=False)\n",
        "      for n_layers in range(1,2,1):\n",
        "        for n_hidden_nodes in [1,8,16,32]:\n",
        "          #random.seed(42)\n",
        "          #torch.manual_seed(42)\n",
        "          #np.random.seed(42)\n",
        "          max_epochs=50\n",
        "          \n",
        "          #CNN model with L1 loss\n",
        "          #best_model=Call_CNN_model(state,dataset=(train_loader, test_loader), lr=1e-2,criterion=nn.L1Loss(),max_epochs=max_epochs)\n",
        "          lstm_model = LSTM(n_f, n_hidden_nodes, output_dim, n_layers,t_s)\n",
        "          #if torch.cuda.is_available():\n",
        "          #stm_model = lstm_model.cuda()\n",
        "          #print(lstm_model)\n",
        "          lstm_optim = optim.SGD(lstm_model.parameters(), lr=1e-2, momentum=0.9)\n",
        "          #fc_optim = optim.Adam(fc_model.parameters(), lr=1e-3)\n",
        "          train_losses,test_losses,best_model = fit(lstm_model, lstm_optim,nn.L1Loss(),(train_loader, test_loader), max_epochs=max_epochs,cuda=False)\n",
        "          #print(f'\\nTraining took {end-start}s!')\n",
        "          #plot_loss(max_epochs,train_losses,test_losses,model_name='CNN for '+state)\n",
        "          lstm_model = LSTM(n_f, n_hidden_nodes, output_dim, n_layers,t_s)\n",
        "          lstm_model.load_state_dict(best_model)\n",
        "          lstm_model.eval()\n",
        "          test_x,test_y=test_loader\n",
        "          predictions=lstm_model(test_x)\n",
        "          test_y=test_y.cpu().detach().numpy()\n",
        "          predictions=predictions.cpu().detach().numpy()\n",
        "          mae=mean_absolute_error(test_y,predictions)\n",
        "          rmse=math.sqrt(mean_squared_error(test_y,predictions))\n",
        "          if rmse<min_error:\n",
        "            min_error=rmse\n",
        "            lstm_best_model=best_model\n",
        "          #mape=mean_absolute_percentage_error(test_y,predictions)\n",
        "          r2s=r2_score(test_y,predictions)\n",
        "          results_lstm.append([state,n_f,t_s,n_layers,n_hidden_nodes,mae,rmse,r2s])\n",
        "          print(state,'n_f',n_f,'t_s',t_s,'n_layers',n_layers,n_hidden_nodes,'Error',mae,rmse,r2s)\n",
        "  lstm_models.append(lstm_best_model) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.051016 Test loss: 0.3548371\n",
            "Karnataka n_f 1 t_s 5 n_layers 1 1 Error 0.46585044 0.4809195102056081 -11.348774318628704\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.134252 Test loss: 0.4259491\n",
            "Karnataka n_f 1 t_s 5 n_layers 1 8 Error 0.32935384 0.33524273954618367 -5.000644141781347\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.185966 Test loss: 0.5585121\n",
            "Karnataka n_f 1 t_s 5 n_layers 1 16 Error 0.27925783 0.283907704451955 -3.303615172027354\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.073047 Test loss: 0.4120711\n",
            "Karnataka n_f 1 t_s 5 n_layers 1 32 Error 0.10916517 0.11160362187008635 0.33497855431661916\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.152302 Test loss: 0.5054311\n",
            "Karnataka n_f 1 t_s 7 n_layers 1 1 Error 0.7183716 0.7260731515575126 -43.29142351406288\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.113735 Test loss: 0.5914151\n",
            "Karnataka n_f 1 t_s 7 n_layers 1 8 Error 0.41436848 0.41801896194747623 -13.680837354244114\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.091827 Test loss: 0.4426941\n",
            "Karnataka n_f 1 t_s 7 n_layers 1 16 Error 0.030235149 0.03592857102199953 0.8915476935610775\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.056423 Test loss: 0.3332501\n",
            "Karnataka n_f 1 t_s 7 n_layers 1 32 Error 0.036172405 0.041974235733937326 0.8519786118932493\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.109202 Test loss: 0.5621641\n",
            "Karnataka n_f 2 t_s 5 n_layers 1 1 Error 0.6958389 0.708865531439751 -25.829145721792074\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.102996 Test loss: 0.5436271\n",
            "Karnataka n_f 2 t_s 5 n_layers 1 8 Error 0.31287643 0.3144733232917911 -4.280155142496372\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.098240 Test loss: 0.5594231\n",
            "Karnataka n_f 2 t_s 5 n_layers 1 16 Error 0.053920824 0.06660804521216257 0.7631177633711126\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.083495 Test loss: 0.4623501\n",
            "Karnataka n_f 2 t_s 5 n_layers 1 32 Error 0.10169819 0.11222976175455779 0.32749554401716585\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.093818 Test loss: 0.4653841\n",
            "Karnataka n_f 2 t_s 7 n_layers 1 1 Error 0.102546446 0.11269102402432865 -0.06693407687243602\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.115984 Test loss: 0.6500251\n",
            "Karnataka n_f 2 t_s 7 n_layers 1 8 Error 0.10691026 0.1228039136644167 -0.2670195627693741\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.048502 Test loss: 0.3290241\n",
            "Karnataka n_f 2 t_s 7 n_layers 1 16 Error 0.06776407 0.07628107496422795 0.5111309562125611\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.049097 Test loss: 0.3159431\n",
            "Karnataka n_f 2 t_s 7 n_layers 1 32 Error 0.08399185 0.10232143468213045 0.12038596911543187\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.222899 Test loss: 0.2435171\n",
            "Karnataka n_f 3 t_s 5 n_layers 1 1 Error 0.18168505 0.18400193553792837 -0.807689592157002\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.068899 Test loss: 0.3998161\n",
            "Karnataka n_f 3 t_s 5 n_layers 1 8 Error 0.35207972 0.3556122961607773 -5.752003094008565\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.108183 Test loss: 0.5944211\n",
            "Karnataka n_f 3 t_s 5 n_layers 1 16 Error 0.3664649 0.36976074931244585 -6.299963916313825\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.121488 Test loss: 0.3925661\n",
            "Karnataka n_f 3 t_s 5 n_layers 1 32 Error 0.32486194 0.3275612347626993 -4.728805812661334\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.115709 Test loss: 0.6191771\n",
            "Karnataka n_f 3 t_s 7 n_layers 1 1 Error 0.63274574 0.6426167114174426 -33.69468434621111\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.091476 Test loss: 0.4918501\n",
            "Karnataka n_f 3 t_s 7 n_layers 1 8 Error 0.18315737 0.1837175236112901 -1.8356983850868067\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.093695 Test loss: 0.3855031\n",
            "Karnataka n_f 3 t_s 7 n_layers 1 16 Error 0.29481876 0.29529081093396947 -6.325861967994186\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.122033 Test loss: 0.6472481\n",
            "Karnataka n_f 3 t_s 7 n_layers 1 32 Error 0.27253988 0.2726857204960621 -5.2471752178748\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.149929 Test loss: 0.4462361\n",
            "Karnataka n_f 4 t_s 5 n_layers 1 1 Error 0.68081456 0.6942525564097893 -24.73440051638309\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.102874 Test loss: 0.6237621\n",
            "Karnataka n_f 4 t_s 5 n_layers 1 8 Error 0.23390672 0.24779138398131628 -2.278320853327033\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.066033 Test loss: 0.3956861\n",
            "Karnataka n_f 4 t_s 5 n_layers 1 16 Error 0.25746876 0.26814335620174484 -2.838956104101468\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.094086 Test loss: 0.4897361\n",
            "Karnataka n_f 4 t_s 5 n_layers 1 32 Error 0.14839026 0.16695585469079263 -0.4882722960970558\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.091466 Test loss: 0.5143921\n",
            "Karnataka n_f 4 t_s 7 n_layers 1 1 Error 0.70108867 0.7090802929101316 -41.24251475536289\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.136349 Test loss: 0.3318261\n",
            "Karnataka n_f 4 t_s 7 n_layers 1 8 Error 0.1986479 0.20825980597623547 -2.6439280741359026\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.086719 Test loss: 0.4831781\n",
            "Karnataka n_f 4 t_s 7 n_layers 1 16 Error 0.08321236 0.09725817130916847 0.2052856156143137\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.061522 Test loss: 0.3146531\n",
            "Karnataka n_f 4 t_s 7 n_layers 1 32 Error 0.1474354 0.1586418778817035 -1.1144360721683797\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.095168 Test loss: 0.4647531\n",
            "Karnataka n_f 5 t_s 5 n_layers 1 1 Error 0.74976474 0.7665729881841203 -30.375170089775832\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.055559 Test loss: 0.3289611\n",
            "Karnataka n_f 5 t_s 5 n_layers 1 8 Error 0.25436422 0.26488150999792237 -2.746126047468372\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.095405 Test loss: 0.3987581\n",
            "Karnataka n_f 5 t_s 5 n_layers 1 16 Error 0.18835132 0.20024552994762143 -1.1409413361107772\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.129668 Test loss: 0.5995291\n",
            "Karnataka n_f 5 t_s 5 n_layers 1 32 Error 0.21382447 0.22723926391305158 -1.7570574470325542\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.129623 Test loss: 0.5803611\n",
            "Karnataka n_f 5 t_s 7 n_layers 1 1 Error 0.13732639 0.15601969673982896 -1.0451150617244336\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.172416 Test loss: 0.6865591\n",
            "Karnataka n_f 5 t_s 7 n_layers 1 8 Error 0.23764852 0.24236853047973841 -3.9352748209126647\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.112007 Test loss: 0.5730171\n",
            "Karnataka n_f 5 t_s 7 n_layers 1 16 Error 0.07436262 0.08706646854717252 0.3631153966973871\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.109522 Test loss: 0.5593741\n",
            "Karnataka n_f 5 t_s 7 n_layers 1 32 Error 0.16710219 0.1712287435600263 -1.463271080258949\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.304555 Test loss: 0.3213221\n",
            "Karnataka n_f 6 t_s 5 n_layers 1 1 Error 0.086289614 0.10987961965506499 0.35536577588457063\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.102119 Test loss: 0.4117791\n",
            "Karnataka n_f 6 t_s 5 n_layers 1 8 Error 0.11163318 0.1261096591320011 0.15086687967257062\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.071485 Test loss: 0.3288271\n",
            "Karnataka n_f 6 t_s 5 n_layers 1 16 Error 0.19127731 0.19640321401466498 -1.059568646320907\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.062688 Test loss: 0.4098891\n",
            "Karnataka n_f 6 t_s 5 n_layers 1 32 Error 0.23399626 0.24383621311187445 -2.1745010021106865\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.272656 Test loss: 0.3335011\n",
            "Karnataka n_f 6 t_s 7 n_layers 1 1 Error 0.3103468 0.31307049175959184 -7.234612747131191\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.104614 Test loss: 0.4273461\n",
            "Karnataka n_f 6 t_s 7 n_layers 1 8 Error 0.16477463 0.1730953103560066 -1.517268479976917\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.084218 Test loss: 0.4468071\n",
            "Karnataka n_f 6 t_s 7 n_layers 1 16 Error 0.088611566 0.1042229356382763 0.08738943790305165\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.058442 Test loss: 0.3557811\n",
            "Karnataka n_f 6 t_s 7 n_layers 1 32 Error 0.12988599 0.14296468171340046 -0.7171824347097349\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.140735 Test loss: 0.5646421\n",
            "Maharashtra n_f 1 t_s 5 n_layers 1 1 Error 0.06537358 0.08498782247728183 0.38827510785856056\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.150178 Test loss: 0.5715191\n",
            "Maharashtra n_f 1 t_s 5 n_layers 1 8 Error 0.10123818 0.10389188097072542 0.08587417669173003\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.142565 Test loss: 0.5446451\n",
            "Maharashtra n_f 1 t_s 5 n_layers 1 16 Error 0.044137966 0.044422758793534314 0.8328702527843574\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.128767 Test loss: 0.4705391\n",
            "Maharashtra n_f 1 t_s 5 n_layers 1 32 Error 0.15006043 0.15015787841239386 -0.9095848882784199\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.137755 Test loss: 0.3422991\n",
            "Maharashtra n_f 1 t_s 7 n_layers 1 1 Error 0.04231017 0.05397934389546909 0.6854622764827194\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.108839 Test loss: 0.3818091\n",
            "Maharashtra n_f 1 t_s 7 n_layers 1 8 Error 0.034171242 0.04366185108228718 0.7942111550637769\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.108806 Test loss: 0.3760771\n",
            "Maharashtra n_f 1 t_s 7 n_layers 1 16 Error 0.026506813 0.02913928663086123 0.9083409494890133\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.146109 Test loss: 0.5276101\n",
            "Maharashtra n_f 1 t_s 7 n_layers 1 32 Error 0.014855788 0.019353126612486032 0.9595685041729013\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.192225 Test loss: 0.4814031\n",
            "Maharashtra n_f 2 t_s 5 n_layers 1 1 Error 0.41751102 0.42299674275115867 -14.153634336135486\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.150968 Test loss: 0.4706741\n",
            "Maharashtra n_f 2 t_s 5 n_layers 1 8 Error 0.07958701 0.0817333842078735 0.43422767695335274\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.110368 Test loss: 0.4750381\n",
            "Maharashtra n_f 2 t_s 5 n_layers 1 16 Error 0.038415138 0.03944195828944512 0.8682472556625436\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.153551 Test loss: 0.6006821\n",
            "Maharashtra n_f 2 t_s 5 n_layers 1 32 Error 0.050234176 0.05264723164985628 0.7652563642612553\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.334243 Test loss: 0.7835311\n",
            "Maharashtra n_f 2 t_s 7 n_layers 1 1 Error 0.039822273 0.04627546722414786 0.7688365334298086\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.233667 Test loss: 0.4983581\n",
            "Maharashtra n_f 2 t_s 7 n_layers 1 8 Error 0.07606118 0.07632212004179222 0.37119149296981147\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.177856 Test loss: 0.4757721\n",
            "Maharashtra n_f 2 t_s 7 n_layers 1 16 Error 0.021192206 0.024932170284037658 0.9328976550754319\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.116432 Test loss: 0.3589581\n",
            "Maharashtra n_f 2 t_s 7 n_layers 1 32 Error 0.03936045 0.03956888514483457 0.8309850564376304\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.273229 Test loss: 0.2887661\n",
            "Maharashtra n_f 3 t_s 5 n_layers 1 1 Error 0.6602641 0.6670431673330623 -36.68344484046984\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.172698 Test loss: 0.4222261\n",
            "Maharashtra n_f 3 t_s 5 n_layers 1 8 Error 0.026758986 0.029494014700755983 0.9263266371663106\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.101388 Test loss: 0.3129181\n",
            "Maharashtra n_f 3 t_s 5 n_layers 1 16 Error 0.063292384 0.06937282212486066 0.5924119498004923\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.152662 Test loss: 0.6060431\n",
            "Maharashtra n_f 3 t_s 5 n_layers 1 32 Error 0.0096412385 0.01085278690381751 0.9900247157622245\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.160118 Test loss: 0.4959871\n",
            "Maharashtra n_f 3 t_s 7 n_layers 1 1 Error 0.069778726 0.0721985499225091 0.43730315338325787\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.130883 Test loss: 0.3821981\n",
            "Maharashtra n_f 3 t_s 7 n_layers 1 8 Error 0.02418823 0.029520130853606948 0.9059293644063869\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.177807 Test loss: 0.6752121\n",
            "Maharashtra n_f 3 t_s 7 n_layers 1 16 Error 0.019462444 0.02391302975652559 0.9382713557220475\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.147300 Test loss: 0.5435981\n",
            "Maharashtra n_f 3 t_s 7 n_layers 1 32 Error 0.038066722 0.03855921507835151 0.8395004378656727\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.134058 Test loss: 0.4165171\n",
            "Maharashtra n_f 4 t_s 5 n_layers 1 1 Error 0.15564352 0.18235044326527 -1.8161541589258214\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.309901 Test loss: 0.7792871\n",
            "Maharashtra n_f 4 t_s 5 n_layers 1 8 Error 0.09254031 0.10374185295318201 0.08851250603472138\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.158327 Test loss: 0.7016701\n",
            "Maharashtra n_f 4 t_s 5 n_layers 1 16 Error 0.15951075 0.1633095436131527 -1.258737881174889\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.130494 Test loss: 0.5014601\n",
            "Maharashtra n_f 4 t_s 5 n_layers 1 32 Error 0.12959246 0.13170631535528968 -0.4691153593855846\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.303681 Test loss: 0.7561731\n",
            "Maharashtra n_f 4 t_s 7 n_layers 1 1 Error 0.15728267 0.18286223468632193 -2.6096539563920973\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.236339 Test loss: 0.5307821\n",
            "Maharashtra n_f 4 t_s 7 n_layers 1 8 Error 0.09514709 0.10300461125091888 -0.14533062678642295\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.112379 Test loss: 0.4021751\n",
            "Maharashtra n_f 4 t_s 7 n_layers 1 16 Error 0.07411246 0.07705254268687665 0.3590982200026728\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.149604 Test loss: 0.5428141\n",
            "Maharashtra n_f 4 t_s 7 n_layers 1 32 Error 0.062431686 0.06315469567388425 0.569444844551888\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.140606 Test loss: 0.5085561\n",
            "Maharashtra n_f 5 t_s 5 n_layers 1 1 Error 0.16102979 0.16390850014683025 -1.2753368325559942\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.114034 Test loss: 0.3687961\n",
            "Maharashtra n_f 5 t_s 5 n_layers 1 8 Error 0.0728442 0.07774623907309769 0.4880806970511691\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.135807 Test loss: 0.4469391\n",
            "Maharashtra n_f 5 t_s 5 n_layers 1 16 Error 0.08049724 0.08376706641589537 0.4057224163161157\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.107231 Test loss: 0.4110041\n",
            "Maharashtra n_f 5 t_s 5 n_layers 1 32 Error 0.1322659 0.13405716617572971 -0.522028455764862\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.183699 Test loss: 0.5308441\n",
            "Maharashtra n_f 5 t_s 7 n_layers 1 1 Error 0.11889953 0.1281444261524599 -0.7726255857960798\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.169423 Test loss: 0.6122111\n",
            "Maharashtra n_f 5 t_s 7 n_layers 1 8 Error 0.18789479 0.19423074606984647 -3.0724283982775376\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.161300 Test loss: 0.5648101\n",
            "Maharashtra n_f 5 t_s 7 n_layers 1 16 Error 0.0999297 0.10526047557802107 -0.1960468319564217\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.119709 Test loss: 0.3640371\n",
            "Maharashtra n_f 5 t_s 7 n_layers 1 32 Error 0.061371412 0.06496337289654965 0.5444304588668194\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.162712 Test loss: 0.5116601\n",
            "Maharashtra n_f 6 t_s 5 n_layers 1 1 Error 0.43119913 0.4454238819231392 -15.803112127294103\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.160416 Test loss: 0.3811131\n",
            "Maharashtra n_f 6 t_s 5 n_layers 1 8 Error 0.091115505 0.09968150089413401 0.1584656731764068\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.103486 Test loss: 0.3879011\n",
            "Maharashtra n_f 6 t_s 5 n_layers 1 16 Error 0.11774682 0.12262488088567977 -0.27350286658261225\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.151897 Test loss: 0.5804141\n",
            "Maharashtra n_f 6 t_s 5 n_layers 1 32 Error 0.067241915 0.07098217779252511 0.5732816303526372\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.695285 Test loss: 0.9192671\n",
            "Maharashtra n_f 6 t_s 7 n_layers 1 1 Error 0.1325079 0.14006390158442655 -1.1177270704294666\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.172774 Test loss: 0.6607581\n",
            "Maharashtra n_f 6 t_s 7 n_layers 1 8 Error 0.09927475 0.10073378261991378 -0.09538773364871145\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.157804 Test loss: 0.5532351\n",
            "Maharashtra n_f 6 t_s 7 n_layers 1 16 Error 0.08076921 0.08646871556380276 0.19288476594317328\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.146089 Test loss: 0.5024621\n",
            "Maharashtra n_f 6 t_s 7 n_layers 1 32 Error 0.08742301 0.08956008163961895 0.13414240966848223\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.599134 Test loss: 1.1095801\n",
            "Uttar-Pradesh n_f 1 t_s 5 n_layers 1 1 Error 0.43155518 0.44108634091193966 -12.170286280251226\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.220585 Test loss: 0.4757701\n",
            "Uttar-Pradesh n_f 1 t_s 5 n_layers 1 8 Error 0.09446597 0.10174604025635159 0.2992178055108985\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.134931 Test loss: 0.3951621\n",
            "Uttar-Pradesh n_f 1 t_s 5 n_layers 1 16 Error 0.052276637 0.05857737034100166 0.7677221847894109\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.152549 Test loss: 0.3618391\n",
            "Uttar-Pradesh n_f 1 t_s 5 n_layers 1 32 Error 0.087505594 0.09108228227692258 0.43841453902454275\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.060962 Test loss: 0.0288991\n",
            "Uttar-Pradesh n_f 1 t_s 7 n_layers 1 1 Error 0.017101778 0.02487087716006344 0.9460471196547566\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.168546 Test loss: 0.5433851\n",
            "Uttar-Pradesh n_f 1 t_s 7 n_layers 1 8 Error 0.05519762 0.06561034441970114 0.6245283960204462\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.156097 Test loss: 0.3385981\n",
            "Uttar-Pradesh n_f 1 t_s 7 n_layers 1 16 Error 0.07678388 0.08042807986416084 0.43578084422808816\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.152168 Test loss: 0.4725971\n",
            "Uttar-Pradesh n_f 1 t_s 7 n_layers 1 32 Error 0.029353678 0.03365000655238313 0.901235072447659\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.179940 Test loss: 0.5649621\n",
            "Uttar-Pradesh n_f 2 t_s 5 n_layers 1 1 Error 0.63692975 0.6483291167716205 -27.45372265727586\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.252868 Test loss: 0.4308391\n",
            "Uttar-Pradesh n_f 2 t_s 5 n_layers 1 8 Error 0.042194102 0.05337089708444595 0.8071778092572315\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.134840 Test loss: 0.3052121\n",
            "Uttar-Pradesh n_f 2 t_s 5 n_layers 1 16 Error 0.11665011 0.12457832350141537 -0.050589295343941076\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.139706 Test loss: 0.4233181\n",
            "Uttar-Pradesh n_f 2 t_s 5 n_layers 1 32 Error 0.0150097255 0.018412971922360362 0.9770493068253748\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.235079 Test loss: 0.3430561\n",
            "Uttar-Pradesh n_f 2 t_s 7 n_layers 1 1 Error 0.65408486 0.6628654686510326 -37.32509196081579\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.169025 Test loss: 0.5975541\n",
            "Uttar-Pradesh n_f 2 t_s 7 n_layers 1 8 Error 0.077161714 0.09018727638060935 0.29054805959146146\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.173912 Test loss: 0.5719761\n",
            "Uttar-Pradesh n_f 2 t_s 7 n_layers 1 16 Error 0.043399677 0.050643566896971935 0.776292270777027\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.170279 Test loss: 0.3885561\n",
            "Uttar-Pradesh n_f 2 t_s 7 n_layers 1 32 Error 0.04219263 0.04715508241531999 0.8060501547494703\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.140217 Test loss: 0.4713791\n",
            "Uttar-Pradesh n_f 3 t_s 5 n_layers 1 1 Error 0.2221708 0.24440589226590573 -3.0436297338318283\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.155616 Test loss: 0.5214601\n",
            "Uttar-Pradesh n_f 3 t_s 5 n_layers 1 8 Error 0.120074175 0.13762950677491395 -0.28224541412894233\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.159381 Test loss: 0.5207951\n",
            "Uttar-Pradesh n_f 3 t_s 5 n_layers 1 16 Error 0.06803374 0.08073538774187754 0.5587589438137629\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.121705 Test loss: 0.3316331\n",
            "Uttar-Pradesh n_f 3 t_s 5 n_layers 1 32 Error 0.08375559 0.0892877582758864 0.4603255726527683\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.218106 Test loss: 0.4859271\n",
            "Uttar-Pradesh n_f 3 t_s 7 n_layers 1 1 Error 0.25303248 0.27478630638871526 -5.586013294529845\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.173661 Test loss: 0.5703961\n",
            "Uttar-Pradesh n_f 3 t_s 7 n_layers 1 8 Error 0.07770659 0.08479837782452253 0.37279785607520677\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.101268 Test loss: 0.2435351\n",
            "Uttar-Pradesh n_f 3 t_s 7 n_layers 1 16 Error 0.06387858 0.0702947289473564 0.5689993396489307\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.149912 Test loss: 0.3824191\n",
            "Uttar-Pradesh n_f 3 t_s 7 n_layers 1 32 Error 0.06606179 0.07057173280438525 0.5655958226722233\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.601763 Test loss: 1.3070061\n",
            "Uttar-Pradesh n_f 4 t_s 5 n_layers 1 1 Error 0.11252436 0.12732089399223823 -0.09735557654302163\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.147877 Test loss: 0.4906171\n",
            "Uttar-Pradesh n_f 4 t_s 5 n_layers 1 8 Error 0.062230337 0.07472151883837193 0.6220456464912159\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.158966 Test loss: 0.4968681\n",
            "Uttar-Pradesh n_f 4 t_s 5 n_layers 1 16 Error 0.11478988 0.12515061959925985 -0.06026406273292695\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.134431 Test loss: 0.4024081\n",
            "Uttar-Pradesh n_f 4 t_s 5 n_layers 1 32 Error 0.041571677 0.04390687320986431 0.8694992530229804\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.146522 Test loss: 0.4913131\n",
            "Uttar-Pradesh n_f 4 t_s 7 n_layers 1 1 Error 0.21271852 0.2391624727834005 -3.989057350308914\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.112955 Test loss: 0.3702311\n",
            "Uttar-Pradesh n_f 4 t_s 7 n_layers 1 8 Error 0.0741876 0.08298202843473707 0.39937896195963274\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.146881 Test loss: 0.4145951\n",
            "Uttar-Pradesh n_f 4 t_s 7 n_layers 1 16 Error 0.16942522 0.17325466910967868 -1.6181970022508851\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.116514 Test loss: 0.3871231\n",
            "Uttar-Pradesh n_f 4 t_s 7 n_layers 1 32 Error 0.034757398 0.0411668512841692 0.8521818616573769\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.386515 Test loss: 0.6721941\n",
            "Uttar-Pradesh n_f 5 t_s 5 n_layers 1 1 Error 0.055562515 0.0712278050645565 0.6565629627808469\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.189201 Test loss: 0.5328921\n",
            "Uttar-Pradesh n_f 5 t_s 5 n_layers 1 8 Error 0.16887681 0.18324649720337519 -1.2731042658024747\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.174744 Test loss: 0.4444871\n",
            "Uttar-Pradesh n_f 5 t_s 5 n_layers 1 16 Error 0.15838107 0.16126024813393022 -0.7603646469829137\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.147364 Test loss: 0.5016991\n",
            "Uttar-Pradesh n_f 5 t_s 5 n_layers 1 32 Error 0.019115325 0.024548167034130857 0.959206948578065\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.151524 Test loss: 0.4781771\n",
            "Uttar-Pradesh n_f 5 t_s 7 n_layers 1 1 Error 0.24314393 0.25769274271004194 -4.792110669541461\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.176294 Test loss: 0.5494331\n",
            "Uttar-Pradesh n_f 5 t_s 7 n_layers 1 8 Error 0.1312274 0.14279644724611412 -0.7785546000530348\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.158238 Test loss: 0.5017151\n",
            "Uttar-Pradesh n_f 5 t_s 7 n_layers 1 16 Error 0.056056246 0.06020097409172453 0.6838890999563505\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.116438 Test loss: 0.3106281\n",
            "Uttar-Pradesh n_f 5 t_s 7 n_layers 1 32 Error 0.026420226 0.027452492129177466 0.9342651054335511\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.198929 Test loss: 0.3813271\n",
            "Uttar-Pradesh n_f 6 t_s 5 n_layers 1 1 Error 0.540512 0.5511461766968357 -19.562769821718614\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.160213 Test loss: 0.3822441\n",
            "Uttar-Pradesh n_f 6 t_s 5 n_layers 1 8 Error 0.059850737 0.062298931854493686 0.737270279319703\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.112558 Test loss: 0.3268601\n",
            "Uttar-Pradesh n_f 6 t_s 5 n_layers 1 16 Error 0.06762425 0.07071340365013681 0.6615055702605186\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.145967 Test loss: 0.4946841\n",
            "Uttar-Pradesh n_f 6 t_s 5 n_layers 1 32 Error 0.10868552 0.11078496658402037 0.1691746793229839\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.308701 Test loss: 0.2140501\n",
            "Uttar-Pradesh n_f 6 t_s 7 n_layers 1 1 Error 0.37368506 0.37940853294349935 -11.55586335194305\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.158123 Test loss: 0.4524861\n",
            "Uttar-Pradesh n_f 6 t_s 7 n_layers 1 8 Error 0.028276127 0.031504490726320715 0.9134280165033352\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.191293 Test loss: 0.3355201\n",
            "Uttar-Pradesh n_f 6 t_s 7 n_layers 1 16 Error 0.19023657 0.19396049808853913 -2.281398990251644\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.153310 Test loss: 0.4527441\n",
            "Uttar-Pradesh n_f 6 t_s 7 n_layers 1 32 Error 0.10396035 0.10452877723152557 0.04697530018791152\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.492775 Test loss: 0.9778081\n",
            "Kerala n_f 1 t_s 5 n_layers 1 1 Error 0.47057298 0.48091120622626593 -12.239105973445348\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.094807 Test loss: 0.2823211\n",
            "Kerala n_f 1 t_s 5 n_layers 1 8 Error 0.29164565 0.2978706103628562 -4.07907009353918\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.105350 Test loss: 0.3415231\n",
            "Kerala n_f 1 t_s 5 n_layers 1 16 Error 0.19386707 0.20160293690982217 -1.3266043306414184\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.106121 Test loss: 0.3832261\n",
            "Kerala n_f 1 t_s 5 n_layers 1 32 Error 0.2023216 0.20675719313868385 -1.4470910772989618\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.417096 Test loss: 0.1787511\n",
            "Kerala n_f 1 t_s 7 n_layers 1 1 Error 0.55678564 0.5644785733409616 -25.702668602852977\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.120583 Test loss: 0.2892371\n",
            "Kerala n_f 1 t_s 7 n_layers 1 8 Error 0.043060977 0.04468406569849184 0.8326733590773137\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.172774 Test loss: 0.4024091\n",
            "Kerala n_f 1 t_s 7 n_layers 1 16 Error 0.1621649 0.16232596715803208 -1.2081864807844398\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.104107 Test loss: 0.3302901\n",
            "Kerala n_f 1 t_s 7 n_layers 1 32 Error 0.113497786 0.11380802371090344 -0.08543914147190934\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.104704 Test loss: 0.3442591\n",
            "Kerala n_f 2 t_s 5 n_layers 1 1 Error 0.35480362 0.3646521185519043 -6.6117818807348785\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.208083 Test loss: 0.4419971\n",
            "Kerala n_f 2 t_s 5 n_layers 1 8 Error 0.30362007 0.31154952941495334 -4.5562658212183775\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.112642 Test loss: 0.4139961\n",
            "Kerala n_f 2 t_s 5 n_layers 1 16 Error 0.28493363 0.2929260095573219 -3.911845961863068\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.245833 Test loss: 0.4931871\n",
            "Kerala n_f 2 t_s 5 n_layers 1 32 Error 0.24255809 0.24815334077740744 -2.525080758000767\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.389738 Test loss: 0.8815441\n",
            "Kerala n_f 2 t_s 7 n_layers 1 1 Error 0.33800456 0.3435687107262491 -8.892065400924356\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.130078 Test loss: 0.4223251\n",
            "Kerala n_f 2 t_s 7 n_layers 1 8 Error 0.31026584 0.31276068543171937 -7.197550800223098\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.095596 Test loss: 0.3310191\n",
            "Kerala n_f 2 t_s 7 n_layers 1 16 Error 0.28790945 0.29010886177678746 -6.053128107094188\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.128097 Test loss: 0.3839881\n",
            "Kerala n_f 2 t_s 7 n_layers 1 32 Error 0.2524636 0.2541551103987333 -4.413241656471866\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.112652 Test loss: 0.3998751\n",
            "Kerala n_f 3 t_s 5 n_layers 1 1 Error 0.58819425 0.6022829967689786 -19.764910359323284\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.097983 Test loss: 0.2832151\n",
            "Kerala n_f 3 t_s 5 n_layers 1 8 Error 0.13521184 0.14087142149138168 -0.13599028105959676\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.103646 Test loss: 0.3161071\n",
            "Kerala n_f 3 t_s 5 n_layers 1 16 Error 0.22180106 0.22643723806923594 -1.935111241634651\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.161378 Test loss: 0.3684731\n",
            "Kerala n_f 3 t_s 5 n_layers 1 32 Error 0.24910456 0.25256166231620164 -2.651436408446454\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.358850 Test loss: 0.7247281\n",
            "Kerala n_f 3 t_s 7 n_layers 1 1 Error 0.5366663 0.5428594575291239 -23.696450503839213\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.115361 Test loss: 0.4199811\n",
            "Kerala n_f 3 t_s 7 n_layers 1 8 Error 0.31149423 0.3148872151437924 -7.309403061576118\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.128441 Test loss: 0.3878481\n",
            "Kerala n_f 3 t_s 7 n_layers 1 16 Error 0.057598013 0.05942709701436515 0.7040428847931273\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.153696 Test loss: 0.2824541\n",
            "Kerala n_f 3 t_s 7 n_layers 1 32 Error 0.20649193 0.20751208123690534 -2.608664943552466\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.382035 Test loss: 0.6078771\n",
            "Kerala n_f 4 t_s 5 n_layers 1 1 Error 0.34167495 0.34824994646073343 -5.94242127945929\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.118050 Test loss: 0.3562471\n",
            "Kerala n_f 4 t_s 5 n_layers 1 8 Error 0.11599219 0.13677606743556575 -0.07090041912077072\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.182988 Test loss: 0.4316061\n",
            "Kerala n_f 4 t_s 5 n_layers 1 16 Error 0.16822621 0.17658757605600653 -0.785044736530498\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.118312 Test loss: 0.3777271\n",
            "Kerala n_f 4 t_s 5 n_layers 1 32 Error 0.08720918 0.10069651220197284 0.4195595293870572\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.251296 Test loss: 0.5809391\n",
            "Kerala n_f 4 t_s 7 n_layers 1 1 Error 0.46281 0.47291800446958276 -17.742671438144317\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.219561 Test loss: 0.3798811\n",
            "Kerala n_f 4 t_s 7 n_layers 1 8 Error 0.06628264 0.08691712170478272 0.36690276096317676\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.103410 Test loss: 0.3504081\n",
            "Kerala n_f 4 t_s 7 n_layers 1 16 Error 0.07488061 0.08876588832820866 0.33968371387335594\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.115732 Test loss: 0.3176361\n",
            "Kerala n_f 4 t_s 7 n_layers 1 32 Error 0.12082874 0.13157929766288357 -0.4508913548460318\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.171498 Test loss: 0.3247901\n",
            "Kerala n_f 5 t_s 5 n_layers 1 1 Error 0.39625582 0.40809564224903977 -8.533508552452203\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.184422 Test loss: 0.4599011\n",
            "Kerala n_f 5 t_s 5 n_layers 1 8 Error 0.124762885 0.1527408657011904 -0.33548604199622356\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.122106 Test loss: 0.4173391\n",
            "Kerala n_f 5 t_s 5 n_layers 1 16 Error 0.090960875 0.11042373542006494 0.30200276931373227\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.104705 Test loss: 0.3444441\n",
            "Kerala n_f 5 t_s 5 n_layers 1 32 Error 0.08070089 0.09994101479733046 0.42823661243526046\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.358408 Test loss: 0.5976951\n",
            "Kerala n_f 5 t_s 7 n_layers 1 1 Error 0.15124501 0.19290665890137262 -2.1185606721765473\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.089762 Test loss: 0.2553121\n",
            "Kerala n_f 5 t_s 7 n_layers 1 8 Error 0.1571295 0.17590175842396502 -1.5929857992554717\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.251770 Test loss: 0.4347001\n",
            "Kerala n_f 5 t_s 7 n_layers 1 16 Error 0.09518159 0.10670686226228243 0.04578893751101276\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.091823 Test loss: 0.2490721\n",
            "Kerala n_f 5 t_s 7 n_layers 1 32 Error 0.10227161 0.11761560919800801 -0.15928344168154496\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.185792 Test loss: 0.3092951\n",
            "Kerala n_f 6 t_s 5 n_layers 1 1 Error 0.26571813 0.2866519475963549 -3.703689574777785\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.154741 Test loss: 0.3837751\n",
            "Kerala n_f 6 t_s 5 n_layers 1 8 Error 0.13029364 0.1515016327874637 -0.31390348542353474\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.157137 Test loss: 0.2968001\n",
            "Kerala n_f 6 t_s 5 n_layers 1 16 Error 0.16272359 0.17443406117472426 -0.7417724021918812\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.097533 Test loss: 0.2708291\n",
            "Kerala n_f 6 t_s 5 n_layers 1 32 Error 0.096642725 0.11391759823101623 0.2571339712754962\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.346799 Test loss: 0.0958161\n",
            "Kerala n_f 6 t_s 7 n_layers 1 1 Error 0.069706686 0.07945256593108056 0.47097567270755647\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.144591 Test loss: 0.4155581\n",
            "Kerala n_f 6 t_s 7 n_layers 1 8 Error 0.14494017 0.154623783841512 -1.0036063361695122\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.108122 Test loss: 0.3660981\n",
            "Kerala n_f 6 t_s 7 n_layers 1 16 Error 0.106362425 0.11517856345488224 -0.11173959955733404\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.146152 Test loss: 0.3012301\n",
            "Kerala n_f 6 t_s 7 n_layers 1 32 Error 0.053539474 0.07023232577965596 0.5866348506732677\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.209207 Test loss: 0.2503221\n",
            "Tamil-Nadu n_f 1 t_s 5 n_layers 1 1 Error 0.030915562 0.035378074188910286 0.9411306407110033\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.139569 Test loss: 0.3992331\n",
            "Tamil-Nadu n_f 1 t_s 5 n_layers 1 8 Error 0.059373558 0.06935714679364939 0.7737422718461455\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.112286 Test loss: 0.4981531\n",
            "Tamil-Nadu n_f 1 t_s 5 n_layers 1 16 Error 0.32549196 0.33131960731285043 -4.1631552822226325\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.108002 Test loss: 0.5002831\n",
            "Tamil-Nadu n_f 1 t_s 5 n_layers 1 32 Error 0.050504994 0.05230645676740751 0.8713139128941079\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.259722 Test loss: 0.4591711\n",
            "Tamil-Nadu n_f 1 t_s 7 n_layers 1 1 Error 0.056414947 0.07290237114905847 0.6869601750695443\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.283880 Test loss: 0.5630181\n",
            "Tamil-Nadu n_f 1 t_s 7 n_layers 1 8 Error 0.3190232 0.32849413680152517 -5.355819324452436\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.105824 Test loss: 0.4613441\n",
            "Tamil-Nadu n_f 1 t_s 7 n_layers 1 16 Error 0.061898384 0.06640640777681345 0.7402615387988059\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.115424 Test loss: 0.4699431\n",
            "Tamil-Nadu n_f 1 t_s 7 n_layers 1 32 Error 0.37398046 0.3783117132829408 -7.429772707368928\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.132492 Test loss: 0.4394091\n",
            "Tamil-Nadu n_f 2 t_s 5 n_layers 1 1 Error 0.15002002 0.16666933271143355 -0.3065689933548874\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.096316 Test loss: 0.4334751\n",
            "Tamil-Nadu n_f 2 t_s 5 n_layers 1 8 Error 0.039796818 0.04968388951802359 0.8838946817811218\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.103533 Test loss: 0.3418941\n",
            "Tamil-Nadu n_f 2 t_s 5 n_layers 1 16 Error 0.025500687 0.03162428668067233 0.9529605322614523\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.096125 Test loss: 0.4206911\n",
            "Tamil-Nadu n_f 2 t_s 5 n_layers 1 32 Error 0.021088846 0.023875883922937814 0.9731873436811316\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.275926 Test loss: 0.6976671\n",
            "Tamil-Nadu n_f 2 t_s 7 n_layers 1 1 Error 0.23420833 0.24644000807280883 -2.577162604292398\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.125840 Test loss: 0.5064581\n",
            "Tamil-Nadu n_f 2 t_s 7 n_layers 1 8 Error 0.11975689 0.12816869816277954 0.032434836920818055\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.121894 Test loss: 0.3190891\n",
            "Tamil-Nadu n_f 2 t_s 7 n_layers 1 16 Error 0.051227845 0.053222608128797144 0.8331567806884119\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.104512 Test loss: 0.4138541\n",
            "Tamil-Nadu n_f 2 t_s 7 n_layers 1 32 Error 0.019632358 0.024626470675278192 0.9642792439747987\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.185545 Test loss: 0.3261801\n",
            "Tamil-Nadu n_f 3 t_s 5 n_layers 1 1 Error 0.30886942 0.31919154131041283 -3.7920758557832546\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.131565 Test loss: 0.2537191\n",
            "Tamil-Nadu n_f 3 t_s 5 n_layers 1 8 Error 0.09341887 0.10586586559287571 0.47285162476119724\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.065082 Test loss: 0.2852211\n",
            "Tamil-Nadu n_f 3 t_s 5 n_layers 1 16 Error 0.055491794 0.06012309495258333 0.8299786105649691\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.116371 Test loss: 0.3297951\n",
            "Tamil-Nadu n_f 3 t_s 5 n_layers 1 32 Error 0.031051256 0.03173380966964867 0.9526341537952688\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.317122 Test loss: 0.7094981\n",
            "Tamil-Nadu n_f 3 t_s 7 n_layers 1 1 Error 0.24649794 0.261794862070658 -3.036812210630016\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.192547 Test loss: 0.4795351\n",
            "Tamil-Nadu n_f 3 t_s 7 n_layers 1 8 Error 0.06928264 0.08295228166541321 0.59470339492588\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.119331 Test loss: 0.3347871\n",
            "Tamil-Nadu n_f 3 t_s 7 n_layers 1 16 Error 0.012679829 0.013772062016646745 0.9888284293043378\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.134767 Test loss: 0.5583491\n",
            "Tamil-Nadu n_f 3 t_s 7 n_layers 1 32 Error 0.021135299 0.02525053902413046 0.9624458786490452\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.155383 Test loss: 0.3974501\n",
            "Tamil-Nadu n_f 4 t_s 5 n_layers 1 1 Error 0.6633269 0.6787816731209396 -20.671111002649774\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.117693 Test loss: 0.5313801\n",
            "Tamil-Nadu n_f 4 t_s 5 n_layers 1 8 Error 0.09386023 0.11014902466554513 0.4293336527221805\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.066659 Test loss: 0.3297961\n",
            "Tamil-Nadu n_f 4 t_s 5 n_layers 1 16 Error 0.026757907 0.031226192845761364 0.9541373647823972\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.068789 Test loss: 0.3418191\n",
            "Tamil-Nadu n_f 4 t_s 5 n_layers 1 32 Error 0.043559518 0.05781556383919609 0.8427790342353173\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.393516 Test loss: 0.8102151\n",
            "Tamil-Nadu n_f 4 t_s 7 n_layers 1 1 Error 0.13516372 0.15668801068967197 -0.44606487060439903\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.081942 Test loss: 0.3760841\n",
            "Tamil-Nadu n_f 4 t_s 7 n_layers 1 8 Error 0.15838853 0.1697840186212285 -0.6978914234258584\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.079715 Test loss: 0.3442021\n",
            "Tamil-Nadu n_f 4 t_s 7 n_layers 1 16 Error 0.07247141 0.086003037409975 0.5643438319902447\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.165096 Test loss: 0.3746441\n",
            "Tamil-Nadu n_f 4 t_s 7 n_layers 1 32 Error 0.0409655 0.04897442596112152 0.85872836357676\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.327694 Test loss: 0.7641051\n",
            "Tamil-Nadu n_f 5 t_s 5 n_layers 1 1 Error 0.6753222 0.6907512989466876 -21.442141825635684\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.157027 Test loss: 0.4264591\n",
            "Tamil-Nadu n_f 5 t_s 5 n_layers 1 8 Error 0.15527274 0.1676241589165252 -0.3215820430172869\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.154640 Test loss: 0.3294631\n",
            "Tamil-Nadu n_f 5 t_s 5 n_layers 1 16 Error 0.06421331 0.07125284960448319 0.7612049092554335\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.103645 Test loss: 0.2796691\n",
            "Tamil-Nadu n_f 5 t_s 5 n_layers 1 32 Error 0.011857664 0.013277520592278635 0.9917080845423585\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.108630 Test loss: 0.4555571\n",
            "Tamil-Nadu n_f 5 t_s 7 n_layers 1 1 Error 0.119299695 0.13967833832431054 -0.1491438239141214\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.101205 Test loss: 0.3926611\n",
            "Tamil-Nadu n_f 5 t_s 7 n_layers 1 8 Error 0.11644603 0.12253478757498856 0.11562776811263842\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.093072 Test loss: 0.3124131\n",
            "Tamil-Nadu n_f 5 t_s 7 n_layers 1 16 Error 0.09159875 0.09725215274700745 0.44292367554877066\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.106131 Test loss: 0.4201111\n",
            "Tamil-Nadu n_f 5 t_s 7 n_layers 1 32 Error 0.082361884 0.0844304856013514 0.580129964864599\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.258922 Test loss: 0.6093831\n",
            "Tamil-Nadu n_f 6 t_s 5 n_layers 1 1 Error 0.63122183 0.6461797728463453 -18.639375301126616\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.136450 Test loss: 0.3327311\n",
            "Tamil-Nadu n_f 6 t_s 5 n_layers 1 8 Error 0.07582097 0.08296336779315865 0.6762619787304329\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.178458 Test loss: 0.4037941\n",
            "Tamil-Nadu n_f 6 t_s 5 n_layers 1 16 Error 0.07864197 0.08434449379502187 0.6653934943527422\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.113598 Test loss: 0.4187161\n",
            "Tamil-Nadu n_f 6 t_s 5 n_layers 1 32 Error 0.057575274 0.06054272560544842 0.827596974999076\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.195569 Test loss: 0.6812681\n",
            "Tamil-Nadu n_f 6 t_s 7 n_layers 1 1 Error 0.10018226 0.11146721182500621 0.2681694524378929\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.139622 Test loss: 0.6398361\n",
            "Tamil-Nadu n_f 6 t_s 7 n_layers 1 8 Error 0.063377336 0.06963403851399079 0.7143991825482028\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.132556 Test loss: 0.3744201\n",
            "Tamil-Nadu n_f 6 t_s 7 n_layers 1 16 Error 0.118310325 0.1252400730357426 0.07614692682249657\n",
            "1\n",
            "Epoch: 0/50  Loss: 0.081842 Test loss: 0.3820301\n",
            "Tamil-Nadu n_f 6 t_s 7 n_layers 1 32 Error 0.10950151 0.11316417530806071 0.24571719825196137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bhbchPkgjo2F",
        "outputId": "0f7f9e22-dcdb-4264-c7ee-e5260f730909"
      },
      "source": [
        "df_lstm = pd.DataFrame (results_lstm,columns=['State','Number_feature','Time_Step','number_layers','number_hiddinen_nodes','MAE','RMSE','R2_Score'])\n",
        "df_lstm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Number_feature</th>\n",
              "      <th>Time_Step</th>\n",
              "      <th>number_layers</th>\n",
              "      <th>number_hiddinen_nodes</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.465850</td>\n",
              "      <td>0.480920</td>\n",
              "      <td>-11.348774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.329354</td>\n",
              "      <td>0.335243</td>\n",
              "      <td>-5.000644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0.279258</td>\n",
              "      <td>0.283908</td>\n",
              "      <td>-3.303615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0.109165</td>\n",
              "      <td>0.111604</td>\n",
              "      <td>0.334979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.718372</td>\n",
              "      <td>0.726073</td>\n",
              "      <td>-43.291424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       State  Number_feature  Time_Step  ...       MAE      RMSE   R2_Score\n",
              "0  Karnataka               1          5  ...  0.465850  0.480920 -11.348774\n",
              "1  Karnataka               1          5  ...  0.329354  0.335243  -5.000644\n",
              "2  Karnataka               1          5  ...  0.279258  0.283908  -3.303615\n",
              "3  Karnataka               1          5  ...  0.109165  0.111604   0.334979\n",
              "4  Karnataka               1          7  ...  0.718372  0.726073 -43.291424\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZudyJNfJiEv",
        "outputId": "5a77a518-11b1-46e9-d48a-913c5676ebea"
      },
      "source": [
        "#github_upload(folder_name='Indian-States-Model-Results',file_name='LSTM_on_short_data.csv', file_data=df_lstm.to_csv())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indian-States-Model-Results/LSTM_on_short_data.csv CREATED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j46DqqGJNh2i"
      },
      "source": [
        "class GRUNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
        "        super(GRUNet, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        weight = next(self.parameters()).data\n",
        "        h = weight.new(self.n_layers, x.size(0), self.hidden_dim).zero_()\n",
        "        out, h = self.gru(x, h)\n",
        "        out = self.fc(self.relu(out[:,-1]))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Tx_dpOxdWh",
        "outputId": "7e025a23-ffd3-4130-e013-8daf09f23734"
      },
      "source": [
        "Shortlisted_States=['Karnataka','Maharashtra','Uttar-Pradesh','Kerala','Tamil-Nadu']\n",
        "results_gru=[]\n",
        "for state in Shortlisted_States:\n",
        "  best_models=[]\n",
        "  df=pd.read_csv(\"https://raw.githubusercontent.com/sureshkuc/Data-Science-in-Life-Science-Project/main/Indian-States-Covid19-Datasets/\"+state+\".csv\", parse_dates=[\"Date\"]).drop(columns =[\"Unnamed: 0\"])\n",
        "  df_temp1 = df[df[\"Date\"] <= \"2020-06-18\"]\n",
        "  df_temp2=  df[df[\"Date\"] > \"2020-03-09\"]\n",
        "  df = pd.merge(df_temp1, df_temp2, how='inner')\n",
        "  df = df.set_index(\"Date\")\n",
        "  df = df[['Confirmed', 'Recovered', 'Deceased', 'New_Confirmerd', 'New_Deaths', 'New_Recovered']]\n",
        "  #print(df.describe())\n",
        "\n",
        "  time_step=[5,7]\n",
        "  Number_of_feature=[1,2,3,4,5,6]\n",
        "  multi_feature=True\n",
        "  output_dim=1\n",
        "  for n_f in Number_of_feature:\n",
        "    for t_s in time_step:\n",
        "      train_loader, test_loader,scaler = data_preparation(df, scaling_range=(0,1),time_step=t_s,number_feature=n_f, response_variable_index=0,data_split_ratio=0.8, Suffle=False)\n",
        "      for n_layers in range(1,3,1):\n",
        "        for n_hidden_nodes in [1,5,8,16,32]:\n",
        "          \n",
        "          max_epochs=10\n",
        "          random.seed(42)\n",
        "          torch.manual_seed(42)\n",
        "          np.random.seed(42)\n",
        "          #CNN model with L1 loss\n",
        "          #best_model=Call_CNN_model(state,dataset=(train_loader, test_loader), lr=1e-2,criterion=nn.L1Loss(),max_epochs=max_epochs)\n",
        "          GRUNet_model = GRUNet(n_f, n_hidden_nodes, output_dim, n_layers)\n",
        "          #if torch.cuda.is_available():\n",
        "          #stm_model = lstm_model.cuda()\n",
        "          #gru_optim = optim.SGD(GRUNet_model.parameters(), lr=1e-3, momentum=0.9)\n",
        "          gru_optim = optim.Adam(GRUNet_model.parameters(), lr=1e-2)\n",
        "          train_losses,test_losses,best_model = fit(GRUNet_model, gru_optim,nn.L1Loss(),(train_loader, test_loader), max_epochs=max_epochs,cuda=False)\n",
        "          #print(f'\\nTraining took {end-start}s!')\n",
        "          #plot_loss(max_epochs,train_losses,test_losses,model_name='CNN for '+state)\n",
        "          GRUNet_model = GRUNet(n_f, n_hidden_nodes, output_dim, n_layers)\n",
        "          GRUNet_model.load_state_dict(best_model)\n",
        "          GRUNet_model.eval()\n",
        "          test_x,test_y=test_loader\n",
        "          predictions=GRUNet_model(test_x)\n",
        "          test_y=test_y.cpu().detach().numpy()\n",
        "          predictions=predictions.cpu().detach().numpy()\n",
        "          mae=mean_absolute_error(test_y,predictions)\n",
        "          rmse=math.sqrt(mean_squared_error(test_y,predictions))\n",
        "          #mape=mean_absolute_percentage_error(test_y,predictions)\n",
        "          r2s=r2_score(test_y,predictions)\n",
        "          results_gru.append([state,n_f,t_s,n_layers,n_hidden_nodes,mae,rmse,r2s])\n",
        "          print(state,'n_f',n_f,'t_s',t_s,'n_layers',n_layers,n_hidden_nodes,'Error',mae,rmse,r2s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.350546 Test loss: 0.268804Karnataka n_f 1 t_s 5 n_layers 1 1 Error 0.7706389 0.784844825435557 -31.888698213431567\n",
            "Epoch: 0/10  Loss: 0.351519 Test loss: 1.018753Karnataka n_f 1 t_s 5 n_layers 1 5 Error 0.6762188 0.6900670071559967 -24.425038855365866\n",
            "Epoch: 0/10  Loss: 0.179443 Test loss: 0.388706Karnataka n_f 1 t_s 5 n_layers 1 8 Error 0.61530405 0.6286460859608453 -20.100441614368293\n",
            "Epoch: 0/10  Loss: 0.066907 Test loss: 0.242868Karnataka n_f 1 t_s 5 n_layers 1 16 Error 0.48299846 0.49171791685098637 -11.909551724683348\n",
            "Epoch: 0/10  Loss: 0.067334 Test loss: 0.396526Karnataka n_f 1 t_s 5 n_layers 1 32 Error 0.037934486 0.04169371901432225 0.9071845266941638\n",
            "Epoch: 0/10  Loss: 0.543205 Test loss: 1.391785Karnataka n_f 1 t_s 5 n_layers 2 1 Error 0.7217745 0.7346344347522065 -27.815200145001874\n",
            "Epoch: 0/10  Loss: 0.267883 Test loss: 0.208029Karnataka n_f 1 t_s 5 n_layers 2 5 Error 0.7212464 0.7341154735641432 -27.774507441872075\n",
            "Epoch: 0/10  Loss: 0.132502 Test loss: 0.542866Karnataka n_f 1 t_s 5 n_layers 2 8 Error 0.60064733 0.6139224157149195 -19.1236199058051\n",
            "Epoch: 0/10  Loss: 0.119886 Test loss: 0.308497Karnataka n_f 1 t_s 5 n_layers 2 16 Error 0.49915388 0.5095048434688966 -12.86039839294013\n",
            "Epoch: 0/10  Loss: 0.083587 Test loss: 0.380735Karnataka n_f 1 t_s 5 n_layers 2 32 Error 0.50154024 0.5106009293465948 -12.92009700708022\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.404892 Test loss: 0.247721Karnataka n_f 1 t_s 7 n_layers 1 1 Error 0.81537694 0.8243178900081792 -56.08846621146869\n",
            "Epoch: 0/10  Loss: 0.364051 Test loss: 1.089156Karnataka n_f 1 t_s 7 n_layers 1 5 Error 0.7060781 0.7144570477243963 -41.88556379179553\n",
            "Epoch: 0/10  Loss: 0.185636 Test loss: 0.432284Karnataka n_f 1 t_s 7 n_layers 1 8 Error 0.6499796 0.6585559521889294 -35.43713716544271\n",
            "Epoch: 0/10  Loss: 0.077700 Test loss: 0.253063Karnataka n_f 1 t_s 7 n_layers 1 16 Error 0.45366082 0.4586314366206852 -16.672033874062954\n",
            "Epoch: 0/10  Loss: 0.087746 Test loss: 0.518159Karnataka n_f 1 t_s 7 n_layers 1 32 Error 0.14622316 0.1486876099739614 -0.8574128470248665\n",
            "Epoch: 0/10  Loss: 0.581720 Test loss: 1.470388Karnataka n_f 1 t_s 7 n_layers 2 1 Error 0.75767773 0.7654921358004807 -48.231191416764204\n",
            "Epoch: 0/10  Loss: 0.264326 Test loss: 0.233228Karnataka n_f 1 t_s 7 n_layers 2 5 Error 0.7476884 0.7556061234179108 -46.967802914723244\n",
            "Epoch: 0/10  Loss: 0.089818 Test loss: 0.366684Karnataka n_f 1 t_s 7 n_layers 2 8 Error 0.5717795 0.5790777346258535 -27.172970297671355\n",
            "Epoch: 0/10  Loss: 0.125153 Test loss: 0.320715Karnataka n_f 1 t_s 7 n_layers 2 16 Error 0.5369188 0.5427623328973806 -23.750175840035553\n",
            "Epoch: 0/10  Loss: 0.100340 Test loss: 0.470239Karnataka n_f 1 t_s 7 n_layers 2 32 Error 0.55315787 0.5586504874058387 -25.220396455974306\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.591574 Test loss: 0.035388Karnataka n_f 2 t_s 5 n_layers 1 1 Error 0.71637917 0.7285010615061591 -27.336058470040538\n",
            "Epoch: 0/10  Loss: 0.102098 Test loss: 0.588017Karnataka n_f 2 t_s 5 n_layers 1 5 Error 0.6223738 0.6368394280963733 -20.65404213132734\n",
            "Epoch: 0/10  Loss: 0.278232 Test loss: 0.638016Karnataka n_f 2 t_s 5 n_layers 1 8 Error 0.45316136 0.46147339590331043 -10.370313126940198\n",
            "Epoch: 0/10  Loss: 0.090194 Test loss: 0.502854Karnataka n_f 2 t_s 5 n_layers 1 16 Error 0.35120484 0.35525319616905426 -5.738373703747272\n",
            "Epoch: 0/10  Loss: 0.083535 Test loss: 0.345901Karnataka n_f 2 t_s 5 n_layers 1 32 Error 0.10231521 0.10382939863177258 0.4244013611778894\n",
            "Epoch: 0/10  Loss: 0.271033 Test loss: 0.765031Karnataka n_f 2 t_s 5 n_layers 2 1 Error 0.7134064 0.7264027984005427 -27.173067486235244\n",
            "Epoch: 0/10  Loss: 0.324786 Test loss: 0.708221Karnataka n_f 2 t_s 5 n_layers 2 5 Error 0.658718 0.6700970612508038 -22.974775526630893\n",
            "Epoch: 0/10  Loss: 0.260695 Test loss: 0.540740Karnataka n_f 2 t_s 5 n_layers 2 8 Error 0.5233127 0.5331080425289068 -14.17433217581856\n",
            "Epoch: 0/10  Loss: 0.143244 Test loss: 0.581436Karnataka n_f 2 t_s 5 n_layers 2 16 Error 0.22421485 0.23379893238263996 -1.9185297044494387\n",
            "Epoch: 0/10  Loss: 0.095829 Test loss: 0.370717Karnataka n_f 2 t_s 5 n_layers 2 32 Error 0.047420938 0.0567830367198229 0.827846331429417\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.567251 Test loss: 0.045680Karnataka n_f 2 t_s 7 n_layers 1 1 Error 0.74937475 0.7569070499605406 -47.13311756566235\n",
            "Epoch: 0/10  Loss: 0.111129 Test loss: 0.635490Karnataka n_f 2 t_s 7 n_layers 1 5 Error 0.6523724 0.6613903811736692 -35.75146252551648\n",
            "Epoch: 0/10  Loss: 0.290415 Test loss: 0.686984Karnataka n_f 2 t_s 7 n_layers 1 8 Error 0.44349432 0.44891089795817013 -15.930867032106434\n",
            "Epoch: 0/10  Loss: 0.097484 Test loss: 0.523299Karnataka n_f 2 t_s 7 n_layers 1 16 Error 0.1453639 0.14639122226294798 -0.800482675861419\n",
            "Epoch: 0/10  Loss: 0.043459 Test loss: 0.227474Karnataka n_f 2 t_s 7 n_layers 1 32 Error 0.042932626 0.04908574806345611 0.7975723968759857\n",
            "Epoch: 0/10  Loss: 0.288837 Test loss: 0.827769Karnataka n_f 2 t_s 7 n_layers 2 1 Error 0.74973 0.7576198923014 -47.22382641896677\n",
            "Epoch: 0/10  Loss: 0.326611 Test loss: 0.705577Karnataka n_f 2 t_s 7 n_layers 2 5 Error 0.66596866 0.6728819908049644 -37.039664798785935\n",
            "Epoch: 0/10  Loss: 0.272196 Test loss: 0.578508Karnataka n_f 2 t_s 7 n_layers 2 8 Error 0.44478548 0.44920067128830204 -15.952730589175566\n",
            "Epoch: 0/10  Loss: 0.150512 Test loss: 0.576451Karnataka n_f 2 t_s 7 n_layers 2 16 Error 0.09652814 0.10436355837909993 0.08492508145774635\n",
            "Epoch: 0/10  Loss: 0.072133 Test loss: 0.316299Karnataka n_f 2 t_s 7 n_layers 2 32 Error 0.34747234 0.3548607079818204 -9.57973309507324\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.111177 Test loss: 0.570762Karnataka n_f 3 t_s 5 n_layers 1 1 Error 0.621004 0.6324209485391825 -20.35460536331969\n",
            "Epoch: 0/10  Loss: 0.484381 Test loss: 0.802692Karnataka n_f 3 t_s 5 n_layers 1 5 Error 0.31184253 0.3181945514530768 -4.405856888832586\n",
            "Epoch: 0/10  Loss: 0.252096 Test loss: 0.500276Karnataka n_f 3 t_s 5 n_layers 1 8 Error 0.35709602 0.36212698802066523 -6.001658237845074\n",
            "Epoch: 0/10  Loss: 0.108293 Test loss: 0.536999Karnataka n_f 3 t_s 5 n_layers 1 16 Error 0.3759894 0.389406497195733 -7.09627930186762\n",
            "Epoch: 0/10  Loss: 0.104087 Test loss: 0.253899Karnataka n_f 3 t_s 5 n_layers 1 32 Error 0.2097817 0.21234624713835704 -1.4075112013241422\n",
            "Epoch: 0/10  Loss: 0.925421 Test loss: 2.453054Karnataka n_f 3 t_s 5 n_layers 2 1 Error 1.1102328 1.1186358260388443 -65.81231349313066\n",
            "Epoch: 0/10  Loss: 0.367889 Test loss: 0.806807Karnataka n_f 3 t_s 5 n_layers 2 5 Error 0.63356185 0.6457114309710177 -21.26158217351468\n",
            "Epoch: 0/10  Loss: 0.175655 Test loss: 0.379622Karnataka n_f 3 t_s 5 n_layers 2 8 Error 0.5129368 0.5258460924542193 -13.763741899549688\n",
            "Epoch: 0/10  Loss: 0.072222 Test loss: 0.373213Karnataka n_f 3 t_s 5 n_layers 2 16 Error 0.38653013 0.39930247867707197 -7.513009418572555\n",
            "Epoch: 0/10  Loss: 0.077404 Test loss: 0.288878Karnataka n_f 3 t_s 5 n_layers 2 32 Error 0.07995146 0.09215649208581637 0.5465483404207665\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.116739 Test loss: 0.596557Karnataka n_f 3 t_s 7 n_layers 1 1 Error 0.64857125 0.6553702588474649 -35.08547096353286\n",
            "Epoch: 0/10  Loss: 0.496017 Test loss: 0.837992Karnataka n_f 3 t_s 7 n_layers 1 5 Error 0.2960131 0.29946932845610624 -6.534658331301309\n",
            "Epoch: 0/10  Loss: 0.259358 Test loss: 0.513608Karnataka n_f 3 t_s 7 n_layers 1 8 Error 0.33910507 0.34109828947701365 -8.77502696062372\n",
            "Epoch: 0/10  Loss: 0.121432 Test loss: 0.576173Karnataka n_f 3 t_s 7 n_layers 1 16 Error 0.40129858 0.41018249791036626 -13.135564828770946\n",
            "Epoch: 0/10  Loss: 0.106910 Test loss: 0.228814Karnataka n_f 3 t_s 7 n_layers 1 32 Error 0.22562447 0.22621946015439504 -3.2995088096947454\n",
            "Epoch: 0/10  Loss: 0.938598 Test loss: 2.559551Karnataka n_f 3 t_s 7 n_layers 2 1 Error 1.146136 1.151316763798581 -110.36495720008354\n",
            "Epoch: 0/10  Loss: 0.386214 Test loss: 0.868747Karnataka n_f 3 t_s 7 n_layers 2 5 Error 0.6550316 0.6621675043836099 -35.83788150645457\n",
            "Epoch: 0/10  Loss: 0.172961 Test loss: 0.383744Karnataka n_f 3 t_s 7 n_layers 2 8 Error 0.5039454 0.5109625317335919 -20.934966408194345\n",
            "Epoch: 0/10  Loss: 0.083812 Test loss: 0.397033Karnataka n_f 3 t_s 7 n_layers 2 16 Error 0.39928743 0.407037723218877 -12.91964743238205\n",
            "Epoch: 0/10  Loss: 0.094951 Test loss: 0.283407Karnataka n_f 3 t_s 7 n_layers 2 32 Error 0.046448648 0.050266768288053786 0.787714257199184\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.490737 Test loss: 1.326031Karnataka n_f 4 t_s 5 n_layers 1 1 Error 0.68455714 0.6981032653471574 -25.02066949269848\n",
            "Epoch: 0/10  Loss: 0.208292 Test loss: 0.698695Karnataka n_f 4 t_s 5 n_layers 1 5 Error 0.42688578 0.4410538405965273 -9.38633414102148\n",
            "Epoch: 0/10  Loss: 0.367573 Test loss: 0.881046Karnataka n_f 4 t_s 5 n_layers 1 8 Error 0.54454327 0.559597660481564 -15.719792057748627\n",
            "Epoch: 0/10  Loss: 0.041967 Test loss: 0.226955Karnataka n_f 4 t_s 5 n_layers 1 16 Error 0.167928 0.1774870650521392 -0.6819476203716752\n",
            "Epoch: 0/10  Loss: 0.070792 Test loss: 0.154047Karnataka n_f 4 t_s 5 n_layers 1 32 Error 0.15969585 0.17042472033854747 -0.5507588880720444\n",
            "Epoch: 0/10  Loss: 0.400657 Test loss: 1.090925Karnataka n_f 4 t_s 5 n_layers 2 1 Error 0.6739123 0.6876678912029683 -24.248558442027104\n",
            "Epoch: 0/10  Loss: 0.097356 Test loss: 0.489039Karnataka n_f 4 t_s 5 n_layers 2 5 Error 0.70307714 0.7159623529457196 -26.369034728472073\n",
            "Epoch: 0/10  Loss: 0.300950 Test loss: 0.706648Karnataka n_f 4 t_s 5 n_layers 2 8 Error 0.47710654 0.4912271667590325 -11.883795397048154\n",
            "Epoch: 0/10  Loss: 0.093405 Test loss: 0.309336Karnataka n_f 4 t_s 5 n_layers 2 16 Error 0.20916411 0.22572371168781877 -1.7204043347179572\n",
            "Epoch: 0/10  Loss: 0.109706 Test loss: 0.339895Karnataka n_f 4 t_s 5 n_layers 2 32 Error 0.240447 0.25503542777866184 -2.4728030937128453\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.505882 Test loss: 1.413678Karnataka n_f 4 t_s 7 n_layers 1 1 Error 0.71939754 0.7276343776044197 -43.48210779182465\n",
            "Epoch: 0/10  Loss: 0.217382 Test loss: 0.750376Karnataka n_f 4 t_s 7 n_layers 1 5 Error 0.461961 0.4707364114095661 -17.617205352756315\n",
            "Epoch: 0/10  Loss: 0.380428 Test loss: 0.936521Karnataka n_f 4 t_s 7 n_layers 1 8 Error 0.5706384 0.5797757217850148 -27.240930674111958\n",
            "Epoch: 0/10  Loss: 0.047989 Test loss: 0.238296Karnataka n_f 4 t_s 7 n_layers 1 16 Error 0.09611999 0.10342288361308402 0.10134659831873893\n",
            "Epoch: 0/10  Loss: 0.077508 Test loss: 0.208115Karnataka n_f 4 t_s 7 n_layers 1 32 Error 0.15367654 0.15815851383175647 -1.1015710504841567\n",
            "Epoch: 0/10  Loss: 0.413834 Test loss: 1.159740Karnataka n_f 4 t_s 7 n_layers 2 1 Error 0.7057688 0.7141513911037601 -41.84887693737112\n",
            "Epoch: 0/10  Loss: 0.104749 Test loss: 0.518703Karnataka n_f 4 t_s 7 n_layers 2 5 Error 0.7318712 0.7399580950728472 -45.001622841332605\n",
            "Epoch: 0/10  Loss: 0.328995 Test loss: 0.828387Karnataka n_f 4 t_s 7 n_layers 2 8 Error 0.44215724 0.45181322957701725 -16.15050000341955\n",
            "Epoch: 0/10  Loss: 0.105523 Test loss: 0.327080Karnataka n_f 4 t_s 7 n_layers 2 16 Error 0.1800254 0.18939935766763738 -2.0138100172825943\n",
            "Epoch: 0/10  Loss: 0.120324 Test loss: 0.292674Karnataka n_f 4 t_s 7 n_layers 2 32 Error 0.25043705 0.25920293570043684 -4.644672449982035\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.608438 Test loss: 2.931150Karnataka n_f 5 t_s 5 n_layers 1 1 Error 0.86394674 0.890458074620507 -41.33563505717792\n",
            "Epoch: 0/10  Loss: 0.175562 Test loss: 0.258692Karnataka n_f 5 t_s 5 n_layers 1 5 Error 0.2185495 0.2324465890775687 -1.8848643392945785\n",
            "Epoch: 0/10  Loss: 0.408366 Test loss: 0.992428Karnataka n_f 5 t_s 5 n_layers 1 8 Error 0.49192268 0.5054866934986058 -12.642643421735732\n",
            "Epoch: 0/10  Loss: 0.090756 Test loss: 0.220004Karnataka n_f 5 t_s 5 n_layers 1 16 Error 0.28203768 0.2958585756350009 -3.6735557378400205\n",
            "Epoch: 0/10  Loss: 0.125114 Test loss: 0.453058Karnataka n_f 5 t_s 5 n_layers 1 32 Error 0.32037127 0.3326440989549313 -4.907976561585767\n",
            "Epoch: 0/10  Loss: 0.776294 Test loss: 0.021554Karnataka n_f 5 t_s 5 n_layers 2 1 Error 0.63935786 0.653324554840136 -21.789618740881092\n",
            "Epoch: 0/10  Loss: 0.098242 Test loss: 0.545715Karnataka n_f 5 t_s 5 n_layers 2 5 Error 0.4579287 0.4724951540481487 -10.919932672827057\n",
            "Epoch: 0/10  Loss: 0.178901 Test loss: 0.618256Karnataka n_f 5 t_s 5 n_layers 2 8 Error 0.5343257 0.5501344007223221 -15.159082782269024\n",
            "Epoch: 0/10  Loss: 0.229234 Test loss: 0.483423Karnataka n_f 5 t_s 5 n_layers 2 16 Error 0.3005187 0.31245090575817164 -4.212459214801062\n",
            "Epoch: 0/10  Loss: 0.086113 Test loss: 0.081661Karnataka n_f 5 t_s 5 n_layers 2 32 Error 0.49903902 0.5119838173681883 -12.995601145541604\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.635513 Test loss: 3.220429Karnataka n_f 5 t_s 7 n_layers 1 1 Error 0.90533835 0.9235163801813132 -70.65527203440452\n",
            "Epoch: 0/10  Loss: 0.177201 Test loss: 0.275159Karnataka n_f 5 t_s 7 n_layers 1 5 Error 0.24582213 0.25387646427042176 -4.415066483622868\n",
            "Epoch: 0/10  Loss: 0.424855 Test loss: 1.055542Karnataka n_f 5 t_s 7 n_layers 1 8 Error 0.52343696 0.5314593744012298 -22.7300725811735\n",
            "Epoch: 0/10  Loss: 0.077567 Test loss: 0.153537Karnataka n_f 5 t_s 7 n_layers 1 16 Error 0.25232846 0.26059225679448506 -4.705344949990741\n",
            "Epoch: 0/10  Loss: 0.139840 Test loss: 0.501603Karnataka n_f 5 t_s 7 n_layers 1 32 Error 0.30216706 0.30987839155506997 -7.067546385468885\n",
            "Epoch: 0/10  Loss: 0.762731 Test loss: 0.012265Karnataka n_f 5 t_s 7 n_layers 2 1 Error 0.6563858 0.6649873240058684 -36.15229584964842\n",
            "Epoch: 0/10  Loss: 0.111032 Test loss: 0.598194Karnataka n_f 5 t_s 7 n_layers 2 5 Error 0.6846085 0.6940355684018168 -39.46898775941656\n",
            "Epoch: 0/10  Loss: 0.193642 Test loss: 0.649147Karnataka n_f 5 t_s 7 n_layers 2 8 Error 0.5760352 0.5849898240435183 -27.751170574105466\n",
            "Epoch: 0/10  Loss: 0.236896 Test loss: 0.544930Karnataka n_f 5 t_s 7 n_layers 2 16 Error 0.29932782 0.30493919051683577 -6.812416420056023\n",
            "Epoch: 0/10  Loss: 0.103601 Test loss: 0.249747Karnataka n_f 5 t_s 7 n_layers 2 32 Error 0.30862254 0.32121397723754774 -7.6685756352662615\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.310166 Test loss: 1.100604Karnataka n_f 6 t_s 5 n_layers 1 1 Error 0.65842026 0.6774090472539908 -23.50084625242262\n",
            "Epoch: 0/10  Loss: 0.407221 Test loss: 1.012698Karnataka n_f 6 t_s 5 n_layers 1 5 Error 0.66982585 0.6824734909023605 -23.868560040403636\n",
            "Epoch: 0/10  Loss: 0.222764 Test loss: 0.464134Karnataka n_f 6 t_s 5 n_layers 1 8 Error 0.5446127 0.5604553945506543 -15.77108679595592\n",
            "Epoch: 0/10  Loss: 0.078689 Test loss: 0.166106Karnataka n_f 6 t_s 5 n_layers 1 16 Error 0.32107076 0.3318431882644269 -4.879561059682798\n",
            "Epoch: 0/10  Loss: 0.067679 Test loss: 0.247481Karnataka n_f 6 t_s 5 n_layers 1 32 Error 0.044010937 0.052676334494888045 0.8518471019725409\n",
            "Epoch: 0/10  Loss: 0.128615 Test loss: 0.339415Karnataka n_f 6 t_s 5 n_layers 2 1 Error 0.55200297 0.5687148565396678 -16.26904134087822\n",
            "Epoch: 0/10  Loss: 0.136296 Test loss: 0.523749Karnataka n_f 6 t_s 5 n_layers 2 5 Error 0.29065928 0.312934370947497 -4.228602325591272\n",
            "Epoch: 0/10  Loss: 0.137408 Test loss: 0.684520Karnataka n_f 6 t_s 5 n_layers 2 8 Error 0.43991002 0.4550589528772702 -10.05641642009835\n",
            "Epoch: 0/10  Loss: 0.053875 Test loss: 0.218953Karnataka n_f 6 t_s 5 n_layers 2 16 Error 0.30294445 0.3184669406522422 -4.415115910889225\n",
            "Epoch: 0/10  Loss: 0.087779 Test loss: 0.341532Karnataka n_f 6 t_s 5 n_layers 2 32 Error 0.15056466 0.16820596976915436 -0.5106433269431296\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.327450 Test loss: 1.201985Karnataka n_f 6 t_s 7 n_layers 1 1 Error 0.70697176 0.7203277189090977 -42.593239226728606\n",
            "Epoch: 0/10  Loss: 0.417216 Test loss: 1.067674Karnataka n_f 6 t_s 7 n_layers 1 5 Error 0.6788522 0.6866790464899422 -38.615623074018835\n",
            "Epoch: 0/10  Loss: 0.229682 Test loss: 0.508458Karnataka n_f 6 t_s 7 n_layers 1 8 Error 0.58620113 0.5957785386674855 -28.82144259310282\n",
            "Epoch: 0/10  Loss: 0.083771 Test loss: 0.170219Karnataka n_f 6 t_s 7 n_layers 1 16 Error 0.33736727 0.3448378731728519 -8.9905360121264\n",
            "Epoch: 0/10  Loss: 0.081954 Test loss: 0.335786Karnataka n_f 6 t_s 7 n_layers 1 32 Error 0.2154278 0.2199222456283563 -3.063471489623123\n",
            "Epoch: 0/10  Loss: 0.129780 Test loss: 0.363005Karnataka n_f 6 t_s 7 n_layers 2 1 Error 0.58254176 0.5926698345917453 -28.511041542707318\n",
            "Epoch: 0/10  Loss: 0.147595 Test loss: 0.560242Karnataka n_f 6 t_s 7 n_layers 2 5 Error 0.32399586 0.33683549268910595 -8.532231281096053\n",
            "Epoch: 0/10  Loss: 0.146092 Test loss: 0.737484Karnataka n_f 6 t_s 7 n_layers 2 8 Error 0.6639501 0.673461836620753 -37.10525595150372\n",
            "Epoch: 0/10  Loss: 0.063704 Test loss: 0.236082Karnataka n_f 6 t_s 7 n_layers 2 16 Error 0.16461729 0.17780290058149378 -1.656052088994981\n",
            "Epoch: 0/10  Loss: 0.107938 Test loss: 0.389724Karnataka n_f 6 t_s 7 n_layers 2 32 Error 0.31176043 0.3158932400536837 -7.383773230072659\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.340995 Test loss: 0.290262Maharashtra n_f 1 t_s 5 n_layers 1 1 Error 0.8002741 0.8084700853809256 -54.35675888522464\n",
            "Epoch: 0/10  Loss: 0.395942 Test loss: 1.074260Maharashtra n_f 1 t_s 5 n_layers 1 5 Error 0.6960821 0.704783222100161 -41.06819210279524\n",
            "Epoch: 0/10  Loss: 0.203371 Test loss: 0.393545Maharashtra n_f 1 t_s 5 n_layers 1 8 Error 0.54327106 0.55227326478907 -24.83156926360611\n",
            "Epoch: 0/10  Loss: 0.103479 Test loss: 0.251391Maharashtra n_f 1 t_s 5 n_layers 1 16 Error 0.36200902 0.36710732173081634 -10.413762441780575\n",
            "Epoch: 0/10  Loss: 0.165822 Test loss: 0.502600Maharashtra n_f 1 t_s 5 n_layers 1 32 Error 0.21624893 0.21642496668443117 -2.966956529157441\n",
            "Epoch: 0/10  Loss: 0.585792 Test loss: 1.453503Maharashtra n_f 1 t_s 5 n_layers 2 1 Error 0.75070614 0.7585295990868698 -47.729036096057484\n",
            "Epoch: 0/10  Loss: 0.262429 Test loss: 0.224459Maharashtra n_f 1 t_s 5 n_layers 2 5 Error 0.7009325 0.7093051993693237 -41.60975246262064\n",
            "Epoch: 0/10  Loss: 0.195792 Test loss: 0.660410Maharashtra n_f 1 t_s 5 n_layers 2 8 Error 0.6145903 0.6225220912629015 -31.82103590538484\n",
            "Epoch: 0/10  Loss: 0.161131 Test loss: 0.331357Maharashtra n_f 1 t_s 5 n_layers 2 16 Error 0.050966904 0.05914135390126031 0.7037725900644873\n",
            "Epoch: 0/10  Loss: 0.113927 Test loss: 0.301394Maharashtra n_f 1 t_s 5 n_layers 2 32 Error 0.27622753 0.27788702717131214 -5.540023747435688\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.386454 Test loss: 0.261165Maharashtra n_f 1 t_s 7 n_layers 1 1 Error 0.819872 0.8262580483949212 -72.69685434317931\n",
            "Epoch: 0/10  Loss: 0.410676 Test loss: 1.121514Maharashtra n_f 1 t_s 7 n_layers 1 5 Error 0.711743 0.7182212626294546 -54.684463536573105\n",
            "Epoch: 0/10  Loss: 0.209887 Test loss: 0.408333Maharashtra n_f 1 t_s 7 n_layers 1 8 Error 0.52875745 0.537445961653251 -30.18078971983675\n",
            "Epoch: 0/10  Loss: 0.118171 Test loss: 0.263305Maharashtra n_f 1 t_s 7 n_layers 1 16 Error 0.31996495 0.32374454197277946 -10.314163926992084\n",
            "Epoch: 0/10  Loss: 0.127339 Test loss: 0.471441Maharashtra n_f 1 t_s 7 n_layers 1 32 Error 0.077839926 0.0811689760307275 0.28879031683950906\n",
            "Epoch: 0/10  Loss: 0.627117 Test loss: 1.509288Maharashtra n_f 1 t_s 7 n_layers 2 1 Error 0.77475494 0.7807104536430396 -64.79570115858718\n",
            "Epoch: 0/10  Loss: 0.261520 Test loss: 0.243816Maharashtra n_f 1 t_s 7 n_layers 2 5 Error 0.7077881 0.7143021496516787 -54.07842144388734\n",
            "Epoch: 0/10  Loss: 0.200120 Test loss: 0.624856Maharashtra n_f 1 t_s 7 n_layers 2 8 Error 0.55197495 0.55877663879557 -32.70497596449428\n",
            "Epoch: 0/10  Loss: 0.169053 Test loss: 0.336149Maharashtra n_f 1 t_s 7 n_layers 2 16 Error 0.08470913 0.09934713869024156 -0.06543819346129687\n",
            "Epoch: 0/10  Loss: 0.126855 Test loss: 0.328336Maharashtra n_f 1 t_s 7 n_layers 2 32 Error 0.49564683 0.49720853671124604 -25.686690620065015\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.549103 Test loss: 0.036005Maharashtra n_f 2 t_s 5 n_layers 1 1 Error 0.7386344 0.7452478856642507 -46.03750347815668\n",
            "Epoch: 0/10  Loss: 0.152330 Test loss: 0.648753Maharashtra n_f 2 t_s 5 n_layers 1 5 Error 0.6472544 0.6563122356513436 -35.480750088986255\n",
            "Epoch: 0/10  Loss: 0.316228 Test loss: 0.681245Maharashtra n_f 2 t_s 5 n_layers 1 8 Error 0.27980265 0.28746162915214624 -5.9984598102716085\n",
            "Epoch: 0/10  Loss: 0.137020 Test loss: 0.548281Maharashtra n_f 2 t_s 5 n_layers 1 16 Error 0.09536113 0.10095499904164304 0.13682597651738726\n",
            "Epoch: 0/10  Loss: 0.155869 Test loss: 0.501449Maharashtra n_f 2 t_s 5 n_layers 1 32 Error 0.06866538 0.07829264891887008 0.48085974386542296\n",
            "Epoch: 0/10  Loss: 0.313227 Test loss: 0.808896Maharashtra n_f 2 t_s 5 n_layers 2 1 Error 0.73336834 0.7413583239550059 -45.54779019736249\n",
            "Epoch: 0/10  Loss: 0.364836 Test loss: 0.740551Maharashtra n_f 2 t_s 5 n_layers 2 5 Error 0.5685322 0.5765126917551168 -27.14883781381375\n",
            "Epoch: 0/10  Loss: 0.303251 Test loss: 0.581733Maharashtra n_f 2 t_s 5 n_layers 2 8 Error 0.35002804 0.3573119406142768 -9.812790619227174\n",
            "Epoch: 0/10  Loss: 0.197801 Test loss: 0.649682Maharashtra n_f 2 t_s 5 n_layers 2 16 Error 0.07834746 0.08901104444517147 0.3289875694131096\n",
            "Epoch: 0/10  Loss: 0.181773 Test loss: 0.440760Maharashtra n_f 2 t_s 5 n_layers 2 32 Error 0.14597645 0.15713631071351178 -1.09120122967798\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.522250 Test loss: 0.048769Maharashtra n_f 2 t_s 7 n_layers 1 1 Error 0.7551407 0.7603529202292094 -61.40910822240377\n",
            "Epoch: 0/10  Loss: 0.164072 Test loss: 0.676075Maharashtra n_f 2 t_s 7 n_layers 1 5 Error 0.6665422 0.6733959415295931 -47.95065821723419\n",
            "Epoch: 0/10  Loss: 0.330949 Test loss: 0.716054Maharashtra n_f 2 t_s 7 n_layers 1 8 Error 0.21375163 0.22208481794103221 -4.324211167828531\n",
            "Epoch: 0/10  Loss: 0.147265 Test loss: 0.547141Maharashtra n_f 2 t_s 7 n_layers 1 16 Error 0.09431886 0.09762267012233701 -0.028771469260218785\n",
            "Epoch: 0/10  Loss: 0.186521 Test loss: 0.629052Maharashtra n_f 2 t_s 7 n_layers 1 32 Error 0.093373574 0.1000933297315499 -0.08150306654428552\n",
            "Epoch: 0/10  Loss: 0.333684 Test loss: 0.856417Maharashtra n_f 2 t_s 7 n_layers 2 1 Error 0.7420559 0.7482586752544446 -59.439525741056585\n",
            "Epoch: 0/10  Loss: 0.368904 Test loss: 0.721041Maharashtra n_f 2 t_s 7 n_layers 2 5 Error 0.5783088 0.5845140332559741 -35.88140082451189\n",
            "Epoch: 0/10  Loss: 0.317595 Test loss: 0.607228Maharashtra n_f 2 t_s 7 n_layers 2 8 Error 0.21627606 0.22507934330322868 -4.468759373198913\n",
            "Epoch: 0/10  Loss: 0.210149 Test loss: 0.638026Maharashtra n_f 2 t_s 7 n_layers 2 16 Error 0.12542842 0.1381475313934949 -1.0601733105362765\n",
            "Epoch: 0/10  Loss: 0.129434 Test loss: 0.307128Maharashtra n_f 2 t_s 7 n_layers 2 32 Error 0.1510722 0.17009922068480157 -2.1233612601047605\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.147130 Test loss: 0.620758Maharashtra n_f 3 t_s 5 n_layers 1 1 Error 0.6477642 0.6551638879746997 -35.353199984710876\n",
            "Epoch: 0/10  Loss: 0.523666 Test loss: 0.844861Maharashtra n_f 3 t_s 5 n_layers 1 5 Error 0.16770941 0.17766917783055167 -1.6734182167914113\n",
            "Epoch: 0/10  Loss: 0.297768 Test loss: 0.514486Maharashtra n_f 3 t_s 5 n_layers 1 8 Error 0.11058517 0.12013828278430325 -0.22237822263499152\n",
            "Epoch: 0/10  Loss: 0.157245 Test loss: 0.545875Maharashtra n_f 3 t_s 5 n_layers 1 16 Error 0.3123258 0.3296997678200816 -8.206192010360224\n",
            "Epoch: 0/10  Loss: 0.151877 Test loss: 0.308423Maharashtra n_f 3 t_s 5 n_layers 1 32 Error 0.045785833 0.05231094346442508 0.7682456742389339\n",
            "Epoch: 0/10  Loss: 0.967696 Test loss: 2.537250Maharashtra n_f 3 t_s 5 n_layers 2 1 Error 1.1391643 1.1443352124533674 -109.90451375254713\n",
            "Epoch: 0/10  Loss: 0.407822 Test loss: 0.841049Maharashtra n_f 3 t_s 5 n_layers 2 5 Error 0.63508385 0.6424189083342147 -33.952590406660036\n",
            "Epoch: 0/10  Loss: 0.224783 Test loss: 0.413992Maharashtra n_f 3 t_s 5 n_layers 2 8 Error 0.22596638 0.24211017081667502 -3.9644231104885144\n",
            "Epoch: 0/10  Loss: 0.097934 Test loss: 0.323917Maharashtra n_f 3 t_s 5 n_layers 2 16 Error 0.26548812 0.27858290749084746 -5.5728187429394165\n",
            "Epoch: 0/10  Loss: 0.123641 Test loss: 0.318524Maharashtra n_f 3 t_s 5 n_layers 2 32 Error 0.305624 0.3124724018308147 -7.269249201215192\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.165961 Test loss: 0.689131Maharashtra n_f 3 t_s 7 n_layers 1 1 Error 0.66322356 0.6689126333900264 -47.30102707992366\n",
            "Epoch: 0/10  Loss: 0.536697 Test loss: 0.856793Maharashtra n_f 3 t_s 7 n_layers 1 5 Error 0.17003599 0.17852095631457818 -2.4402971640457403\n",
            "Epoch: 0/10  Loss: 0.306037 Test loss: 0.505650Maharashtra n_f 3 t_s 7 n_layers 1 8 Error 0.09895389 0.10805401770868396 -0.2603737673823312\n",
            "Epoch: 0/10  Loss: 0.173184 Test loss: 0.569417Maharashtra n_f 3 t_s 7 n_layers 1 16 Error 0.31228986 0.3255181185291254 -10.43846860352426\n",
            "Epoch: 0/10  Loss: 0.156101 Test loss: 0.253513Maharashtra n_f 3 t_s 7 n_layers 1 32 Error 0.0396056 0.049012924013058574 0.7406783671359685\n",
            "Epoch: 0/10  Loss: 0.983524 Test loss: 2.611719Maharashtra n_f 3 t_s 7 n_layers 2 1 Error 1.1632133 1.1671883517955446 -146.06162736953894\n",
            "Epoch: 0/10  Loss: 0.428312 Test loss: 0.885824Maharashtra n_f 3 t_s 7 n_layers 2 5 Error 0.62537396 0.6309982713790527 -41.98073693520727\n",
            "Epoch: 0/10  Loss: 0.224531 Test loss: 0.413438Maharashtra n_f 3 t_s 7 n_layers 2 8 Error 0.32446888 0.33525185144085307 -11.132767820828573\n",
            "Epoch: 0/10  Loss: 0.106013 Test loss: 0.337381Maharashtra n_f 3 t_s 7 n_layers 2 16 Error 0.083265275 0.1048739580505044 -0.18727919833261097\n",
            "Epoch: 0/10  Loss: 0.142867 Test loss: 0.297119Maharashtra n_f 3 t_s 7 n_layers 2 32 Error 0.08965078 0.11220512952927725 -0.3590734952132637\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.532340 Test loss: 1.387527Maharashtra n_f 4 t_s 5 n_layers 1 1 Error 0.71574086 0.7239422053088923 -43.38645915543689\n",
            "Epoch: 0/10  Loss: 0.240571 Test loss: 0.761743Maharashtra n_f 4 t_s 5 n_layers 1 5 Error 0.3116117 0.32196598572513047 -7.779357239173425\n",
            "Epoch: 0/10  Loss: 0.406708 Test loss: 0.898727Maharashtra n_f 4 t_s 5 n_layers 1 8 Error 0.48733938 0.4967969281262104 -19.902611798734526\n",
            "Epoch: 0/10  Loss: 0.089400 Test loss: 0.292214Maharashtra n_f 4 t_s 5 n_layers 1 16 Error 0.14153288 0.14911056061662772 -0.8830399612547633\n",
            "Epoch: 0/10  Loss: 0.102848 Test loss: 0.154790Maharashtra n_f 4 t_s 5 n_layers 1 32 Error 0.1713109 0.18154570447677537 -1.7913525083140827\n",
            "Epoch: 0/10  Loss: 0.442933 Test loss: 1.144755Maharashtra n_f 4 t_s 5 n_layers 2 1 Error 0.7031477 0.711494353477714 -41.87317890936478\n",
            "Epoch: 0/10  Loss: 0.146018 Test loss: 0.509852Maharashtra n_f 4 t_s 5 n_layers 2 5 Error 0.73933923 0.7477445066014928 -46.35318454907783\n",
            "Epoch: 0/10  Loss: 0.341857 Test loss: 0.722812Maharashtra n_f 4 t_s 5 n_layers 2 8 Error 0.28252962 0.2939708736623182 -6.3189935836712126\n",
            "Epoch: 0/10  Loss: 0.135030 Test loss: 0.311641Maharashtra n_f 4 t_s 5 n_layers 2 16 Error 0.19048704 0.20116595842864396 -2.4272966461983856\n",
            "Epoch: 0/10  Loss: 0.151003 Test loss: 0.342168Maharashtra n_f 4 t_s 5 n_layers 2 32 Error 0.12509157 0.14777235280303602 -0.8493924974875342\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.550306 Test loss: 1.455661Maharashtra n_f 4 t_s 7 n_layers 1 1 Error 0.73784566 0.7440966495526151 -58.76903156222694\n",
            "Epoch: 0/10  Loss: 0.252405 Test loss: 0.803239Maharashtra n_f 4 t_s 7 n_layers 1 5 Error 0.32334882 0.3316943872051944 -10.87664512487779\n",
            "Epoch: 0/10  Loss: 0.422348 Test loss: 0.934926Maharashtra n_f 4 t_s 7 n_layers 1 8 Error 0.51117074 0.518413661020103 -28.011514114241443\n",
            "Epoch: 0/10  Loss: 0.097125 Test loss: 0.282030Maharashtra n_f 4 t_s 7 n_layers 1 16 Error 0.0843126 0.09580537627513129 0.009174219920670357\n",
            "Epoch: 0/10  Loss: 0.102162 Test loss: 0.121262Maharashtra n_f 4 t_s 7 n_layers 1 32 Error 0.105547346 0.11538060656829402 -0.43708744246728193\n",
            "Epoch: 0/10  Loss: 0.458761 Test loss: 1.193985Maharashtra n_f 4 t_s 7 n_layers 2 1 Error 0.72358 0.7299531555169242 -56.51850046676713\n",
            "Epoch: 0/10  Loss: 0.156979 Test loss: 0.537759Maharashtra n_f 4 t_s 7 n_layers 2 5 Error 0.7497377 0.7558903650835775 -60.6786941410775\n",
            "Epoch: 0/10  Loss: 0.370754 Test loss: 0.823644Maharashtra n_f 4 t_s 7 n_layers 2 8 Error 0.29227895 0.30201890137714044 -8.846589009234679\n",
            "Epoch: 0/10  Loss: 0.148874 Test loss: 0.314395Maharashtra n_f 4 t_s 7 n_layers 2 16 Error 0.12703735 0.1406140256944083 -1.1343952863569227\n",
            "Epoch: 0/10  Loss: 0.158866 Test loss: 0.282002Maharashtra n_f 4 t_s 7 n_layers 2 32 Error 0.20038989 0.2148251958984881 -3.981819076757052\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.675719 Test loss: 3.029549Maharashtra n_f 5 t_s 5 n_layers 1 1 Error 0.8472914 0.8604079887254247 -61.6976972900318\n",
            "Epoch: 0/10  Loss: 0.191803 Test loss: 0.251339Maharashtra n_f 5 t_s 5 n_layers 1 5 Error 0.0911565 0.11096545592510586 -0.042841478670203825\n",
            "Epoch: 0/10  Loss: 0.457803 Test loss: 1.054006Maharashtra n_f 5 t_s 5 n_layers 1 8 Error 0.49103063 0.5003209276222216 -20.200206160795656\n",
            "Epoch: 0/10  Loss: 0.124851 Test loss: 0.218112Maharashtra n_f 5 t_s 5 n_layers 1 16 Error 0.16213144 0.17410915139108715 -1.5673551184350338\n",
            "Epoch: 0/10  Loss: 0.170295 Test loss: 0.442415Maharashtra n_f 5 t_s 5 n_layers 1 32 Error 0.10753889 0.11375168836435781 -0.09586847351995131\n",
            "Epoch: 0/10  Loss: 0.734130 Test loss: 0.012339Maharashtra n_f 5 t_s 5 n_layers 2 1 Error 0.59760165 0.6070719014306479 -30.212100842468647\n",
            "Epoch: 0/10  Loss: 0.154549 Test loss: 0.587530Maharashtra n_f 5 t_s 5 n_layers 2 5 Error 0.68468684 0.6934091039742669 -39.721315635884054\n",
            "Epoch: 0/10  Loss: 0.224057 Test loss: 0.680171Maharashtra n_f 5 t_s 5 n_layers 2 8 Error 0.48555386 0.49684841096859467 -19.906946088475134\n",
            "Epoch: 0/10  Loss: 0.256193 Test loss: 0.449068Maharashtra n_f 5 t_s 5 n_layers 2 16 Error 0.16463333 0.1769316013879651 -1.651267661708454\n",
            "Epoch: 0/10  Loss: 0.113117 Test loss: 0.064166Maharashtra n_f 5 t_s 5 n_layers 2 32 Error 0.22275034 0.23837112857893428 -3.8122706546112166\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.705060 Test loss: 3.270541Maharashtra n_f 5 t_s 7 n_layers 1 1 Error 0.864726 0.8755082289321543 -81.74427457703742\n",
            "Epoch: 0/10  Loss: 0.194056 Test loss: 0.255534Maharashtra n_f 5 t_s 7 n_layers 1 5 Error 0.08535735 0.10285710557082377 -0.14205263999497109\n",
            "Epoch: 0/10  Loss: 0.476636 Test loss: 1.095276Maharashtra n_f 5 t_s 7 n_layers 1 8 Error 0.5226867 0.5294378451860834 -29.258508041798294\n",
            "Epoch: 0/10  Loss: 0.107514 Test loss: 0.110202Maharashtra n_f 5 t_s 7 n_layers 1 16 Error 0.07997876 0.0859320243261402 0.2028727930777554\n",
            "Epoch: 0/10  Loss: 0.188577 Test loss: 0.468171Maharashtra n_f 5 t_s 7 n_layers 1 32 Error 0.13390541 0.1393448457364693 -1.0960390070420956\n",
            "Epoch: 0/10  Loss: 0.717822 Test loss: 0.009337Maharashtra n_f 5 t_s 7 n_layers 2 1 Error 0.60071695 0.6080825009839781 -38.91559297237842\n",
            "Epoch: 0/10  Loss: 0.171287 Test loss: 0.630921Maharashtra n_f 5 t_s 7 n_layers 2 5 Error 0.7054498 0.7120416890514024 -53.73036587488738\n",
            "Epoch: 0/10  Loss: 0.239835 Test loss: 0.670424Maharashtra n_f 5 t_s 7 n_layers 2 8 Error 0.27279505 0.28499532103880476 -7.767846754149854\n",
            "Epoch: 0/10  Loss: 0.264149 Test loss: 0.454530Maharashtra n_f 5 t_s 7 n_layers 2 16 Error 0.15951946 0.17182208460428744 -2.1869518272432735\n",
            "Epoch: 0/10  Loss: 0.114223 Test loss: 0.080326Maharashtra n_f 5 t_s 7 n_layers 2 32 Error 0.20609893 0.2212837817916335 -4.285872676457544\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.325600 Test loss: 1.109373Maharashtra n_f 6 t_s 5 n_layers 1 1 Error 0.64083225 0.649792783058857 -34.75958810020929\n",
            "Epoch: 0/10  Loss: 0.450265 Test loss: 1.062582Maharashtra n_f 6 t_s 5 n_layers 1 5 Error 0.6803842 0.688271068450062 -39.1200798639069\n",
            "Epoch: 0/10  Loss: 0.250128 Test loss: 0.468550Maharashtra n_f 6 t_s 5 n_layers 1 8 Error 0.574954 0.5848475937101699 -27.96864188160382\n",
            "Epoch: 0/10  Loss: 0.121371 Test loss: 0.204136Maharashtra n_f 6 t_s 5 n_layers 1 16 Error 0.14435819 0.15077749875200366 -0.9253772048359621\n",
            "Epoch: 0/10  Loss: 0.074018 Test loss: 0.071616Maharashtra n_f 6 t_s 5 n_layers 1 32 Error 0.13762207 0.14196914449146167 -0.7069885929771262\n",
            "Epoch: 0/10  Loss: 0.152454 Test loss: 0.340422Maharashtra n_f 6 t_s 5 n_layers 2 1 Error 0.55863976 0.5691097065232058 -26.430563472537624\n",
            "Epoch: 0/10  Loss: 0.186520 Test loss: 0.565234Maharashtra n_f 6 t_s 5 n_layers 2 5 Error 0.27081925 0.28708304719167843 -5.9800387738882375\n",
            "Epoch: 0/10  Loss: 0.196812 Test loss: 0.726660Maharashtra n_f 6 t_s 5 n_layers 2 8 Error 0.30352443 0.3197758761845093 -7.660323379236896\n",
            "Epoch: 0/10  Loss: 0.103259 Test loss: 0.247973Maharashtra n_f 6 t_s 5 n_layers 2 16 Error 0.14632402 0.16111929287691187 -1.1985574664577725\n",
            "Epoch: 0/10  Loss: 0.135089 Test loss: 0.367955Maharashtra n_f 6 t_s 5 n_layers 2 32 Error 0.1322346 0.14917208206435692 -0.88459412182994\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.345456 Test loss: 1.168405Maharashtra n_f 6 t_s 7 n_layers 1 1 Error 0.6481553 0.6552410998942535 -45.34680388535522\n",
            "Epoch: 0/10  Loss: 0.462391 Test loss: 1.101030Maharashtra n_f 6 t_s 7 n_layers 1 5 Error 0.6636651 0.6699745891506442 -47.45451353518701\n",
            "Epoch: 0/10  Loss: 0.257092 Test loss: 0.494683Maharashtra n_f 6 t_s 7 n_layers 1 8 Error 0.58232486 0.5901139505713842 -36.591468336267944\n",
            "Epoch: 0/10  Loss: 0.127383 Test loss: 0.189343Maharashtra n_f 6 t_s 7 n_layers 1 16 Error 0.13504894 0.13874742974873416 -1.0781046918469124\n",
            "Epoch: 0/10  Loss: 0.101061 Test loss: 0.145677Maharashtra n_f 6 t_s 7 n_layers 1 32 Error 0.059829332 0.06496198227822705 0.544449990224426\n",
            "Epoch: 0/10  Loss: 0.157245 Test loss: 0.352690Maharashtra n_f 6 t_s 7 n_layers 2 1 Error 0.56445885 0.5726058781680208 -34.39395567243252\n",
            "Epoch: 0/10  Loss: 0.198581 Test loss: 0.572737Maharashtra n_f 6 t_s 7 n_layers 2 5 Error 0.23361054 0.24862468433503931 -5.672768108538517\n",
            "Epoch: 0/10  Loss: 0.206978 Test loss: 0.734444Maharashtra n_f 6 t_s 7 n_layers 2 8 Error 0.3577879 0.36899911095478505 -13.698334895564233\n",
            "Epoch: 0/10  Loss: 0.099360 Test loss: 0.212724Maharashtra n_f 6 t_s 7 n_layers 2 16 Error 0.20747307 0.2180339042471396 -4.131751442646807\n",
            "Epoch: 0/10  Loss: 0.157159 Test loss: 0.406080Maharashtra n_f 6 t_s 7 n_layers 2 32 Error 0.24912423 0.25936949793024033 -6.261984594716077\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.313130 Test loss: 0.247680Uttar-Pradesh n_f 1 t_s 5 n_layers 1 1 Error 0.7170686 0.7286070083697856 -34.93641355795333\n",
            "Epoch: 0/10  Loss: 0.410224 Test loss: 0.991362Uttar-Pradesh n_f 1 t_s 5 n_layers 1 5 Error 0.63519275 0.6471021299544951 -27.34612405683569\n",
            "Epoch: 0/10  Loss: 0.184009 Test loss: 0.329877Uttar-Pradesh n_f 1 t_s 5 n_layers 1 8 Error 0.45443633 0.4682540017805775 -13.842635037413535\n",
            "Epoch: 0/10  Loss: 0.116139 Test loss: 0.219727Uttar-Pradesh n_f 1 t_s 5 n_layers 1 16 Error 0.2826766 0.2896630646812187 -4.679815822744053\n",
            "Epoch: 0/10  Loss: 0.149420 Test loss: 0.371975Uttar-Pradesh n_f 1 t_s 5 n_layers 1 32 Error 0.17628588 0.17912021527352054 -1.1718869100183888\n",
            "Epoch: 0/10  Loss: 0.598918 Test loss: 1.363299Uttar-Pradesh n_f 1 t_s 5 n_layers 2 1 Error 0.7112608 0.721570782322722 -34.24568038167778\n",
            "Epoch: 0/10  Loss: 0.238926 Test loss: 0.192600Uttar-Pradesh n_f 1 t_s 5 n_layers 2 5 Error 0.6334202 0.6449756823990171 -27.160132359440244\n",
            "Epoch: 0/10  Loss: 0.183181 Test loss: 0.501508Uttar-Pradesh n_f 1 t_s 5 n_layers 2 8 Error 0.47625634 0.4882060031131486 -15.134452185935857\n",
            "Epoch: 0/10  Loss: 0.173689 Test loss: 0.289450Uttar-Pradesh n_f 1 t_s 5 n_layers 2 16 Error 0.106677815 0.12133505067629571 0.0034007162148096404\n",
            "Epoch: 0/10  Loss: 0.071056 Test loss: 0.051671Uttar-Pradesh n_f 1 t_s 5 n_layers 2 32 Error 0.088857904 0.10233597398293225 0.2910678680092532\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.357453 Test loss: 0.222856Uttar-Pradesh n_f 1 t_s 7 n_layers 1 1 Error 0.73977816 0.7486533154457444 -47.88706007071874\n",
            "Epoch: 0/10  Loss: 0.422487 Test loss: 1.042370Uttar-Pradesh n_f 1 t_s 7 n_layers 1 5 Error 0.65469825 0.6633962991995942 -37.38650101912023\n",
            "Epoch: 0/10  Loss: 0.189788 Test loss: 0.351173Uttar-Pradesh n_f 1 t_s 7 n_layers 1 8 Error 0.43663326 0.44837309810191456 -16.535232429799695\n",
            "Epoch: 0/10  Loss: 0.129490 Test loss: 0.232272Uttar-Pradesh n_f 1 t_s 7 n_layers 1 16 Error 0.26133534 0.2663659392480207 -5.1885631144824815\n",
            "Epoch: 0/10  Loss: 0.107094 Test loss: 0.345151Uttar-Pradesh n_f 1 t_s 7 n_layers 1 32 Error 0.025245093 0.03397100126543263 0.8993418094352886\n",
            "Epoch: 0/10  Loss: 0.637757 Test loss: 1.423966Uttar-Pradesh n_f 1 t_s 7 n_layers 2 1 Error 0.73848695 0.7462089809089941 -47.568350918311445\n",
            "Epoch: 0/10  Loss: 0.236513 Test loss: 0.212203Uttar-Pradesh n_f 1 t_s 7 n_layers 2 5 Error 0.6453491 0.6541713537262902 -36.32634671571001\n",
            "Epoch: 0/10  Loss: 0.157728 Test loss: 0.373332Uttar-Pradesh n_f 1 t_s 7 n_layers 2 8 Error 0.1689818 0.18287149357774923 -1.9169195342059875\n",
            "Epoch: 0/10  Loss: 0.180787 Test loss: 0.299137Uttar-Pradesh n_f 1 t_s 7 n_layers 2 16 Error 0.09645717 0.11001036652706928 -0.05560075173033918\n",
            "Epoch: 0/10  Loss: 0.072065 Test loss: 0.050978Uttar-Pradesh n_f 1 t_s 7 n_layers 2 32 Error 0.5384958 0.5402341907470566 -24.456375431879767\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.535566 Test loss: 0.028140Uttar-Pradesh n_f 2 t_s 5 n_layers 1 1 Error 0.66374284 0.6735069725862299 -29.706631247321297\n",
            "Epoch: 0/10  Loss: 0.152933 Test loss: 0.544346Uttar-Pradesh n_f 2 t_s 5 n_layers 1 5 Error 0.5824224 0.5946986750937393 -22.940981730280097\n",
            "Epoch: 0/10  Loss: 0.326204 Test loss: 0.619976Uttar-Pradesh n_f 2 t_s 5 n_layers 1 8 Error 0.21468754 0.23157216873009265 -2.6301183894002698\n",
            "Epoch: 0/10  Loss: 0.153709 Test loss: 0.486658Uttar-Pradesh n_f 2 t_s 5 n_layers 1 16 Error 0.038322814 0.04416543481711676 0.8679577156092233\n",
            "Epoch: 0/10  Loss: 0.162837 Test loss: 0.425708Uttar-Pradesh n_f 2 t_s 5 n_layers 1 32 Error 0.039006326 0.04532183240697017 0.8609525758048078\n",
            "Epoch: 0/10  Loss: 0.326585 Test loss: 0.743095Uttar-Pradesh n_f 2 t_s 5 n_layers 2 1 Error 0.63593495 0.6474439063500498 -27.376073722397237\n",
            "Epoch: 0/10  Loss: 0.376742 Test loss: 0.679366Uttar-Pradesh n_f 2 t_s 5 n_layers 2 5 Error 0.4627506 0.47474156803198225 -14.256769033790953\n",
            "Epoch: 0/10  Loss: 0.316675 Test loss: 0.526160Uttar-Pradesh n_f 2 t_s 5 n_layers 2 8 Error 0.18797627 0.203969419859623 -1.816294967293567\n",
            "Epoch: 0/10  Loss: 0.201885 Test loss: 0.559716Uttar-Pradesh n_f 2 t_s 5 n_layers 2 16 Error 0.075406834 0.09684867731997093 0.36505605670589336\n",
            "Epoch: 0/10  Loss: 0.159966 Test loss: 0.358460Uttar-Pradesh n_f 2 t_s 5 n_layers 2 32 Error 0.12209719 0.1452798914469419 -0.4287591790895737\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.509629 Test loss: 0.037784Uttar-Pradesh n_f 2 t_s 7 n_layers 1 1 Error 0.68267757 0.6902049560840384 -40.55167802589754\n",
            "Epoch: 0/10  Loss: 0.164210 Test loss: 0.581229Uttar-Pradesh n_f 2 t_s 7 n_layers 1 5 Error 0.5996711 0.6089230842407025 -31.34128807763875\n",
            "Epoch: 0/10  Loss: 0.339330 Test loss: 0.657533Uttar-Pradesh n_f 2 t_s 7 n_layers 1 8 Error 0.1538447 0.168959831980994 -1.4900001088746935\n",
            "Epoch: 0/10  Loss: 0.162026 Test loss: 0.488683Uttar-Pradesh n_f 2 t_s 7 n_layers 1 16 Error 0.033857174 0.03894776092923305 0.8676885515332617\n",
            "Epoch: 0/10  Loss: 0.184114 Test loss: 0.511678Uttar-Pradesh n_f 2 t_s 7 n_layers 1 32 Error 0.05186275 0.0603401284358365 0.6824260168986356\n",
            "Epoch: 0/10  Loss: 0.345609 Test loss: 0.793339Uttar-Pradesh n_f 2 t_s 7 n_layers 2 1 Error 0.6472471 0.6560470403445329 -36.540702090296016\n",
            "Epoch: 0/10  Loss: 0.379429 Test loss: 0.665130Uttar-Pradesh n_f 2 t_s 7 n_layers 2 5 Error 0.49049792 0.4992995272909028 -20.74476584360043\n",
            "Epoch: 0/10  Loss: 0.329361 Test loss: 0.553413Uttar-Pradesh n_f 2 t_s 7 n_layers 2 8 Error 0.2880194 0.2986442773288569 -6.779304600441552\n",
            "Epoch: 0/10  Loss: 0.202038 Test loss: 0.514253Uttar-Pradesh n_f 2 t_s 7 n_layers 2 16 Error 0.08250523 0.09618076033184059 0.19312022054603628\n",
            "Epoch: 0/10  Loss: 0.120915 Test loss: 0.245519Uttar-Pradesh n_f 2 t_s 7 n_layers 2 32 Error 0.24837567 0.2621878505063357 -4.995943257124119\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.158850 Test loss: 0.571512Uttar-Pradesh n_f 3 t_s 5 n_layers 1 1 Error 0.57869554 0.5890654171737361 -22.48957083576301\n",
            "Epoch: 0/10  Loss: 0.535289 Test loss: 0.778660Uttar-Pradesh n_f 3 t_s 5 n_layers 1 5 Error 0.13965686 0.15578208837981833 -0.6427936874548741\n",
            "Epoch: 0/10  Loss: 0.306378 Test loss: 0.454847Uttar-Pradesh n_f 3 t_s 5 n_layers 1 8 Error 0.14432062 0.15456343815083431 -0.6171918495381246\n",
            "Epoch: 0/10  Loss: 0.163229 Test loss: 0.478587Uttar-Pradesh n_f 3 t_s 5 n_layers 1 16 Error 0.30886295 0.32886368618827744 -6.321158487980898\n",
            "Epoch: 0/10  Loss: 0.171230 Test loss: 0.278152Uttar-Pradesh n_f 3 t_s 5 n_layers 1 32 Error 0.1090143 0.11403086122246346 0.11977681727966571\n",
            "Epoch: 0/10  Loss: 0.981032 Test loss: 2.416400Uttar-Pradesh n_f 3 t_s 5 n_layers 2 1 Error 1.0997192 1.1064151985400255 -81.86750317918866\n",
            "Epoch: 0/10  Loss: 0.419662 Test loss: 0.776617Uttar-Pradesh n_f 3 t_s 5 n_layers 2 5 Error 0.5370962 0.5477909591800614 -19.313171432339278\n",
            "Epoch: 0/10  Loss: 0.237408 Test loss: 0.363710Uttar-Pradesh n_f 3 t_s 5 n_layers 2 8 Error 0.17314146 0.19793827269390973 -1.6522080077313404\n",
            "Epoch: 0/10  Loss: 0.074010 Test loss: 0.208183Uttar-Pradesh n_f 3 t_s 5 n_layers 2 16 Error 0.25913256 0.2804536671952839 -4.324394897001529\n",
            "Epoch: 0/10  Loss: 0.137425 Test loss: 0.275837Uttar-Pradesh n_f 3 t_s 5 n_layers 2 32 Error 0.20515583 0.22453365708230907 -2.4128004362991455\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.168700 Test loss: 0.608655Uttar-Pradesh n_f 3 t_s 7 n_layers 1 1 Error 0.59495825 0.6028118783365212 -30.695382547649647\n",
            "Epoch: 0/10  Loss: 0.545442 Test loss: 0.776065Uttar-Pradesh n_f 3 t_s 7 n_layers 1 5 Error 0.14765987 0.16029284630035562 -1.2410973228120827\n",
            "Epoch: 0/10  Loss: 0.313151 Test loss: 0.454878Uttar-Pradesh n_f 3 t_s 7 n_layers 1 8 Error 0.11018881 0.12063077128395248 -0.2692542832401159\n",
            "Epoch: 0/10  Loss: 0.173881 Test loss: 0.487886Uttar-Pradesh n_f 3 t_s 7 n_layers 1 16 Error 0.31645328 0.33254887119535237 -8.645913110337514\n",
            "Epoch: 0/10  Loss: 0.173192 Test loss: 0.220705Uttar-Pradesh n_f 3 t_s 7 n_layers 1 32 Error 0.11209892 0.11820846700604751 -0.2187920513900432\n",
            "Epoch: 0/10  Loss: 0.995360 Test loss: 2.498220Uttar-Pradesh n_f 3 t_s 7 n_layers 2 1 Error 1.1269453 1.1320205024540764 -110.77405371333656\n",
            "Epoch: 0/10  Loss: 0.438595 Test loss: 0.825440Uttar-Pradesh n_f 3 t_s 7 n_layers 2 5 Error 0.52114725 0.5295120590122755 -23.45592774278445\n",
            "Epoch: 0/10  Loss: 0.235382 Test loss: 0.366376Uttar-Pradesh n_f 3 t_s 7 n_layers 2 8 Error 0.16323434 0.1852787489816349 -1.9942195139753256\n",
            "Epoch: 0/10  Loss: 0.077623 Test loss: 0.206125Uttar-Pradesh n_f 3 t_s 7 n_layers 2 16 Error 0.27904296 0.2961131157493091 -6.647998083903814\n",
            "Epoch: 0/10  Loss: 0.157590 Test loss: 0.274059Uttar-Pradesh n_f 3 t_s 7 n_layers 2 32 Error 0.3414421 0.35046071018244024 -9.712999376654473\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.544621 Test loss: 1.301179Uttar-Pradesh n_f 4 t_s 5 n_layers 1 1 Error 0.67216337 0.6830637157623783 -30.584240561588004\n",
            "Epoch: 0/10  Loss: 0.255291 Test loss: 0.727722Uttar-Pradesh n_f 4 t_s 5 n_layers 1 5 Error 0.29144058 0.3043370064946886 -5.269855686014779\n",
            "Epoch: 0/10  Loss: 0.425976 Test loss: 0.825136Uttar-Pradesh n_f 4 t_s 5 n_layers 1 8 Error 0.45784438 0.47006858698085635 -13.957894284093133\n",
            "Epoch: 0/10  Loss: 0.093764 Test loss: 0.234696Uttar-Pradesh n_f 4 t_s 5 n_layers 1 16 Error 0.08754985 0.10275888495102041 0.2851963397387519\n",
            "Epoch: 0/10  Loss: 0.114127 Test loss: 0.129544Uttar-Pradesh n_f 4 t_s 5 n_layers 1 32 Error 0.0754572 0.0909053701569305 0.4405940715688219\n",
            "Epoch: 0/10  Loss: 0.456269 Test loss: 1.065305Uttar-Pradesh n_f 4 t_s 5 n_layers 2 1 Error 0.64884484 0.6601303592096669 -28.499009521478033\n",
            "Epoch: 0/10  Loss: 0.138018 Test loss: 0.449976Uttar-Pradesh n_f 4 t_s 5 n_layers 2 5 Error 0.65185696 0.663091083669567 -28.764214131469128\n",
            "Epoch: 0/10  Loss: 0.357117 Test loss: 0.663551Uttar-Pradesh n_f 4 t_s 5 n_layers 2 8 Error 0.19206685 0.21008876191969583 -1.9878148282863641\n",
            "Epoch: 0/10  Loss: 0.143563 Test loss: 0.267687Uttar-Pradesh n_f 4 t_s 5 n_layers 2 16 Error 0.105244316 0.12465860267392836 -0.05194376964201464\n",
            "Epoch: 0/10  Loss: 0.164399 Test loss: 0.306062Uttar-Pradesh n_f 4 t_s 5 n_layers 2 32 Error 0.1937248 0.2116013254069605 -2.0309917618796014\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.560764 Test loss: 1.373356Uttar-Pradesh n_f 4 t_s 7 n_layers 1 1 Error 0.69829977 0.7064612393407095 -42.53205049578304\n",
            "Epoch: 0/10  Loss: 0.265948 Test loss: 0.775687Uttar-Pradesh n_f 4 t_s 7 n_layers 1 5 Error 0.30411312 0.3144098571958673 -7.622332246288941\n",
            "Epoch: 0/10  Loss: 0.440472 Test loss: 0.861302Uttar-Pradesh n_f 4 t_s 7 n_layers 1 8 Error 0.4738897 0.48345923763886356 -19.386944787453416\n",
            "Epoch: 0/10  Loss: 0.098807 Test loss: 0.223591Uttar-Pradesh n_f 4 t_s 7 n_layers 1 16 Error 0.10694038 0.1174474574677089 -0.203149672481854\n",
            "Epoch: 0/10  Loss: 0.111887 Test loss: 0.098658Uttar-Pradesh n_f 4 t_s 7 n_layers 1 32 Error 0.11568173 0.12721048824533424 -0.41149137650532386\n",
            "Epoch: 0/10  Loss: 0.470596 Test loss: 1.118550Uttar-Pradesh n_f 4 t_s 7 n_layers 2 1 Error 0.6718414 0.6803203574249462 -39.370056523378224\n",
            "Epoch: 0/10  Loss: 0.145889 Test loss: 0.477142Uttar-Pradesh n_f 4 t_s 7 n_layers 2 5 Error 0.66729987 0.6760685040084874 -38.86702851522965\n",
            "Epoch: 0/10  Loss: 0.382938 Test loss: 0.767756Uttar-Pradesh n_f 4 t_s 7 n_layers 2 8 Error 0.27384177 0.28768108822218147 -6.218634446262063\n",
            "Epoch: 0/10  Loss: 0.155575 Test loss: 0.280692Uttar-Pradesh n_f 4 t_s 7 n_layers 2 16 Error 0.18327719 0.19337081875315415 -2.26147699378546\n",
            "Epoch: 0/10  Loss: 0.171669 Test loss: 0.251219Uttar-Pradesh n_f 4 t_s 7 n_layers 2 32 Error 0.37809512 0.3873087880373911 -12.08419846793794\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.711119 Test loss: 3.041611Uttar-Pradesh n_f 5 t_s 5 n_layers 1 1 Error 0.8052864 0.8250446610933341 -45.078989209210675\n",
            "Epoch: 0/10  Loss: 0.171723 Test loss: 0.237059Uttar-Pradesh n_f 5 t_s 5 n_layers 1 5 Error 0.123981625 0.14343864915217083 -0.39277302950064286\n",
            "Epoch: 0/10  Loss: 0.464466 Test loss: 0.978525Uttar-Pradesh n_f 5 t_s 5 n_layers 1 8 Error 0.45002985 0.46241491153640835 -13.474770693365352\n",
            "Epoch: 0/10  Loss: 0.148498 Test loss: 0.216232Uttar-Pradesh n_f 5 t_s 5 n_layers 1 16 Error 0.10632526 0.12757740583526622 -0.10178173856053552\n",
            "Epoch: 0/10  Loss: 0.177430 Test loss: 0.378937Uttar-Pradesh n_f 5 t_s 5 n_layers 1 32 Error 0.20002191 0.21030313860675268 -1.9939155138028486\n",
            "Epoch: 0/10  Loss: 0.719987 Test loss: 0.018502Uttar-Pradesh n_f 5 t_s 5 n_layers 2 1 Error 0.5652913 0.5777300181298726 -21.594249240165553\n",
            "Epoch: 0/10  Loss: 0.159777 Test loss: 0.527818Uttar-Pradesh n_f 5 t_s 5 n_layers 2 5 Error 0.6189187 0.6310489712134226 -25.95716073873326\n",
            "Epoch: 0/10  Loss: 0.235428 Test loss: 0.556821Uttar-Pradesh n_f 5 t_s 5 n_layers 2 8 Error 0.21297696 0.2359599169130069 -2.768985650067757\n",
            "Epoch: 0/10  Loss: 0.233807 Test loss: 0.375294Uttar-Pradesh n_f 5 t_s 5 n_layers 2 16 Error 0.2173329 0.23213469771308878 -2.647775655879779\n",
            "Epoch: 0/10  Loss: 0.124654 Test loss: 0.043593Uttar-Pradesh n_f 5 t_s 5 n_layers 2 32 Error 0.22606546 0.24057588106900063 -2.917889518086736\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.744118 Test loss: 3.315598Uttar-Pradesh n_f 5 t_s 7 n_layers 1 1 Error 0.8341901 0.8500408260975247 -62.024869610369755\n",
            "Epoch: 0/10  Loss: 0.173762 Test loss: 0.257532Uttar-Pradesh n_f 5 t_s 7 n_layers 1 5 Error 0.12769939 0.14206783215945928 -0.7604511233029445\n",
            "Epoch: 0/10  Loss: 0.481414 Test loss: 1.031722Uttar-Pradesh n_f 5 t_s 7 n_layers 1 8 Error 0.4655376 0.4748199529480922 -18.664837642539155\n",
            "Epoch: 0/10  Loss: 0.130621 Test loss: 0.127754Uttar-Pradesh n_f 5 t_s 7 n_layers 1 16 Error 0.10006918 0.10757271839648232 -0.009338232272812608\n",
            "Epoch: 0/10  Loss: 0.190356 Test loss: 0.398186Uttar-Pradesh n_f 5 t_s 7 n_layers 1 32 Error 0.14932306 0.15739934916285983 -1.1609180927999887\n",
            "Epoch: 0/10  Loss: 0.705183 Test loss: 0.012570Uttar-Pradesh n_f 5 t_s 7 n_layers 2 1 Error 0.57284665 0.5823886209431481 -28.584090255361982\n",
            "Epoch: 0/10  Loss: 0.171064 Test loss: 0.562533Uttar-Pradesh n_f 5 t_s 7 n_layers 2 5 Error 0.6339861 0.6429392950419142 -35.05557115684492\n",
            "Epoch: 0/10  Loss: 0.248735 Test loss: 0.555117Uttar-Pradesh n_f 5 t_s 7 n_layers 2 8 Error 0.22538513 0.24411141793068203 -4.1976690275638155\n",
            "Epoch: 0/10  Loss: 0.244159 Test loss: 0.403690Uttar-Pradesh n_f 5 t_s 7 n_layers 2 16 Error 0.13248715 0.14622005775618532 -0.8648605269919003\n",
            "Epoch: 0/10  Loss: 0.125154 Test loss: 0.058181Uttar-Pradesh n_f 5 t_s 7 n_layers 2 32 Error 0.37393618 0.38709560489125433 -12.0698003288377\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.368115 Test loss: 1.117170Uttar-Pradesh n_f 6 t_s 5 n_layers 1 1 Error 0.55445313 0.567518497073168 -20.802588695570893\n",
            "Epoch: 0/10  Loss: 0.460351 Test loss: 0.978932Uttar-Pradesh n_f 6 t_s 5 n_layers 1 5 Error 0.526049 0.5375880379990097 -18.563528809792267\n",
            "Epoch: 0/10  Loss: 0.229441 Test loss: 0.399659Uttar-Pradesh n_f 6 t_s 5 n_layers 1 8 Error 0.5136242 0.5269836043697383 -17.799322405494078\n",
            "Epoch: 0/10  Loss: 0.127518 Test loss: 0.120618Uttar-Pradesh n_f 6 t_s 5 n_layers 1 16 Error 0.17680623 0.1828793260912679 -1.2640044670739479\n",
            "Epoch: 0/10  Loss: 0.054850 Test loss: 0.005661Uttar-Pradesh n_f 6 t_s 5 n_layers 1 32 Error 0.1523013 0.15692509009176514 -0.6669892695738155\n",
            "Epoch: 0/10  Loss: 0.130207 Test loss: 0.283964Uttar-Pradesh n_f 6 t_s 5 n_layers 2 1 Error 0.48501107 0.5000081657696545 -15.923966926472701\n",
            "Epoch: 0/10  Loss: 0.170274 Test loss: 0.428587Uttar-Pradesh n_f 6 t_s 5 n_layers 2 5 Error 0.30078444 0.3178381719695174 -5.838489062408089\n",
            "Epoch: 0/10  Loss: 0.202307 Test loss: 0.613463Uttar-Pradesh n_f 6 t_s 5 n_layers 2 8 Error 0.26386616 0.2851448710013255 -4.504008818246636\n",
            "Epoch: 0/10  Loss: 0.096113 Test loss: 0.188155Uttar-Pradesh n_f 6 t_s 5 n_layers 2 16 Error 0.17339365 0.18429821888755868 -1.299271720758611\n",
            "Epoch: 0/10  Loss: 0.142947 Test loss: 0.305529Uttar-Pradesh n_f 6 t_s 5 n_layers 2 32 Error 0.14885907 0.1695406682610929 -0.9457892812526243\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.387907 Test loss: 1.211051Uttar-Pradesh n_f 6 t_s 7 n_layers 1 1 Error 0.5782704 0.5884784281916627 -29.206019299248762\n",
            "Epoch: 0/10  Loss: 0.470894 Test loss: 1.019312Uttar-Pradesh n_f 6 t_s 7 n_layers 1 5 Error 0.48882505 0.4987980432483849 -20.70110902299623\n",
            "Epoch: 0/10  Loss: 0.235400 Test loss: 0.429165Uttar-Pradesh n_f 6 t_s 7 n_layers 1 8 Error 0.5464308 0.5562316194990746 -25.986328192312087\n",
            "Epoch: 0/10  Loss: 0.131844 Test loss: 0.112330Uttar-Pradesh n_f 6 t_s 7 n_layers 1 16 Error 0.13324727 0.1398957270455921 -0.7070306366375878\n",
            "Epoch: 0/10  Loss: 0.053924 Test loss: 0.018893Uttar-Pradesh n_f 6 t_s 7 n_layers 1 32 Error 0.066867396 0.07141137734395733 0.5551974409035888\n",
            "Epoch: 0/10  Loss: 0.128952 Test loss: 0.307104Uttar-Pradesh n_f 6 t_s 7 n_layers 2 1 Error 0.49300972 0.5045031184165311 -21.200366669592583\n",
            "Epoch: 0/10  Loss: 0.171552 Test loss: 0.377846Uttar-Pradesh n_f 6 t_s 7 n_layers 2 5 Error 0.2816278 0.29546900391630804 -6.614761459256528\n",
            "Epoch: 0/10  Loss: 0.211709 Test loss: 0.634157Uttar-Pradesh n_f 6 t_s 7 n_layers 2 8 Error 0.21675484 0.2305501131523854 -3.6362099508616614\n",
            "Epoch: 0/10  Loss: 0.110440 Test loss: 0.187651Uttar-Pradesh n_f 6 t_s 7 n_layers 2 16 Error 0.17826222 0.18821294661531818 -2.089807299135949\n",
            "Epoch: 0/10  Loss: 0.162836 Test loss: 0.338380Uttar-Pradesh n_f 6 t_s 7 n_layers 2 32 Error 0.19622001 0.2068026738349965 -2.7303084342774286\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.277150 Test loss: 0.270349Kerala n_f 1 t_s 5 n_layers 1 1 Error 0.6596762 0.6756912127364493 -25.13517236851502\n",
            "Epoch: 0/10  Loss: 0.418815 Test loss: 1.009931Kerala n_f 1 t_s 5 n_layers 1 5 Error 0.59323573 0.6079408936600446 -20.15687857805143\n",
            "Epoch: 0/10  Loss: 0.134436 Test loss: 0.386569Kerala n_f 1 t_s 5 n_layers 1 8 Error 0.52303857 0.537213402124188 -15.520475460458744\n",
            "Epoch: 0/10  Loss: 0.129139 Test loss: 0.227907Kerala n_f 1 t_s 5 n_layers 1 16 Error 0.3912307 0.4006129880166651 -8.187109277764089\n",
            "Epoch: 0/10  Loss: 0.045750 Test loss: 0.312326Kerala n_f 1 t_s 5 n_layers 1 32 Error 0.25042903 0.25657961568764664 -2.7685401594559362\n",
            "Epoch: 0/10  Loss: 0.610281 Test loss: 1.397223Kerala n_f 1 t_s 5 n_layers 2 1 Error 0.72462934 0.7365845656134516 -30.058042891463074\n",
            "Epoch: 0/10  Loss: 0.207598 Test loss: 0.208507Kerala n_f 1 t_s 5 n_layers 2 5 Error 0.6197136 0.6336513187393219 -21.98420949934228\n",
            "Epoch: 0/10  Loss: 0.120822 Test loss: 0.320785Kerala n_f 1 t_s 5 n_layers 2 8 Error 0.4786688 0.49133399347241974 -12.819186136475246\n",
            "Epoch: 0/10  Loss: 0.185974 Test loss: 0.304463Kerala n_f 1 t_s 5 n_layers 2 16 Error 0.46370208 0.4740648010338881 -11.864836563409732\n",
            "Epoch: 0/10  Loss: 0.105256 Test loss: 0.260282Kerala n_f 1 t_s 5 n_layers 2 32 Error 0.37658343 0.38452960293388805 -7.464248880996118\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.328211 Test loss: 0.247958Kerala n_f 1 t_s 7 n_layers 1 1 Error 0.6968874 0.7077720091566551 -40.980395154516756\n",
            "Epoch: 0/10  Loss: 0.433962 Test loss: 1.071425Kerala n_f 1 t_s 7 n_layers 1 5 Error 0.6218943 0.631646907777509 -32.435553885188895\n",
            "Epoch: 0/10  Loss: 0.139847 Test loss: 0.416242Kerala n_f 1 t_s 7 n_layers 1 8 Error 0.5280394 0.5364522347211624 -23.116919979899606\n",
            "Epoch: 0/10  Loss: 0.142293 Test loss: 0.244009Kerala n_f 1 t_s 7 n_layers 1 16 Error 0.41315684 0.4189285950782071 -13.70753139226184\n",
            "Epoch: 0/10  Loss: 0.055727 Test loss: 0.335407Kerala n_f 1 t_s 7 n_layers 1 32 Error 0.22861804 0.23005942186070044 -3.435471367800562\n",
            "Epoch: 0/10  Loss: 0.645239 Test loss: 1.470362Kerala n_f 1 t_s 7 n_layers 2 1 Error 0.7576544 0.7654887097558274 -48.10631173309038\n",
            "Epoch: 0/10  Loss: 0.204649 Test loss: 0.232233Kerala n_f 1 t_s 7 n_layers 2 5 Error 0.65091157 0.6600140751436023 -35.50616050134238\n",
            "Epoch: 0/10  Loss: 0.131473 Test loss: 0.338086Kerala n_f 1 t_s 7 n_layers 2 8 Error 0.4925516 0.5001895068575367 -19.966644234668813\n",
            "Epoch: 0/10  Loss: 0.192910 Test loss: 0.318333Kerala n_f 1 t_s 7 n_layers 2 16 Error 0.5255612 0.5319584162260281 -22.714562828931296\n",
            "Epoch: 0/10  Loss: 0.110616 Test loss: 0.228538Kerala n_f 1 t_s 7 n_layers 2 32 Error 0.4289681 0.434401764491091 -14.814043647799048\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.522684 Test loss: 0.034798Kerala n_f 2 t_s 5 n_layers 1 1 Error 0.60656387 0.6204288930779179 -21.034991033171533\n",
            "Epoch: 0/10  Loss: 0.112138 Test loss: 0.448136Kerala n_f 2 t_s 5 n_layers 1 5 Error 0.5611034 0.5759050430284376 -17.985873645526038\n",
            "Epoch: 0/10  Loss: 0.332993 Test loss: 0.645120Kerala n_f 2 t_s 5 n_layers 1 8 Error 0.4355088 0.4463768503337145 -10.405968625274486\n",
            "Epoch: 0/10  Loss: 0.169979 Test loss: 0.507906Kerala n_f 2 t_s 5 n_layers 1 16 Error 0.3546904 0.3632466289471484 -6.553218692319559\n",
            "Epoch: 0/10  Loss: 0.047715 Test loss: 0.238547Kerala n_f 2 t_s 5 n_layers 1 32 Error 0.35213608 0.3595203644697369 -6.399047256833803\n",
            "Epoch: 0/10  Loss: 0.339121 Test loss: 0.768558Kerala n_f 2 t_s 5 n_layers 2 1 Error 0.625529 0.6393760275809196 -22.40138380692062\n",
            "Epoch: 0/10  Loss: 0.388105 Test loss: 0.708299Kerala n_f 2 t_s 5 n_layers 2 5 Error 0.57270426 0.5848663457387965 -18.58132711217696\n",
            "Epoch: 0/10  Loss: 0.327530 Test loss: 0.538766Kerala n_f 2 t_s 5 n_layers 2 8 Error 0.4237461 0.4343500500655823 -9.799622890707765\n",
            "Epoch: 0/10  Loss: 0.127270 Test loss: 0.368675Kerala n_f 2 t_s 5 n_layers 2 16 Error 0.28867874 0.29862373193541075 -4.10478540197784\n",
            "Epoch: 0/10  Loss: 0.117348 Test loss: 0.284479Kerala n_f 2 t_s 5 n_layers 2 32 Error 0.37029418 0.38127315247698207 -7.321493441120499\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.496827 Test loss: 0.045654Kerala n_f 2 t_s 7 n_layers 1 1 Error 0.628278 0.6374986470899999 -33.05793415885683\n",
            "Epoch: 0/10  Loss: 0.122773 Test loss: 0.489035Kerala n_f 2 t_s 7 n_layers 1 5 Error 0.5926117 0.6022593437853985 -29.39672654670175\n",
            "Epoch: 0/10  Loss: 0.344600 Test loss: 0.678018Kerala n_f 2 t_s 7 n_layers 1 8 Error 0.3875352 0.39461986566320406 -12.050213657417553\n",
            "Epoch: 0/10  Loss: 0.177442 Test loss: 0.518756Kerala n_f 2 t_s 7 n_layers 1 16 Error 0.3007008 0.30351853485872743 -6.720229713351931\n",
            "Epoch: 0/10  Loss: 0.057581 Test loss: 0.300931Kerala n_f 2 t_s 7 n_layers 1 32 Error 0.34879637 0.35283762370179794 -9.43300750527001\n",
            "Epoch: 0/10  Loss: 0.357640 Test loss: 0.827653Kerala n_f 2 t_s 7 n_layers 2 1 Error 0.65422124 0.6633161726565701 -35.87236011710955\n",
            "Epoch: 0/10  Loss: 0.389079 Test loss: 0.696021Kerala n_f 2 t_s 7 n_layers 2 5 Error 0.5974735 0.6056094344572688 -29.73583224186434\n",
            "Epoch: 0/10  Loss: 0.338963 Test loss: 0.569788Kerala n_f 2 t_s 7 n_layers 2 8 Error 0.5289362 0.5366814035362809 -23.137531093849617\n",
            "Epoch: 0/10  Loss: 0.142762 Test loss: 0.410941Kerala n_f 2 t_s 7 n_layers 2 16 Error 0.399642 0.40453812408795176 -12.714460472428422\n",
            "Epoch: 0/10  Loss: 0.116994 Test loss: 0.250331Kerala n_f 2 t_s 7 n_layers 2 32 Error 0.41410044 0.42254971485405923 -13.962887386590861\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.145397 Test loss: 0.503278Kerala n_f 3 t_s 5 n_layers 1 1 Error 0.5601273 0.5726064246595041 -17.769006706477146\n",
            "Epoch: 0/10  Loss: 0.550141 Test loss: 0.745079Kerala n_f 3 t_s 5 n_layers 1 5 Error 0.25559112 0.2681229328529328 -3.115255299990377\n",
            "Epoch: 0/10  Loss: 0.310693 Test loss: 0.451350Kerala n_f 3 t_s 5 n_layers 1 8 Error 0.292863 0.302122457480948 -4.2251030431912024\n",
            "Epoch: 0/10  Loss: 0.117203 Test loss: 0.360844Kerala n_f 3 t_s 5 n_layers 1 16 Error 0.4150151 0.43043321577066745 -9.605726484272273\n",
            "Epoch: 0/10  Loss: 0.185274 Test loss: 0.241158Kerala n_f 3 t_s 5 n_layers 1 32 Error 0.18803859 0.1939056175307688 -1.1523338070689144\n",
            "Epoch: 0/10  Loss: 0.993476 Test loss: 2.460711Kerala n_f 3 t_s 5 n_layers 2 1 Error 1.1130878 1.1209073327085952 -70.923073908074\n",
            "Epoch: 0/10  Loss: 0.427548 Test loss: 0.814787Kerala n_f 3 t_s 5 n_layers 2 5 Error 0.56471336 0.5772911192323403 -18.077375139010982\n",
            "Epoch: 0/10  Loss: 0.245588 Test loss: 0.359482Kerala n_f 3 t_s 5 n_layers 2 8 Error 0.4608367 0.474974974173782 -11.914282519740963\n",
            "Epoch: 0/10  Loss: 0.081024 Test loss: 0.247317Kerala n_f 3 t_s 5 n_layers 2 16 Error 0.3380619 0.3530486695323565 -6.135065993907476\n",
            "Epoch: 0/10  Loss: 0.130497 Test loss: 0.259925Kerala n_f 3 t_s 5 n_layers 2 32 Error 0.2213467 0.22606878088720225 -1.925567211073087\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.169179 Test loss: 0.563095Kerala n_f 3 t_s 7 n_layers 1 1 Error 0.58991766 0.5979216989666533 -28.960452428710614\n",
            "Epoch: 0/10  Loss: 0.560108 Test loss: 0.760328Kerala n_f 3 t_s 7 n_layers 1 5 Error 0.26979113 0.2788450948735576 -5.516070891012817\n",
            "Epoch: 0/10  Loss: 0.315217 Test loss: 0.448025Kerala n_f 3 t_s 7 n_layers 1 8 Error 0.30517244 0.3115702626783146 -7.135266751153658\n",
            "Epoch: 0/10  Loss: 0.119436 Test loss: 0.366979Kerala n_f 3 t_s 7 n_layers 1 16 Error 0.40456337 0.41480280715425666 -13.419264333153132\n",
            "Epoch: 0/10  Loss: 0.186926 Test loss: 0.190714Kerala n_f 3 t_s 7 n_layers 1 32 Error 0.1846676 0.18789975943141396 -1.9587769826178887\n",
            "Epoch: 0/10  Loss: 1.007123 Test loss: 2.559507Kerala n_f 3 t_s 7 n_layers 2 1 Error 1.1461127 1.1513066684390285 -110.08150993414468\n",
            "Epoch: 0/10  Loss: 0.445772 Test loss: 0.875606Kerala n_f 3 t_s 7 n_layers 2 5 Error 0.5835717 0.5917796015972565 -28.34808386858543\n",
            "Epoch: 0/10  Loss: 0.242639 Test loss: 0.362262Kerala n_f 3 t_s 7 n_layers 2 8 Error 0.45243788 0.4619501757063925 -16.883397115731352\n",
            "Epoch: 0/10  Loss: 0.091960 Test loss: 0.277029Kerala n_f 3 t_s 7 n_layers 2 16 Error 0.4239222 0.43389862957733816 -14.77743117879759\n",
            "Epoch: 0/10  Loss: 0.139743 Test loss: 0.271127Kerala n_f 3 t_s 7 n_layers 2 32 Error 0.075951226 0.09089806007860989 0.3075809568732366\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.553719 Test loss: 1.338713Kerala n_f 4 t_s 5 n_layers 1 1 Error 0.6753715 0.6881506831740519 -26.107905424823386\n",
            "Epoch: 0/10  Loss: 0.274738 Test loss: 0.777286Kerala n_f 4 t_s 5 n_layers 1 5 Error 0.43591657 0.45133199781565847 -10.660605886105257\n",
            "Epoch: 0/10  Loss: 0.448457 Test loss: 0.812996Kerala n_f 4 t_s 5 n_layers 1 8 Error 0.45037782 0.4672589748147237 -11.498104160576725\n",
            "Epoch: 0/10  Loss: 0.107056 Test loss: 0.242736Kerala n_f 4 t_s 5 n_layers 1 16 Error 0.20706792 0.21933380628656085 -1.7538482215399305\n",
            "Epoch: 0/10  Loss: 0.121362 Test loss: 0.108514Kerala n_f 4 t_s 5 n_layers 1 32 Error 0.10256894 0.1259940527078143 0.0912823402179529\n",
            "Epoch: 0/10  Loss: 0.468712 Test loss: 1.095585Kerala n_f 4 t_s 5 n_layers 2 1 Error 0.61892676 0.6328818200844131 -21.92841875948919\n",
            "Epoch: 0/10  Loss: 0.093865 Test loss: 0.461594Kerala n_f 4 t_s 5 n_layers 2 5 Error 0.60673916 0.6209682121802452 -21.073316202925795\n",
            "Epoch: 0/10  Loss: 0.369545 Test loss: 0.677495Kerala n_f 4 t_s 5 n_layers 2 8 Error 0.2810009 0.3008565932199495 -4.181409444211669\n",
            "Epoch: 0/10  Loss: 0.144785 Test loss: 0.301832Kerala n_f 4 t_s 5 n_layers 2 16 Error 0.10498003 0.12986660619602292 0.03456322965641789\n",
            "Epoch: 0/10  Loss: 0.131213 Test loss: 0.216711Kerala n_f 4 t_s 5 n_layers 2 32 Error 0.28984174 0.30504220709570257 -4.326582857897248\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.568491 Test loss: 1.423809Kerala n_f 4 t_s 7 n_layers 1 1 Error 0.7065991 0.7149034485616788 -41.830639242716536\n",
            "Epoch: 0/10  Loss: 0.285949 Test loss: 0.835578Kerala n_f 4 t_s 7 n_layers 1 5 Error 0.45176214 0.4630562852032354 -16.96914008173037\n",
            "Epoch: 0/10  Loss: 0.463163 Test loss: 0.857875Kerala n_f 4 t_s 7 n_layers 1 8 Error 0.48688108 0.49830466685830266 -19.80892619788455\n",
            "Epoch: 0/10  Loss: 0.109449 Test loss: 0.220687Kerala n_f 4 t_s 7 n_layers 1 16 Error 0.13388857 0.14995285823250157 -0.8843831638507906\n",
            "Epoch: 0/10  Loss: 0.117257 Test loss: 0.076851Kerala n_f 4 t_s 7 n_layers 1 32 Error 0.18694486 0.1973676700849635 -2.264463336627415\n",
            "Epoch: 0/10  Loss: 0.482359 Test loss: 1.159721Kerala n_f 4 t_s 7 n_layers 2 1 Error 0.6471074 0.6562626701221793 -35.09234970032866\n",
            "Epoch: 0/10  Loss: 0.096941 Test loss: 0.456302Kerala n_f 4 t_s 7 n_layers 2 5 Error 0.6017692 0.6138913466930335 -30.582229180844763\n",
            "Epoch: 0/10  Loss: 0.394514 Test loss: 0.815120Kerala n_f 4 t_s 7 n_layers 2 8 Error 0.43751475 0.4489010060286556 -15.8873275327973\n",
            "Epoch: 0/10  Loss: 0.151998 Test loss: 0.303071Kerala n_f 4 t_s 7 n_layers 2 16 Error 0.22484156 0.2359529859626936 -3.6656340701229455\n",
            "Epoch: 0/10  Loss: 0.116259 Test loss: 0.157445Kerala n_f 4 t_s 7 n_layers 2 32 Error 0.3137774 0.3231039875473663 -7.748717532125099\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.710249 Test loss: 2.840421Kerala n_f 5 t_s 5 n_layers 1 1 Error 0.8441285 0.8622349746536385 -41.55789140128502\n",
            "Epoch: 0/10  Loss: 0.126905 Test loss: 0.300688Kerala n_f 5 t_s 5 n_layers 1 5 Error 0.35330015 0.3705456953132473 -6.8598162687209765\n",
            "Epoch: 0/10  Loss: 0.472810 Test loss: 1.015434Kerala n_f 5 t_s 5 n_layers 1 8 Error 0.47418976 0.48854535399009946 -12.662766918421443\n",
            "Epoch: 0/10  Loss: 0.147812 Test loss: 0.150922Kerala n_f 5 t_s 5 n_layers 1 16 Error 0.11908167 0.1403579427838627 -0.12772409814873287\n",
            "Epoch: 0/10  Loss: 0.088726 Test loss: 0.187375Kerala n_f 5 t_s 5 n_layers 1 32 Error 0.25121418 0.273209176786012 -3.2728670473832064\n",
            "Epoch: 0/10  Loss: 0.706357 Test loss: 0.019638Kerala n_f 5 t_s 5 n_layers 2 1 Error 0.61234814 0.6262444980554775 -21.45001600858176\n",
            "Epoch: 0/10  Loss: 0.106945 Test loss: 0.431823Kerala n_f 5 t_s 5 n_layers 2 5 Error 0.48514187 0.500672990163235 -13.349514030925961\n",
            "Epoch: 0/10  Loss: 0.247551 Test loss: 0.618031Kerala n_f 5 t_s 5 n_layers 2 8 Error 0.3703145 0.3858639874890306 -7.523095407529958\n",
            "Epoch: 0/10  Loss: 0.183800 Test loss: 0.484604Kerala n_f 5 t_s 5 n_layers 2 16 Error 0.21918856 0.2380976047426631 -2.2451805043440585\n",
            "Epoch: 0/10  Loss: 0.142354 Test loss: 0.050577Kerala n_f 5 t_s 5 n_layers 2 32 Error 0.3150062 0.33355516885110015 -5.36889681127375\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.724931 Test loss: 3.075876Kerala n_f 5 t_s 7 n_layers 1 1 Error 0.87201256 0.8849346344725827 -64.62693279661599\n",
            "Epoch: 0/10  Loss: 0.128851 Test loss: 0.322704Kerala n_f 5 t_s 7 n_layers 1 5 Error 0.37266314 0.3847057276543567 -11.40272319448876\n",
            "Epoch: 0/10  Loss: 0.489617 Test loss: 1.078712Kerala n_f 5 t_s 7 n_layers 1 8 Error 0.50163966 0.5111100165152692 -20.89215695683196\n",
            "Epoch: 0/10  Loss: 0.137033 Test loss: 0.121281Kerala n_f 5 t_s 7 n_layers 1 16 Error 0.17906076 0.1925599304332358 -2.107360012210496\n",
            "Epoch: 0/10  Loss: 0.099164 Test loss: 0.197400Kerala n_f 5 t_s 7 n_layers 1 32 Error 0.117507145 0.1456099030441827 -0.7768124627588842\n",
            "Epoch: 0/10  Loss: 0.692195 Test loss: 0.012103Kerala n_f 5 t_s 7 n_layers 2 1 Error 0.62736356 0.6366492157395222 -32.96723154030054\n",
            "Epoch: 0/10  Loss: 0.115312 Test loss: 0.486849Kerala n_f 5 t_s 7 n_layers 2 5 Error 0.63439953 0.6442472352311625 -33.78282775115514\n",
            "Epoch: 0/10  Loss: 0.261032 Test loss: 0.618692Kerala n_f 5 t_s 7 n_layers 2 8 Error 0.36140063 0.3739976600150482 -10.72188805800185\n",
            "Epoch: 0/10  Loss: 0.190064 Test loss: 0.489608Kerala n_f 5 t_s 7 n_layers 2 16 Error 0.23329581 0.24965690375202002 -4.223323268897596\n",
            "Epoch: 0/10  Loss: 0.136337 Test loss: 0.038329Kerala n_f 5 t_s 7 n_layers 2 32 Error 0.38279313 0.3956808771203701 -12.120483110686227\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.382372 Test loss: 1.099061Kerala n_f 6 t_s 5 n_layers 1 1 Error 0.59151435 0.6083945431898463 -20.18846305861777\n",
            "Epoch: 0/10  Loss: 0.470038 Test loss: 1.024584Kerala n_f 6 t_s 5 n_layers 1 5 Error 0.5839341 0.5980820977461027 -19.476253161173346\n",
            "Epoch: 0/10  Loss: 0.163436 Test loss: 0.457815Kerala n_f 6 t_s 5 n_layers 1 8 Error 0.54867524 0.5641991595044615 -17.221902664843782\n",
            "Epoch: 0/10  Loss: 0.144810 Test loss: 0.151617Kerala n_f 6 t_s 5 n_layers 1 16 Error 0.22207531 0.24446713548537 -2.4211315318164193\n",
            "Epoch: 0/10  Loss: 0.079874 Test loss: 0.052798Kerala n_f 6 t_s 5 n_layers 1 32 Error 0.10706555 0.13089104881140595 0.019271595066048808\n",
            "Epoch: 0/10  Loss: 0.093768 Test loss: 0.308581Kerala n_f 6 t_s 5 n_layers 2 1 Error 0.5217915 0.5382708666150169 -15.585577745762908\n",
            "Epoch: 0/10  Loss: 0.114155 Test loss: 0.404856Kerala n_f 6 t_s 5 n_layers 2 5 Error 0.3231292 0.34617068036320303 -5.859767431008409\n",
            "Epoch: 0/10  Loss: 0.131612 Test loss: 0.396057Kerala n_f 6 t_s 5 n_layers 2 8 Error 0.22692439 0.25212096013608964 -2.6387039381756434\n",
            "Epoch: 0/10  Loss: 0.119546 Test loss: 0.279167Kerala n_f 6 t_s 5 n_layers 2 16 Error 0.2186451 0.2411532081989537 -2.3290086066120708\n",
            "Epoch: 0/10  Loss: 0.138663 Test loss: 0.278150Kerala n_f 6 t_s 5 n_layers 2 32 Error 0.12811747 0.15987657341432643 -0.46318259691291797\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.401124 Test loss: 1.185249Kerala n_f 6 t_s 7 n_layers 1 1 Error 0.6228235 0.6354047404144535 -32.83457126876499\n",
            "Epoch: 0/10  Loss: 0.480237 Test loss: 1.076502Kerala n_f 6 t_s 7 n_layers 1 5 Error 0.62418276 0.6334324849047345 -32.6248513976326\n",
            "Epoch: 0/10  Loss: 0.169292 Test loss: 0.501189Kerala n_f 6 t_s 7 n_layers 1 8 Error 0.57318515 0.5833564367714587 -27.518571544009063\n",
            "Epoch: 0/10  Loss: 0.146606 Test loss: 0.143503Kerala n_f 6 t_s 7 n_layers 1 16 Error 0.22663361 0.24622394508645545 -4.080662423621698\n",
            "Epoch: 0/10  Loss: 0.089842 Test loss: 0.112101Kerala n_f 6 t_s 7 n_layers 1 32 Error 0.27811992 0.2892850328577012 -6.0131267607120344\n",
            "Epoch: 0/10  Loss: 0.096950 Test loss: 0.334137Kerala n_f 6 t_s 7 n_layers 2 1 Error 0.546769 0.5575742955588769 -25.053449636432543\n",
            "Epoch: 0/10  Loss: 0.122585 Test loss: 0.448698Kerala n_f 6 t_s 7 n_layers 2 5 Error 0.3289165 0.3457092780303798 -9.015711732196436\n",
            "Epoch: 0/10  Loss: 0.140348 Test loss: 0.430076Kerala n_f 6 t_s 7 n_layers 2 8 Error 0.2753235 0.29132139540347274 -6.112208786060911\n",
            "Epoch: 0/10  Loss: 0.111151 Test loss: 0.243636Kerala n_f 6 t_s 7 n_layers 2 16 Error 0.2374316 0.25462838698013285 -4.433420740607624\n",
            "Epoch: 0/10  Loss: 0.143174 Test loss: 0.310365Kerala n_f 6 t_s 7 n_layers 2 32 Error 0.17242932 0.1964140347111704 -2.2329931524556224\n",
            "(80, 5, 1)\n",
            "(80, 5, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.345999 Test loss: 0.218718Tamil-Nadu n_f 1 t_s 5 n_layers 1 1 Error 0.7328179 0.7489730638975148 -25.384771124586294\n",
            "Epoch: 0/10  Loss: 0.359439 Test loss: 0.924388Tamil-Nadu n_f 1 t_s 5 n_layers 1 5 Error 0.63972515 0.6563501508676997 -19.262458770837117\n",
            "Epoch: 0/10  Loss: 0.190690 Test loss: 0.332583Tamil-Nadu n_f 1 t_s 5 n_layers 1 8 Error 0.57409114 0.5894045173316577 -15.339842325478223\n",
            "Epoch: 0/10  Loss: 0.074359 Test loss: 0.202542Tamil-Nadu n_f 1 t_s 5 n_layers 1 16 Error 0.4062949 0.41619287216241285 -7.1472338606417924\n",
            "Epoch: 0/10  Loss: 0.133156 Test loss: 0.420391Tamil-Nadu n_f 1 t_s 5 n_layers 1 32 Error 0.12857056 0.12896740791975714 0.21768647003434516\n",
            "Epoch: 0/10  Loss: 0.551060 Test loss: 1.285767Tamil-Nadu n_f 1 t_s 5 n_layers 2 1 Error 0.6745028 0.6900832670873801 -21.3987567274147\n",
            "Epoch: 0/10  Loss: 0.264447 Test loss: 0.170993Tamil-Nadu n_f 1 t_s 5 n_layers 2 5 Error 0.66180396 0.6776763935186944 -20.600591078291398\n",
            "Epoch: 0/10  Loss: 0.160731 Test loss: 0.556281Tamil-Nadu n_f 1 t_s 5 n_layers 2 8 Error 0.5812007 0.5956826878778456 -15.689790440764849\n",
            "Epoch: 0/10  Loss: 0.127263 Test loss: 0.264178Tamil-Nadu n_f 1 t_s 5 n_layers 2 16 Error 0.39981028 0.4131577702104718 -7.028839425013571\n",
            "Epoch: 0/10  Loss: 0.102830 Test loss: 0.323359Tamil-Nadu n_f 1 t_s 5 n_layers 2 32 Error 0.14868003 0.16597749608819398 -0.29574449851433604\n",
            "(80, 7, 1)\n",
            "(80, 7, 1) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.396921 Test loss: 0.197606Tamil-Nadu n_f 1 t_s 7 n_layers 1 1 Error 0.7766232 0.7890200461873719 -35.66843449318638\n",
            "Epoch: 0/10  Loss: 0.371720 Test loss: 0.990601Tamil-Nadu n_f 1 t_s 7 n_layers 1 5 Error 0.6650146 0.6776595280457827 -26.048262157742744\n",
            "Epoch: 0/10  Loss: 0.194838 Test loss: 0.358873Tamil-Nadu n_f 1 t_s 7 n_layers 1 8 Error 0.59889066 0.6115869821083652 -21.030927227729304\n",
            "Epoch: 0/10  Loss: 0.083897 Test loss: 0.212592Tamil-Nadu n_f 1 t_s 7 n_layers 1 16 Error 0.4147584 0.42249143563568375 -9.5136156578383\n",
            "Epoch: 0/10  Loss: 0.107570 Test loss: 0.442148Tamil-Nadu n_f 1 t_s 7 n_layers 1 32 Error 0.21772994 0.22060619183574243 -1.8664982644140782\n",
            "Epoch: 0/10  Loss: 0.589728 Test loss: 1.353735Tamil-Nadu n_f 1 t_s 7 n_layers 2 1 Error 0.7061822 0.718102578194084 -29.373105981105166\n",
            "Epoch: 0/10  Loss: 0.260386 Test loss: 0.191609Tamil-Nadu n_f 1 t_s 7 n_layers 2 5 Error 0.6755879 0.6880383767705198 -26.883135775101678\n",
            "Epoch: 0/10  Loss: 0.151836 Test loss: 0.495852Tamil-Nadu n_f 1 t_s 7 n_layers 2 8 Error 0.55152947 0.5639541162568746 -17.732849888047117\n",
            "Epoch: 0/10  Loss: 0.132145 Test loss: 0.273626Tamil-Nadu n_f 1 t_s 7 n_layers 2 16 Error 0.23725627 0.24790110772994475 -2.6197051987945295\n",
            "Epoch: 0/10  Loss: 0.108223 Test loss: 0.315090Tamil-Nadu n_f 1 t_s 7 n_layers 2 32 Error 0.06870617 0.09362106099106066 0.4837460523955879\n",
            "(80, 5, 2)\n",
            "(80, 5, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.583879 Test loss: 0.027384Tamil-Nadu n_f 2 t_s 5 n_layers 1 1 Error 0.6672746 0.681677065861696 -20.856384990500803\n",
            "Epoch: 0/10  Loss: 0.127006 Test loss: 0.554166Tamil-Nadu n_f 2 t_s 5 n_layers 1 5 Error 0.5857324 0.6026045208806013 -16.07991714760386\n",
            "Epoch: 0/10  Loss: 0.284178 Test loss: 0.585974Tamil-Nadu n_f 2 t_s 5 n_layers 1 8 Error 0.31975496 0.3365595735619278 -4.32776236504976\n",
            "Epoch: 0/10  Loss: 0.100202 Test loss: 0.449769Tamil-Nadu n_f 2 t_s 5 n_layers 1 16 Error 0.0841353 0.09771686580074757 0.5508825084502034\n",
            "Epoch: 0/10  Loss: 0.119997 Test loss: 0.410239Tamil-Nadu n_f 2 t_s 5 n_layers 1 32 Error 0.08830109 0.11183899647096414 0.4116883744904981\n",
            "Epoch: 0/10  Loss: 0.278648 Test loss: 0.688503Tamil-Nadu n_f 2 t_s 5 n_layers 2 1 Error 0.6866318 0.7018992442073576 -22.172369623479124\n",
            "Epoch: 0/10  Loss: 0.331313 Test loss: 0.631464Tamil-Nadu n_f 2 t_s 5 n_layers 2 5 Error 0.54875576 0.5642579741195495 -13.975328142731154\n",
            "Epoch: 0/10  Loss: 0.268822 Test loss: 0.482801Tamil-Nadu n_f 2 t_s 5 n_layers 2 8 Error 0.3464717 0.3601828286051555 -5.101925956732147\n",
            "Epoch: 0/10  Loss: 0.161321 Test loss: 0.540927Tamil-Nadu n_f 2 t_s 5 n_layers 2 16 Error 0.14782403 0.17882638339639895 -0.5041256783252619\n",
            "Epoch: 0/10  Loss: 0.142105 Test loss: 0.349485Tamil-Nadu n_f 2 t_s 5 n_layers 2 32 Error 0.16131173 0.1901222975894349 -0.7001491241202331\n",
            "(80, 7, 2)\n",
            "(80, 7, 2) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.559850 Test loss: 0.033848Tamil-Nadu n_f 2 t_s 7 n_layers 1 1 Error 0.7035385 0.7147330526722434 -29.088740911988396\n",
            "Epoch: 0/10  Loss: 0.138308 Test loss: 0.612141Tamil-Nadu n_f 2 t_s 7 n_layers 1 5 Error 0.6133718 0.6266665650513072 -22.13073015467149\n",
            "Epoch: 0/10  Loss: 0.295716 Test loss: 0.616551Tamil-Nadu n_f 2 t_s 7 n_layers 1 8 Error 0.34061745 0.35377101208992867 -6.371584067576049\n",
            "Epoch: 0/10  Loss: 0.107053 Test loss: 0.456229Tamil-Nadu n_f 2 t_s 7 n_layers 1 16 Error 0.08891896 0.10427580024018449 0.35955276248426604\n",
            "Epoch: 0/10  Loss: 0.149359 Test loss: 0.549790Tamil-Nadu n_f 2 t_s 7 n_layers 1 32 Error 0.18608992 0.18830946200465365 -1.0886254393276595\n",
            "Epoch: 0/10  Loss: 0.295997 Test loss: 0.743112Tamil-Nadu n_f 2 t_s 7 n_layers 2 1 Error 0.71557623 0.7273035269820745 -30.15642910855221\n",
            "Epoch: 0/10  Loss: 0.332447 Test loss: 0.623781Tamil-Nadu n_f 2 t_s 7 n_layers 2 5 Error 0.5654082 0.5775057853062159 -18.643955042889022\n",
            "Epoch: 0/10  Loss: 0.279939 Test loss: 0.514272Tamil-Nadu n_f 2 t_s 7 n_layers 2 8 Error 0.28956097 0.3022365537749393 -4.380346609220864\n",
            "Epoch: 0/10  Loss: 0.170706 Test loss: 0.540479Tamil-Nadu n_f 2 t_s 7 n_layers 2 16 Error 0.16308562 0.1819523013904189 -0.9499854337848743\n",
            "Epoch: 0/10  Loss: 0.110597 Test loss: 0.347537Tamil-Nadu n_f 2 t_s 7 n_layers 2 32 Error 0.18985817 0.20390162188659924 -1.4488242225241432\n",
            "(80, 5, 3)\n",
            "(80, 5, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.112539 Test loss: 0.526368Tamil-Nadu n_f 3 t_s 5 n_layers 1 1 Error 0.60372967 0.6176627297209911 -16.944183138626343\n",
            "Epoch: 0/10  Loss: 0.494646 Test loss: 0.760598Tamil-Nadu n_f 3 t_s 5 n_layers 1 5 Error 0.15236923 0.17046039026708315 -0.3666831559936663\n",
            "Epoch: 0/10  Loss: 0.265685 Test loss: 0.436325Tamil-Nadu n_f 3 t_s 5 n_layers 1 8 Error 0.16034554 0.17273237138377193 -0.40335778992882165\n",
            "Epoch: 0/10  Loss: 0.121238 Test loss: 0.455323Tamil-Nadu n_f 3 t_s 5 n_layers 1 16 Error 0.2867856 0.3187535425999067 -3.778932909145367\n",
            "Epoch: 0/10  Loss: 0.118781 Test loss: 0.245468Tamil-Nadu n_f 3 t_s 5 n_layers 1 32 Error 0.019629415 0.02144343026448547 0.978372343116201\n",
            "Epoch: 0/10  Loss: 0.933022 Test loss: 2.310311Tamil-Nadu n_f 3 t_s 5 n_layers 2 1 Error 1.0629611 1.072915246956389 -53.14417906391893\n",
            "Epoch: 0/10  Loss: 0.368828 Test loss: 0.707490Tamil-Nadu n_f 3 t_s 5 n_layers 2 5 Error 0.5646846 0.5800972880784885 -14.827875420715484\n",
            "Epoch: 0/10  Loss: 0.193552 Test loss: 0.338930Tamil-Nadu n_f 3 t_s 5 n_layers 2 8 Error 0.47893462 0.4966290807049864 -10.600727049560561\n",
            "Epoch: 0/10  Loss: 0.081548 Test loss: 0.270185Tamil-Nadu n_f 3 t_s 5 n_layers 2 16 Error 0.31505552 0.3349036787823716 -4.275465181626679\n",
            "Epoch: 0/10  Loss: 0.090199 Test loss: 0.258374Tamil-Nadu n_f 3 t_s 5 n_layers 2 32 Error 0.11804312 0.14924571582541563 -0.04767039746758028\n",
            "(80, 7, 3)\n",
            "(80, 7, 3) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.124502 Test loss: 0.585559Tamil-Nadu n_f 3 t_s 7 n_layers 1 1 Error 0.63245165 0.6431182400169282 -23.361157578206882\n",
            "Epoch: 0/10  Loss: 0.505739 Test loss: 0.782857Tamil-Nadu n_f 3 t_s 7 n_layers 1 5 Error 0.16034812 0.1748659410192381 -0.8010540982732561\n",
            "Epoch: 0/10  Loss: 0.271439 Test loss: 0.437565Tamil-Nadu n_f 3 t_s 7 n_layers 1 8 Error 0.16160463 0.17240349838027497 -0.7506865696144187\n",
            "Epoch: 0/10  Loss: 0.134468 Test loss: 0.486115Tamil-Nadu n_f 3 t_s 7 n_layers 1 16 Error 0.31663752 0.3401120650331878 -5.813345020210938\n",
            "Epoch: 0/10  Loss: 0.120353 Test loss: 0.208171Tamil-Nadu n_f 3 t_s 7 n_layers 1 32 Error 0.035717633 0.044052390932517255 0.885697621205007\n",
            "Epoch: 0/10  Loss: 0.945712 Test loss: 2.402891Tamil-Nadu n_f 3 t_s 7 n_layers 2 1 Error 1.0946405 1.1023682156990007 -70.57636878965687\n",
            "Epoch: 0/10  Loss: 0.385601 Test loss: 0.759648Tamil-Nadu n_f 3 t_s 7 n_layers 2 5 Error 0.5713538 0.5830803703000932 -19.02502914812566\n",
            "Epoch: 0/10  Loss: 0.190547 Test loss: 0.344303Tamil-Nadu n_f 3 t_s 7 n_layers 2 8 Error 0.372786 0.3894262803906856 -7.932371417694018\n",
            "Epoch: 0/10  Loss: 0.088665 Test loss: 0.290557Tamil-Nadu n_f 3 t_s 7 n_layers 2 16 Error 0.2659328 0.286758363985904 -3.8433789941345706\n",
            "Epoch: 0/10  Loss: 0.103310 Test loss: 0.231498Tamil-Nadu n_f 3 t_s 7 n_layers 2 32 Error 0.16863441 0.19155418751340705 -1.1612229448678026\n",
            "(80, 5, 4)\n",
            "(80, 5, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.492862 Test loss: 1.208679Tamil-Nadu n_f 4 t_s 5 n_layers 1 1 Error 0.64130014 0.6576712522383907 -19.344107434369146\n",
            "Epoch: 0/10  Loss: 0.196567 Test loss: 0.626712Tamil-Nadu n_f 4 t_s 5 n_layers 1 5 Error 0.30400875 0.32267761483014085 -3.8973214238334526\n",
            "Epoch: 0/10  Loss: 0.380398 Test loss: 0.765936Tamil-Nadu n_f 4 t_s 5 n_layers 1 8 Error 0.47980535 0.4964967127361749 -10.59454492806604\n",
            "Epoch: 0/10  Loss: 0.074208 Test loss: 0.324597Tamil-Nadu n_f 4 t_s 5 n_layers 1 16 Error 0.09075031 0.10950402330247992 0.4359974326582716\n",
            "Epoch: 0/10  Loss: 0.074302 Test loss: 0.124549Tamil-Nadu n_f 4 t_s 5 n_layers 1 32 Error 0.05457548 0.07306453458218631 0.7489072372646713\n",
            "Epoch: 0/10  Loss: 0.408259 Test loss: 0.997794Tamil-Nadu n_f 4 t_s 5 n_layers 2 1 Error 0.64155686 0.6579178777816026 -19.359368630559683\n",
            "Epoch: 0/10  Loss: 0.119953 Test loss: 0.424943Tamil-Nadu n_f 4 t_s 5 n_layers 2 5 Error 0.6776111 0.6931216409944092 -21.596431964495668\n",
            "Epoch: 0/10  Loss: 0.310729 Test loss: 0.611010Tamil-Nadu n_f 4 t_s 5 n_layers 2 8 Error 0.18770854 0.21847802522995946 -1.245103790312712\n",
            "Epoch: 0/10  Loss: 0.099552 Test loss: 0.255856Tamil-Nadu n_f 4 t_s 5 n_layers 2 16 Error 0.12069189 0.14662780097975542 -0.01123841582874796\n",
            "Epoch: 0/10  Loss: 0.118302 Test loss: 0.284964Tamil-Nadu n_f 4 t_s 5 n_layers 2 32 Error 0.2085742 0.2323852317839304 -1.5400251169374326\n",
            "(80, 7, 4)\n",
            "(80, 7, 4) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.506484 Test loss: 1.284496Tamil-Nadu n_f 4 t_s 7 n_layers 1 1 Error 0.6719468 0.6844636014953631 -26.594148773562473\n",
            "Epoch: 0/10  Loss: 0.203887 Test loss: 0.674229Tamil-Nadu n_f 4 t_s 7 n_layers 1 5 Error 0.31080213 0.3265932639018653 -5.282474832204293\n",
            "Epoch: 0/10  Loss: 0.393554 Test loss: 0.807278Tamil-Nadu n_f 4 t_s 7 n_layers 1 8 Error 0.47750443 0.49151824681647843 -13.229694053416834\n",
            "Epoch: 0/10  Loss: 0.081396 Test loss: 0.318760Tamil-Nadu n_f 4 t_s 7 n_layers 1 16 Error 0.05814441 0.06773086854466998 0.7297973814340204\n",
            "Epoch: 0/10  Loss: 0.087314 Test loss: 0.168575Tamil-Nadu n_f 4 t_s 7 n_layers 1 32 Error 0.051511467 0.06301807467804278 0.7660912201631281\n",
            "Epoch: 0/10  Loss: 0.420948 Test loss: 1.057126Tamil-Nadu n_f 4 t_s 7 n_layers 2 1 Error 0.66945875 0.6820212670433504 -26.397573414921606\n",
            "Epoch: 0/10  Loss: 0.128351 Test loss: 0.460731Tamil-Nadu n_f 4 t_s 7 n_layers 2 5 Error 0.7073554 0.7192562227931308 -29.4707784402325\n",
            "Epoch: 0/10  Loss: 0.334989 Test loss: 0.711302Tamil-Nadu n_f 4 t_s 7 n_layers 2 8 Error 0.28881675 0.31059990436103585 -4.682231583959123\n",
            "Epoch: 0/10  Loss: 0.110458 Test loss: 0.268020Tamil-Nadu n_f 4 t_s 7 n_layers 2 16 Error 0.11095706 0.13772927534991278 -0.11729739276216278\n",
            "Epoch: 0/10  Loss: 0.127245 Test loss: 0.238598Tamil-Nadu n_f 4 t_s 7 n_layers 2 32 Error 0.23587385 0.2627850489165443 -3.067406716298656\n",
            "(80, 5, 5)\n",
            "(80, 5, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.616014 Test loss: 2.879703Tamil-Nadu n_f 5 t_s 5 n_layers 1 1 Error 0.80792075 0.8377209471580092 -32.00803233557188\n",
            "Epoch: 0/10  Loss: 0.184582 Test loss: 0.233410Tamil-Nadu n_f 5 t_s 5 n_layers 1 5 Error 0.10604404 0.1339313627417646 0.15630495090372154\n",
            "Epoch: 0/10  Loss: 0.415114 Test loss: 0.920953Tamil-Nadu n_f 5 t_s 5 n_layers 1 8 Error 0.41622037 0.4354151881647637 -7.917191140522553\n",
            "Epoch: 0/10  Loss: 0.102531 Test loss: 0.185918Tamil-Nadu n_f 5 t_s 5 n_layers 1 16 Error 0.13531674 0.15969707212108067 -0.19954030497923503\n",
            "Epoch: 0/10  Loss: 0.139262 Test loss: 0.380044Tamil-Nadu n_f 5 t_s 5 n_layers 1 32 Error 0.11315455 0.1345023541426173 0.1490956822897206\n",
            "Epoch: 0/10  Loss: 0.769445 Test loss: 0.030995Tamil-Nadu n_f 5 t_s 5 n_layers 2 1 Error 0.5686973 0.5865356952149818 -15.18116554532045\n",
            "Epoch: 0/10  Loss: 0.115668 Test loss: 0.500654Tamil-Nadu n_f 5 t_s 5 n_layers 2 5 Error 0.62017655 0.6373207896913882 -18.104562883241716\n",
            "Epoch: 0/10  Loss: 0.188849 Test loss: 0.543620Tamil-Nadu n_f 5 t_s 5 n_layers 2 8 Error 0.25178257 0.27993139469569095 -2.68573544544204\n",
            "Epoch: 0/10  Loss: 0.242575 Test loss: 0.402508Tamil-Nadu n_f 5 t_s 5 n_layers 2 16 Error 0.300873 0.3175784989621071 -3.743764552890072\n",
            "Epoch: 0/10  Loss: 0.085672 Test loss: 0.039883Tamil-Nadu n_f 5 t_s 5 n_layers 2 32 Error 0.29481936 0.3190539453613151 -3.787945007860337\n",
            "(80, 7, 5)\n",
            "(80, 7, 5) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.643802 Test loss: 3.159851Tamil-Nadu n_f 5 t_s 7 n_layers 1 1 Error 0.8448257 0.8686911117025224 -43.447465223092564\n",
            "Epoch: 0/10  Loss: 0.184576 Test loss: 0.238600Tamil-Nadu n_f 5 t_s 7 n_layers 1 5 Error 0.08765899 0.11384084619326097 0.2366697142779084\n",
            "Epoch: 0/10  Loss: 0.429978 Test loss: 0.979462Tamil-Nadu n_f 5 t_s 7 n_layers 1 8 Error 0.44730562 0.4616985503811188 -11.555480539517161\n",
            "Epoch: 0/10  Loss: 0.085505 Test loss: 0.106953Tamil-Nadu n_f 5 t_s 7 n_layers 1 16 Error 0.07301234 0.0871427746749239 0.5527204671966706\n",
            "Epoch: 0/10  Loss: 0.153949 Test loss: 0.414386Tamil-Nadu n_f 5 t_s 7 n_layers 1 32 Error 0.17173822 0.18559281633716776 -1.0287970393487114\n",
            "Epoch: 0/10  Loss: 0.756396 Test loss: 0.021351Tamil-Nadu n_f 5 t_s 7 n_layers 2 1 Error 0.58396095 0.5977895999317103 -20.048104513139478\n",
            "Epoch: 0/10  Loss: 0.128841 Test loss: 0.553974Tamil-Nadu n_f 5 t_s 7 n_layers 2 5 Error 0.6497494 0.6628960181552442 -24.8825518476889\n",
            "Epoch: 0/10  Loss: 0.201709 Test loss: 0.539349Tamil-Nadu n_f 5 t_s 7 n_layers 2 8 Error 0.24341193 0.2672580280133031 -3.207051208054045\n",
            "Epoch: 0/10  Loss: 0.249108 Test loss: 0.414014Tamil-Nadu n_f 5 t_s 7 n_layers 2 16 Error 0.23308332 0.2463144342239582 -2.573518416258332\n",
            "Epoch: 0/10  Loss: 0.084269 Test loss: 0.055442Tamil-Nadu n_f 5 t_s 7 n_layers 2 32 Error 0.24817517 0.2734864463594764 -3.405426009806618\n",
            "(80, 5, 6)\n",
            "(80, 5, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.296337 Test loss: 1.020343Tamil-Nadu n_f 6 t_s 5 n_layers 1 1 Error 0.60249543 0.6201397028162182 -17.088394917473472\n",
            "Epoch: 0/10  Loss: 0.412998 Test loss: 0.914429Tamil-Nadu n_f 6 t_s 5 n_layers 1 5 Error 0.58202463 0.598107659896735 -15.825952988416567\n",
            "Epoch: 0/10  Loss: 0.239013 Test loss: 0.386110Tamil-Nadu n_f 6 t_s 5 n_layers 1 8 Error 0.52209955 0.5416350141471525 -12.798581219952993\n",
            "Epoch: 0/10  Loss: 0.087996 Test loss: 0.095530Tamil-Nadu n_f 6 t_s 5 n_layers 1 16 Error 0.1563781 0.16674985647266852 -0.307831670708117\n",
            "Epoch: 0/10  Loss: 0.095871 Test loss: 0.288540Tamil-Nadu n_f 6 t_s 5 n_layers 1 32 Error 0.047226865 0.05597941057622393 0.8526067626853489\n",
            "Epoch: 0/10  Loss: 0.131699 Test loss: 0.266742Tamil-Nadu n_f 6 t_s 5 n_layers 2 1 Error 0.49268728 0.5138107808210434 -11.417306877996342\n",
            "Epoch: 0/10  Loss: 0.159036 Test loss: 0.468155Tamil-Nadu n_f 6 t_s 5 n_layers 2 5 Error 0.2387489 0.27200741776877274 -2.480025395494486\n",
            "Epoch: 0/10  Loss: 0.161428 Test loss: 0.642336Tamil-Nadu n_f 6 t_s 5 n_layers 2 8 Error 0.27930316 0.3095267713474038 -3.5062716051930334\n",
            "Epoch: 0/10  Loss: 0.081337 Test loss: 0.254287Tamil-Nadu n_f 6 t_s 5 n_layers 2 16 Error 0.22048308 0.24490591267918707 -1.8211064139097601\n",
            "Epoch: 0/10  Loss: 0.097968 Test loss: 0.288730Tamil-Nadu n_f 6 t_s 5 n_layers 2 32 Error 0.21867405 0.24967961345435052 -1.932156178095417\n",
            "(80, 7, 6)\n",
            "(80, 7, 6) (80, 1)\n",
            "Epoch: 0/10  Loss: 0.313481 Test loss: 1.107063Tamil-Nadu n_f 6 t_s 7 n_layers 1 1 Error 0.6331874 0.6476293146401648 -23.704112809063748\n",
            "Epoch: 0/10  Loss: 0.421862 Test loss: 0.960587Tamil-Nadu n_f 6 t_s 7 n_layers 1 5 Error 0.5599806 0.5736182310012972 -18.38037533568273\n",
            "Epoch: 0/10  Loss: 0.243469 Test loss: 0.423184Tamil-Nadu n_f 6 t_s 7 n_layers 1 8 Error 0.5506017 0.5654280008610423 -17.830892188186006\n",
            "Epoch: 0/10  Loss: 0.089355 Test loss: 0.089633Tamil-Nadu n_f 6 t_s 7 n_layers 1 16 Error 0.09148265 0.10056978855309207 0.40426746456104357\n",
            "Epoch: 0/10  Loss: 0.098699 Test loss: 0.248080Tamil-Nadu n_f 6 t_s 7 n_layers 1 32 Error 0.015509651 0.019398399874285443 0.977835999318983\n",
            "Epoch: 0/10  Loss: 0.131223 Test loss: 0.284854Tamil-Nadu n_f 6 t_s 7 n_layers 2 1 Error 0.5042703 0.5208324400576243 -14.977629816578142\n",
            "Epoch: 0/10  Loss: 0.168931 Test loss: 0.463575Tamil-Nadu n_f 6 t_s 7 n_layers 2 5 Error 0.2773701 0.29925687113819116 -4.274782588180659\n",
            "Epoch: 0/10  Loss: 0.169492 Test loss: 0.673957Tamil-Nadu n_f 6 t_s 7 n_layers 2 8 Error 0.307175 0.3309450108519626 -5.451013045387225\n",
            "Epoch: 0/10  Loss: 0.070051 Test loss: 0.173920Tamil-Nadu n_f 6 t_s 7 n_layers 2 16 Error 0.18231367 0.19925834224939362 -1.3385644363089075\n",
            "Epoch: 0/10  Loss: 0.115966 Test loss: 0.323164Tamil-Nadu n_f 6 t_s 7 n_layers 2 32 Error 0.23010173 0.2455302932995421 -2.5508019338606607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fAvSsrNr3KK_",
        "outputId": "f6a753cc-fb3c-41d9-b135-a6572485e24f"
      },
      "source": [
        "df_gru = pd.DataFrame (results_gru,columns=['State','Number_feature','Time_Step','number_layers','number_hiddinen_nodes','MAE','RMSE','R2_Score'])\n",
        "df_gru.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Number_feature</th>\n",
              "      <th>Time_Step</th>\n",
              "      <th>number_layers</th>\n",
              "      <th>number_hiddinen_nodes</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.770639</td>\n",
              "      <td>0.784845</td>\n",
              "      <td>-31.888698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.676219</td>\n",
              "      <td>0.690067</td>\n",
              "      <td>-24.425039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.615304</td>\n",
              "      <td>0.628646</td>\n",
              "      <td>-20.100442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0.482998</td>\n",
              "      <td>0.491718</td>\n",
              "      <td>-11.909552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Karnataka</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0.037934</td>\n",
              "      <td>0.041694</td>\n",
              "      <td>0.907185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       State  Number_feature  Time_Step  ...       MAE      RMSE   R2_Score\n",
              "0  Karnataka               1          5  ...  0.770639  0.784845 -31.888698\n",
              "1  Karnataka               1          5  ...  0.676219  0.690067 -24.425039\n",
              "2  Karnataka               1          5  ...  0.615304  0.628646 -20.100442\n",
              "3  Karnataka               1          5  ...  0.482998  0.491718 -11.909552\n",
              "4  Karnataka               1          5  ...  0.037934  0.041694   0.907185\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6b7yYd8sjUX",
        "outputId": "a7796a0a-2968-4162-b4ff-575a08ed13f7"
      },
      "source": [
        "#github_upload(folder_name='Indian-States-Model-Results',file_name='GRU_on_short_data.csv', file_data=df_gru.to_csv())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indian-States-Model-Results/GRU_on_short_data.csv UPDATED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V1Guw4ht_R3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}